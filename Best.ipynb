{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2F4nkytZCqo+5r/d9+C/2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AyanBhardwaj06/Niseeth/blob/main/Best.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BR1(1/07/25)"
      ],
      "metadata": {
        "id": "vHtUeMr4ZJiB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRDt6micZDn8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "outputId": "4c501198-1ab5-4242-c982-cbb458de443b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2']\n",
            "['Name', 'Usable_Area_(SQM)', 'Max_Assignable_Floor_loading_Capacity']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unable to parse string \"Usable_Area_(SQM)\" at position 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32mlib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unable to parse string \"Usable_Area_(SQM)\"",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-512271449.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_floor_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Coerce floor‐area and capacity to numeric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m all_floor_data['Usable_Area_(SQM)'] = pd.to_numeric(\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mall_floor_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Usable_Area_(SQM)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raise'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/tools/numeric.py\u001b[0m in \u001b[0;36mto_numeric\u001b[0;34m(arg, errors, downcast, dtype_backend)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mcoerce_numeric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             values, new_mask = lib.maybe_convert_numeric(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m    233\u001b[0m                 \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mlib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unable to parse string \"Usable_Area_(SQM)\" at position 0"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import math\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 1: Load All Input Sheets from AR-1.xlsx\n",
        "\n",
        "# ----------------------------------------\n",
        "\n",
        "excel_path = '/content/BR-1.xlsx'  # ← adjust if needed\n",
        "\n",
        "# 1.1 Floors sheet (skip the first row)\n",
        "all_floor_data = pd.read_excel(\n",
        "    excel_path,\n",
        "    sheet_name='Program Table Input 2 - Floor',\n",
        "    skiprows=0  # Don't skip header\n",
        ")\n",
        "all_floor_data.columns = all_floor_data.columns.str.strip()\n",
        "print(all_floor_data.columns.tolist())\n",
        "\n",
        "all_floor_data = all_floor_data.rename(columns={\n",
        "    all_floor_data.columns[0]: 'Name',\n",
        "    all_floor_data.columns[1]: 'Usable_Area_(SQM)',\n",
        "    all_floor_data.columns[2]: 'Max_Assignable_Floor_loading_Capacity'\n",
        "})\n",
        "print(all_floor_data.columns.tolist())\n",
        "# Coerce floor‐area and capacity to numeric\n",
        "all_floor_data['Usable_Area_(SQM)'] = pd.to_numeric(\n",
        "    all_floor_data['Usable_Area_(SQM)'], errors='raise'\n",
        ")\n",
        "all_floor_data['Max_Assignable_Floor_loading_Capacity'] = pd.to_numeric(\n",
        "    all_floor_data['Max_Assignable_Floor_loading_Capacity'], errors='raise'\n",
        ")\n",
        "\n",
        "# 1.2 Blocks sheet\n",
        "all_block_data = pd.read_excel(\n",
        "    excel_path,\n",
        "    sheet_name='Program Table Input 1 - Block'\n",
        ")\n",
        "all_block_data.columns = all_block_data.columns.str.strip()\n",
        "\n",
        "# Ensure these columns are numeric\n",
        "all_block_data['Cumulative_Area_SQM'] = pd.to_numeric(\n",
        "    all_block_data['Cumulative_Block_Circulation_Area'], errors='raise'\n",
        ")\n",
        "all_block_data['Max_Occupancy_with_Capacity'] = pd.to_numeric(\n",
        "    all_block_data['Max_Occupancy_with_Capacity'], errors='raise'\n",
        ")\n",
        "\n",
        "# 1.3 Department Split sheet (skip header row)\n",
        "department_split_data = pd.read_excel(\n",
        "    excel_path,\n",
        "    sheet_name='Department Split',\n",
        "    skiprows=1 # Skip the first row which is not the header\n",
        ")\n",
        "# Set column names explicitly based on expected structure\n",
        "department_split_data.columns = [\n",
        "    'Department_Sub-Department',\n",
        "    'Splittable',\n",
        "    'Min_%_of_Block_per_department',\n",
        "    'Unknown1', # Assuming these are the extra columns\n",
        "    'Unknown2'\n",
        "]\n",
        "department_split_data = department_split_data[['Department_Sub-Department', 'Splittable', 'Min_%_of_Block_per_department']].copy()\n",
        "\n",
        "department_split_data.columns = department_split_data.columns.str.strip()\n",
        "print(department_split_data.columns.tolist())\n",
        "# Build dictionaries:\n",
        "dept_splittable = department_split_data.set_index('Department_Sub-Department')['Splittable'].to_dict()\n",
        "dept_min_pct    = department_split_data.set_index('Department_Sub-Department')['Min_%_of_Block_per_department'].to_dict()\n",
        "\n",
        "# 1.4 Min%Split sheet (not used below but loaded)\n",
        "min_split_data = pd.read_excel(\n",
        "    excel_path,\n",
        "    sheet_name='Min % Split'\n",
        ")\n",
        "min_split_data.columns = min_split_data.columns.str.strip()\n",
        "\n",
        "# 1.5 Adjacency sheet\n",
        "xls = pd.ExcelFile(excel_path)\n",
        "adjacency_sheet_name = [name for name in xls.sheet_names if \"Adjacency\" in name][0]\n",
        "raw_data = xls.parse(adjacency_sheet_name, header=1, index_col=0)\n",
        "adjacency_data = raw_data.apply(pd.to_numeric, errors='coerce')\n",
        "adjacency_data.index   = adjacency_data.index.str.strip()\n",
        "adjacency_data.columns = adjacency_data.columns.str.strip()\n",
        "\n",
        "# 1.6 De-Centralized Logic sheet\n",
        "df_logic = pd.read_excel(\n",
        "    excel_path,\n",
        "    sheet_name='De-Centralized Logic',\n",
        "    header=None\n",
        ")\n",
        "De_Centralized_data = {}\n",
        "current_section = None\n",
        "for _, row in df_logic.iterrows():\n",
        "    first_cell = str(row[0]).strip() if pd.notna(row[0]) else \"\"\n",
        "    if first_cell in [\"Centralised\", \"Semi Centralized\", \"DeCentralised\"]:\n",
        "        current_section = first_cell\n",
        "        De_Centralized_data[current_section] = {\"Add\": 0}\n",
        "    elif current_section and first_cell == \"( Add into cetralised destination Block)\":\n",
        "        De_Centralized_data[current_section][\"Add\"] = int(row[1]) if pd.notna(row[1]) else 0\n",
        "\n",
        "for key in [\"Centralised\", \"Semi Centralized\", \"DeCentralised\"]:\n",
        "    if key not in De_Centralized_data:\n",
        "        De_Centralized_data[key] = {\"Add\": 0}\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 2: Preprocess Blocks & Department Split\n",
        "# ----------------------------------------\n",
        "\n",
        "# 2.2 Separate Destination vs. Typical blocks\n",
        "destination_blocks = all_block_data[\n",
        "    all_block_data['Typical_Destination'] == 'Destination'\n",
        "].copy()\n",
        "typical_blocks = all_block_data[\n",
        "    all_block_data['Typical_Destination'] == 'Typical'\n",
        "].copy()\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 3: Initialize Floor Assignments\n",
        "# ----------------------------------------\n",
        "\n",
        "def initialize_floor_assignments(floor_df):\n",
        "    \"\"\"\n",
        "    Returns a dict keyed by floor name. Each entry has:\n",
        "      - remaining_area\n",
        "      - remaining_capacity\n",
        "      - assigned_blocks      (list of block‐row dicts)\n",
        "      - assigned_departments (set of sub‐departments)\n",
        "      - ME_area, WE_area, US_area, Support_area, Speciality_area (floats)\n",
        "    \"\"\"\n",
        "    assignments = {}\n",
        "    for _, row in floor_df.iterrows():\n",
        "        floor = row['Name'].strip()\n",
        "        assignments[floor] = {\n",
        "            'remaining_area': row['Usable_Area_(SQM)'],\n",
        "            'remaining_capacity': row['Max_Assignable_Floor_loading_Capacity'],\n",
        "            'assigned_blocks': [],\n",
        "            'assigned_departments': set(),\n",
        "            'ME_area': 0.0,\n",
        "            'WE_area': 0.0,\n",
        "            'US_area': 0.0,\n",
        "            'Support_area': 0.0,\n",
        "            'Speciality_area': 0.0\n",
        "        }\n",
        "    return assignments\n",
        "\n",
        "floors = list(initialize_floor_assignments(all_floor_data).keys())\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 4: Core Stacking Function (with modified destination‐split logic + unassigned handling)\n",
        "# ----------------------------------------\n",
        "\n",
        "def run_stack_plan(mode):\n",
        "    \"\"\"\n",
        "    mode: 'centralized', 'semi', or 'decentralized'\n",
        "    Returns four DataFrames:\n",
        "      detailed_df      – block‐to‐floor assignments\n",
        "      floor_summary_df – floor totals (count, area, occupancy)\n",
        "      space_mix_df     – for each floor & category {ME, WE, US, Support, Speciality}:\n",
        "                          Unit_Count_on_Floor,\n",
        "                          Pct_of_Floor_UC,\n",
        "                          Pct_of_Overall_UC\n",
        "      unassigned_df    – blocks that couldn’t be placed\n",
        "    \"\"\"\n",
        "    assignments = initialize_floor_assignments(all_floor_data)\n",
        "    unassigned_blocks = []\n",
        "\n",
        "    # 4.1 Determine how many floors to use for destination blocks\n",
        "    def destination_floor_count():\n",
        "        if mode == 'centralized':\n",
        "            return 2\n",
        "        elif mode == 'semi':\n",
        "            return 2 + De_Centralized_data[\"Semi Centralized\"][\"Add\"]\n",
        "        elif mode == 'decentralized':\n",
        "            return 2 + De_Centralized_data[\"DeCentralised\"][\"Add\"]\n",
        "        else:\n",
        "            return 2\n",
        "\n",
        "    max_dest_floors = min(destination_floor_count(), len(floors))\n",
        "\n",
        "    # 4.2 Group destination blocks by Destination_Group\n",
        "    dest_groups = {}\n",
        "    for _, blk in destination_blocks.iterrows():\n",
        "        grp = blk['Destination_Group']\n",
        "        if grp not in dest_groups:\n",
        "            dest_groups[grp] = {'blocks': [], 'total_area': 0.0, 'total_capacity': 0}\n",
        "        dest_groups[grp]['blocks'].append(blk.to_dict())\n",
        "        dest_groups[grp]['total_area'] += blk['Cumulative_Area_SQM']\n",
        "        dest_groups[grp]['total_capacity'] += blk['Max_Occupancy_with_Capacity']\n",
        "\n",
        "    # Phase 1: Assign destination groups (try whole‐group first; if that fails, split across floors)\n",
        "    group_names = list(dest_groups.keys())\n",
        "    random.shuffle(group_names)\n",
        "    for grp in group_names:\n",
        "        info_grp = dest_groups[grp]\n",
        "        grp_area = info_grp['total_area']\n",
        "        grp_cap  = info_grp['total_capacity']\n",
        "        placed_whole = False\n",
        "\n",
        "        # 4.2.a Attempt to place entire group on any of the first max_dest_floors\n",
        "        candidate_floors = floors[:max_dest_floors].copy()\n",
        "\n",
        "        for fl in candidate_floors:\n",
        "            if (assignments[fl]['remaining_area'] >= grp_area and\n",
        "                assignments[fl]['remaining_capacity'] >= grp_cap):\n",
        "                # Entire group fits here—place all blocks\n",
        "                for blk in info_grp['blocks']:\n",
        "                    assignments[fl]['assigned_blocks'].append(blk)\n",
        "                    assignments[fl]['assigned_departments'].add(\n",
        "                        blk['Department_Sub_Department']\n",
        "                    )\n",
        "                assignments[fl]['remaining_area'] -= grp_area\n",
        "                assignments[fl]['remaining_capacity'] -= grp_cap\n",
        "                placed_whole = True\n",
        "                break\n",
        "\n",
        "        # 4.2.b If not yet placed, try the remaining floors (beyond max_dest_floors)\n",
        "        if not placed_whole:\n",
        "            for fl in floors[max_dest_floors:]:\n",
        "                if (assignments[fl]['remaining_area'] >= grp_area and\n",
        "                    assignments[fl]['remaining_capacity'] >= grp_cap):\n",
        "                    for blk in info_grp['blocks']:\n",
        "                        assignments[fl]['assigned_blocks'].append(blk)\n",
        "                        assignments[fl]['assigned_departments'].add(\n",
        "                            blk['Department_Sub_Department'].strip()\n",
        "                        )\n",
        "                    assignments[fl]['remaining_area'] -= grp_area\n",
        "                    assignments[fl]['remaining_capacity'] -= grp_cap\n",
        "                    placed_whole = True\n",
        "                    break\n",
        "\n",
        "        # 4.2.c If still not placed as a whole, split the group block‐by‐block across floors\n",
        "        if not placed_whole:\n",
        "            total_remaining_area = sum(assignments[f]['remaining_area'] for f in floors)\n",
        "            if total_remaining_area >= grp_area:\n",
        "                # Try placing group by removing the largest blocks one-by-one until remaining can be placed whole\n",
        "                blocks_sorted = sorted(info_grp['blocks'], key=lambda b: b['Cumulative_Area_SQM'], reverse=True)\n",
        "                removed_blocks = []\n",
        "                trial_blocks = blocks_sorted.copy()\n",
        "\n",
        "                while trial_blocks:\n",
        "                    trial_area = sum(b['Cumulative_Area_SQM'] for b in trial_blocks)\n",
        "                    trial_capacity = sum(b['Max_Occupancy_with_Capacity'] for b in trial_blocks)\n",
        "\n",
        "                    # Try to place this reduced group\n",
        "                    floor_combination = []\n",
        "                    temp_assignments = {f: assignments[f].copy() for f in floors}\n",
        "                    temp_floors_by_space = sorted(floors, key=lambda f: assignments[f]['remaining_area'], reverse=True)\n",
        "\n",
        "                    temp_success = True\n",
        "                    for blk in trial_blocks:\n",
        "                        blk_area = blk['Cumulative_Area_SQM']\n",
        "                        blk_capacity = blk['Max_Occupancy_with_Capacity']\n",
        "                        placed_block = False\n",
        "\n",
        "                        for fl in temp_floors_by_space:\n",
        "                            if (temp_assignments[fl]['remaining_area'] >= blk_area and\n",
        "                                temp_assignments[fl]['remaining_capacity'] >= blk_capacity):\n",
        "                                temp_assignments[fl]['remaining_area'] -= blk_area\n",
        "                                temp_assignments[fl]['remaining_capacity'] -= blk_capacity\n",
        "                                floor_combination.append((blk, fl))\n",
        "                                placed_block = True\n",
        "                                break\n",
        "\n",
        "                        if not placed_block:\n",
        "                            temp_success = False\n",
        "                            break\n",
        "\n",
        "                    if temp_success:\n",
        "                        # Apply final assignment for successfully placed trial blocks\n",
        "                        for blk, fl in floor_combination:\n",
        "                            assignments[fl]['assigned_blocks'].append(blk)\n",
        "                            assignments[fl]['assigned_departments'].add(blk['Department_Sub_Department'].strip())\n",
        "                            assignments[fl]['remaining_area'] -= blk['Cumulative_Area_SQM']\n",
        "                            assignments[fl]['remaining_capacity'] -= blk['Max_Occupancy_with_Capacity']\n",
        "                        placed_whole = True\n",
        "                        break\n",
        "                    else:\n",
        "                        # Remove one largest block and retry\n",
        "                        removed_blocks.append(trial_blocks.pop(0))\n",
        "\n",
        "                # Place removed blocks one-by-one\n",
        "                for blk in removed_blocks:\n",
        "                    blk_area = blk['Cumulative_Area_SQM']\n",
        "                    blk_capacity = blk['Max_Occupancy_with_Capacity']\n",
        "                    placed_block = False\n",
        "                    floors_by_space = sorted(floors, key=lambda f: assignments[f]['remaining_area'], reverse=True)\n",
        "\n",
        "                    for fl in floors_by_space:\n",
        "                        if (assignments[fl]['remaining_area'] >= blk_area and\n",
        "                            assignments[fl]['remaining_capacity'] >= blk_capacity):\n",
        "                            assignments[fl]['assigned_blocks'].append(blk)\n",
        "                            assignments[fl]['assigned_departments'].add(blk['Department_Sub_Department'].strip())\n",
        "                            assignments[fl]['remaining_area'] -= blk_area\n",
        "                            assignments[fl]['remaining_capacity'] -= blk_capacity\n",
        "                            placed_block = True\n",
        "                            break\n",
        "\n",
        "                    if not placed_block:\n",
        "                        unassigned_blocks.append(blk)\n",
        "            else:\n",
        "                # Even splitting won't fit all blocks, place block-by-block\n",
        "                for blk in sorted(info_grp['blocks'], key=lambda b: b['Cumulative_Area_SQM'], reverse=True):\n",
        "                    blk_area     = blk['Cumulative_Area_SQM']\n",
        "                    blk_capacity = blk['Max_Occupancy_with_Capacity']\n",
        "                    placed_block = False\n",
        "\n",
        "                    floors_by_space = sorted(floors, key=lambda f: assignments[f]['remaining_area'], reverse=True)\n",
        "                    for fl in floors_by_space:\n",
        "                        if (assignments[fl]['remaining_area'] >= blk_area and\n",
        "                            assignments[fl]['remaining_capacity'] >= blk_capacity):\n",
        "                            assignments[fl]['assigned_blocks'].append(blk)\n",
        "                            assignments[fl]['assigned_departments'].add(blk['Department_Sub_Department'].strip())\n",
        "                            assignments[fl]['remaining_area'] -= blk_area\n",
        "                            assignments[fl]['remaining_capacity'] -= blk_capacity\n",
        "                            placed_block = True\n",
        "                            break\n",
        "\n",
        "                    if not placed_block:\n",
        "                        unassigned_blocks.append(blk)\n",
        "\n",
        "\n",
        "    # Phase 2: Handle typical blocks with department‐splittable logic\n",
        "\n",
        "    # 4.3 Separate typical blocks into:\n",
        "    #   - dept_unsplittable_groups: {department → [block_dicts]} for Splittable != -1\n",
        "    #   - splittable_blocks: list of block_dicts for Splittable == -1\n",
        "    dept_unsplittable_groups = {}\n",
        "    splittable_blocks = []\n",
        "\n",
        "    for blk in typical_blocks.to_dict('records'):\n",
        "        dept = blk['Department_Sub_Department'].strip()\n",
        "        # ← DEFAULT TO -1 (splittable) IF MISSING\n",
        "        spl = dept_splittable.get(dept, -1)\n",
        "        if spl == -1:\n",
        "            splittable_blocks.append(blk)\n",
        "        else:\n",
        "            dept_unsplittable_groups.setdefault(dept, []).append(blk)\n",
        "\n",
        "    # 4.4 Phase 2A: Assign each unsplittable department's blocks as a group\n",
        "    for dept, blocks_list in dept_unsplittable_groups.items():\n",
        "        total_area = sum(b['Cumulative_Area_SQM'] for b in blocks_list)\n",
        "        total_cap  = sum(b['Max_Occupancy_with_Capacity'] for b in blocks_list)\n",
        "        placed = False\n",
        "\n",
        "        candidate_floors = sorted(\n",
        "            floors,\n",
        "            key=lambda f: assignments[f]['remaining_area'],\n",
        "            reverse=True\n",
        "        )\n",
        "        for fl in candidate_floors:\n",
        "            if (assignments[fl]['remaining_area'] >= total_area and\n",
        "                assignments[fl]['remaining_capacity'] >= total_cap):\n",
        "                for blk in blocks_list:\n",
        "                    assignments[fl]['assigned_blocks'].append(blk)\n",
        "                    assignments[fl]['assigned_departments'].add(dept)\n",
        "                    cat = blk['SpaceMix_(ME_WE_US_Support_Speciality)'].strip()\n",
        "                    if cat == 'ME':\n",
        "                        assignments[fl]['ME_area'] += blk['Cumulative_Area_SQM']\n",
        "                    elif cat == 'WE':\n",
        "                        assignments[fl]['WE_area'] += blk['Cumulative_Area_SQM']\n",
        "                    elif cat == 'US':\n",
        "                        assignments[fl]['US_area'] += blk['Cumulative_Area_SQM']\n",
        "                    elif cat.lower() == 'support':\n",
        "                        assignments[fl]['Support_area'] += blk['Cumulative_Area_SQM']\n",
        "                    elif cat.lower() == 'speciality':\n",
        "                        assignments[fl]['Speciality_area'] += blk['Cumulative_Area_SQM']\n",
        "                assignments[fl]['remaining_area'] -= total_area\n",
        "                assignments[fl]['remaining_capacity'] -= total_cap\n",
        "                placed = True\n",
        "                break\n",
        "\n",
        "        if not placed:\n",
        "            # Mark entire department group as unassigned\n",
        "            unassigned_blocks.extend(blocks_list)\n",
        "\n",
        "    # 4.5 Phase 2B: On the remaining splittable blocks, assign by space‐mix logic\n",
        "\n",
        "    # 4.5.a Assign all ME blocks randomly\n",
        "    me_blocks = [\n",
        "        blk for blk in splittable_blocks\n",
        "        if blk['SpaceMix_(ME_WE_US_Support_Speciality)'].strip() == 'ME'\n",
        "    ]\n",
        "    random.shuffle(me_blocks)\n",
        "    for blk in me_blocks:\n",
        "        blk_area     = blk['Cumulative_Area_SQM']\n",
        "        blk_capacity = blk['Max_Occupancy_with_Capacity']\n",
        "        blk_dept     = blk['Department_Sub_Department'].strip()\n",
        "\n",
        "        candidate_floors = floors.copy()\n",
        "        random.shuffle(candidate_floors)\n",
        "        placed = False\n",
        "        for fl in candidate_floors:\n",
        "            if (assignments[fl]['remaining_area']   >= blk_area  and\n",
        "    assignments[fl]['remaining_capacity'] >= blk_capacity):\n",
        "\n",
        "                assignments[fl]['assigned_blocks'].append(blk)\n",
        "                assignments[fl]['remaining_area'] -= blk_area\n",
        "                assignments[fl]['remaining_capacity'] -= blk_capacity\n",
        "                assignments[fl]['assigned_departments'].add(blk_dept)\n",
        "                assignments[fl]['ME_area'] += blk_area\n",
        "                placed = True\n",
        "                break\n",
        "        if not placed:\n",
        "            unassigned_blocks.append(blk)\n",
        "\n",
        "    # 4.5.b Compute ME distribution per floor (unit counts)\n",
        "    me_count_per_floor = {fl: 0 for fl in floors}\n",
        "    for fl, info in assignments.items():\n",
        "        me_count_per_floor[fl] = sum(\n",
        "            1 for blk in info['assigned_blocks']\n",
        "            if blk['SpaceMix_(ME_WE_US_Support_Speciality)'].strip() == 'ME'\n",
        "        )\n",
        "    total_me = sum(me_count_per_floor.values())\n",
        "    if total_me == 0:\n",
        "        me_frac_per_floor = {fl: 1 / len(floors) for fl in floors}\n",
        "    else:\n",
        "        me_frac_per_floor = {\n",
        "            fl: me_count_per_floor[fl] / total_me for fl in floors\n",
        "        }\n",
        "\n",
        "    # 4.5.c Assign other categories proportionally\n",
        "    other_categories = ['WE', 'US', 'Support', 'Speciality']\n",
        "    for category in other_categories:\n",
        "        cat_blocks = [\n",
        "            blk for blk in splittable_blocks\n",
        "            if blk['SpaceMix_(ME_WE_US_Support_Speciality)'].strip() == category\n",
        "        ]\n",
        "        total_cat = len(cat_blocks)\n",
        "        if total_cat == 0:\n",
        "            continue\n",
        "\n",
        "        raw_targets = {fl: me_frac_per_floor[fl] * total_cat for fl in floors}\n",
        "        target_counts = {fl: int(round(raw_targets[fl])) for fl in floors}\n",
        "\n",
        "        diff = total_cat - sum(target_counts.values())\n",
        "        if diff != 0:\n",
        "            fractional_parts = {\n",
        "                fl: raw_targets[fl] - math.floor(raw_targets[fl]) for fl in floors\n",
        "            }\n",
        "            if diff > 0:\n",
        "                for fl in sorted(floors, key=lambda x: fractional_parts[x], reverse=True)[:diff]:\n",
        "                    target_counts[fl] += 1\n",
        "            else:\n",
        "                for fl in sorted(floors, key=lambda x: fractional_parts[x])[: -diff]:\n",
        "                    target_counts[fl] -= 1\n",
        "\n",
        "        random.shuffle(cat_blocks)\n",
        "        assigned_counts = {fl: 0 for fl in floors}\n",
        "\n",
        "        for blk in cat_blocks:\n",
        "            blk_area     = blk['Cumulative_Area_SQM']\n",
        "            blk_capacity = blk['Max_Occupancy_with_Capacity']\n",
        "            blk_dept     = blk['Department_Sub_Department'].strip()\n",
        "\n",
        "            deficits = {fl: target_counts[fl] - assigned_counts[fl] for fl in floors}\n",
        "            floors_with_deficit = [fl for fl, d in deficits.items() if d > 0]\n",
        "            if floors_with_deficit:\n",
        "                candidate_floors = sorted(\n",
        "                    floors_with_deficit,\n",
        "                    key=lambda x: deficits[x],\n",
        "                    reverse=True\n",
        "                )\n",
        "            else:\n",
        "                candidate_floors = floors.copy()\n",
        "\n",
        "            placed = False\n",
        "            for fl in candidate_floors:\n",
        "                if (assignments[fl]['remaining_area']   >= blk_area  and\n",
        "    assignments[fl]['remaining_capacity'] >= blk_capacity):\n",
        "\n",
        "                    assignments[fl]['assigned_blocks'].append(blk)\n",
        "                    assignments[fl]['remaining_area'] -= blk_area\n",
        "                    assignments[fl]['remaining_capacity'] -= blk_capacity\n",
        "                    assignments[fl]['assigned_departments'].add(blk_dept)\n",
        "                    if category == 'WE':\n",
        "                        assignments[fl]['WE_area'] += blk_area\n",
        "                    elif category == 'US':\n",
        "                        assignments[fl]['US_area'] += blk_area\n",
        "                    elif category == 'Support':\n",
        "                        assignments[fl]['Support_area'] += blk_area\n",
        "                    elif category == 'Speciality':\n",
        "                        assignments[fl]['Speciality_area'] += blk_area\n",
        "                    assigned_counts[fl] += 1\n",
        "                    placed = True\n",
        "                    break\n",
        "\n",
        "            if not placed:\n",
        "                # Try fallback random floors\n",
        "                fallback = floors.copy()\n",
        "                random.shuffle(fallback)\n",
        "                for fl in fallback:\n",
        "                    if (assignments[fl]['remaining_area']   >= blk_area  and\n",
        "    assignments[fl]['remaining_capacity'] >= blk_capacity):\n",
        "\n",
        "                        assignments[fl]['assigned_blocks'].append(blk)\n",
        "                        assignments[fl]['remaining_area'] -= blk_area\n",
        "                        assignments[fl]['remaining_capacity'] -= blk_capacity\n",
        "                        assignments[fl]['assigned_departments'].add(blk_dept)\n",
        "                        if category == 'WE':\n",
        "                            assignments[fl]['WE_area'] += blk_area\n",
        "                        elif category == 'US':\n",
        "                            assignments[fl]['US_area'] += blk_area\n",
        "                        elif category == 'Support':\n",
        "                            assignments[fl]['Support_area'] += blk_area\n",
        "                        elif category == 'Speciality':\n",
        "                            assignments[fl]['Speciality_area'] += blk_area\n",
        "                        assigned_counts[fl] += 1\n",
        "                        placed = True\n",
        "                        break\n",
        "\n",
        "            if not placed:\n",
        "                unassigned_blocks.append(blk)\n",
        "\n",
        "    # Final pass: try to place any still‐unassigned blocks\n",
        "    for blk in unassigned_blocks.copy():\n",
        "        ba = blk['Cumulative_Area_SQM']\n",
        "        bc = blk['Max_Occupancy_with_Capacity']\n",
        "        for fl in floors:\n",
        "            if (assignments[fl]['remaining_area']   >= ba  and\n",
        "                assignments[fl]['remaining_capacity'] >= bc):\n",
        "                assignments[fl]['assigned_blocks'].append(blk)\n",
        "                assignments[fl]['assigned_departments'].add(\n",
        "                    blk['Department_Sub_Department'].strip()\n",
        "                )\n",
        "                assignments[fl]['remaining_area']     -= ba\n",
        "                assignments[fl]['remaining_capacity'] -= bc\n",
        "                unassigned_blocks.remove(blk)\n",
        "                break\n",
        "\n",
        "\n",
        "\n",
        "    # 4.6 Phase 3: Build Output DataFrames\n",
        "\n",
        "    # 4.6.1 Detailed DataFrame\n",
        "    assignment_list = []\n",
        "    for fl, info in assignments.items():\n",
        "        for blk in info['assigned_blocks']:\n",
        "            assignment_list.append({\n",
        "                'Floor': fl,\n",
        "                'Department': blk['Department_Sub_Department'],\n",
        "                'Block_Name': blk['Block_Name'],\n",
        "                'Destination_Group': blk['Destination_Group'],\n",
        "                'SpaceMix': blk['SpaceMix_(ME_WE_US_Support_Speciality)'],\n",
        "                'Assigned_Area_SQM': blk['Cumulative_Area_SQM'],\n",
        "                'Max_Occupancy': blk['Max_Occupancy_with_Capacity']\n",
        "            })\n",
        "    detailed_df = pd.DataFrame(assignment_list)\n",
        "\n",
        "    # 4.6.2 Floor_Summary DataFrame\n",
        "     # 3.2 “Floor_Summary” DataFrame\n",
        "    floor_summary_df = (\n",
        "    detailed_df\n",
        "    .groupby('Floor')\n",
        "    .agg(\n",
        "        Assgn_Blocks=('Block_Name', 'count'),\n",
        "        Assgn_Area_SQM=('Assigned_Area_SQM', 'sum'),\n",
        "        Total_Occupancy=('Max_Occupancy', 'sum')\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "    # Merge with original floor input data to get base values\n",
        "    floor_input_subset = all_floor_data[[\n",
        "    'Name', 'Usable_Area_(SQM)', 'Max_Assignable_Floor_loading_Capacity'\n",
        "]].rename(columns={\n",
        "    'Name': 'Floor',\n",
        "    'Usable_Area_(SQM)': 'Input_Usable_Area_SQM',\n",
        "    'Max_Assignable_Floor_loading_Capacity': 'Input_Max_Capacity'\n",
        "})\n",
        "\n",
        "    # Join input data with summary\n",
        "    floor_summary_df = pd.merge(\n",
        "    floor_input_subset,\n",
        "    floor_summary_df,\n",
        "    on='Floor',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "    # Fill NaNs (if any floor didn't get any assignments)\n",
        "    floor_summary_df[[\n",
        "    'Assgn_Blocks',\n",
        "    'Assgn_Area_SQM',\n",
        "    'Total_Occupancy'\n",
        "]] = floor_summary_df[[\n",
        "    'Assgn_Blocks',\n",
        "    'Assgn_Area_SQM',\n",
        "    'Total_Occupancy'\n",
        "]].fillna(0)\n",
        "\n",
        "    # 3.3 “SpaceMix_By_Units” DataFrame\n",
        "    all_categories = ['ME', 'WE', 'US', 'Support', 'Speciality']\n",
        "    category_totals = {\n",
        "        cat: len(typical_blocks[\n",
        "            typical_blocks['SpaceMix_(ME_WE_US_Support_Speciality)'].str.strip() == cat\n",
        "        ])\n",
        "        for cat in all_categories\n",
        "    }\n",
        "\n",
        "    rows = []\n",
        "    for fl, info in assignments.items():\n",
        "        counts = {cat: 0 for cat in all_categories}\n",
        "        for blk in info['assigned_blocks']:\n",
        "            cat = blk['SpaceMix_(ME_WE_US_Support_Speciality)'].strip()\n",
        "            if cat in counts:\n",
        "                counts[cat] += 1\n",
        "        total_blocks_on_floor = sum(counts.values())\n",
        "\n",
        "        for cat in all_categories:\n",
        "            cnt = counts[cat]\n",
        "            # Percent of floor’s blocks\n",
        "            pct_of_floor = (cnt / total_blocks_on_floor * 100) if total_blocks_on_floor else 0.0\n",
        "            # Percent of overall blocks of that category\n",
        "            total_cat = category_totals[cat]\n",
        "            pct_overall = (cnt / total_cat * 100) if total_cat else 0.0\n",
        "\n",
        "            rows.append({\n",
        "                'Floor': fl,\n",
        "                'SpaceMix': cat,\n",
        "                '%spaceMix': round(pct_overall, 2)\n",
        "\n",
        "            })\n",
        "\n",
        "    space_mix_df = pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # 4.6.4 Unassigned DataFrame\n",
        "    unassigned_list = []\n",
        "    for blk in unassigned_blocks:\n",
        "        unassigned_list.append({\n",
        "            'Department': blk.get('Department_Sub_Department', ''),\n",
        "            'Block_Name': blk.get('Block_Name', ''),\n",
        "            'Destination_Group': blk.get('Destination_Group', ''),\n",
        "            'SpaceMix': blk.get('SpaceMix_(ME_WE_US_Support_Speciality)', ''),\n",
        "            'Area_SQM': blk.get('Cumulative_Area_SQM', 0),\n",
        "            'Max_Occupancy': blk.get('Max_Occupancy_with_Capacity', 0)\n",
        "        })\n",
        "    unassigned_df = pd.DataFrame(unassigned_list)\n",
        "\n",
        "    return detailed_df, floor_summary_df, space_mix_df, unassigned_df\n",
        "\n",
        "\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 5: Generate & Export Excel + CSV Files (including Unassigned)\n",
        "# ----------------------------------------\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 5: Run & Export (with sampling to minimize unassigned)\n",
        "# ----------------------------------------\n",
        "\n",
        "def best_plan(mode, trials=50):\n",
        "    best = None\n",
        "    best_unassigned = float('inf')\n",
        "    for seed in range(trials):\n",
        "        random.seed(seed)\n",
        "        det, fs, sm, un = run_stack_plan(mode)\n",
        "        if len(un) < best_unassigned:\n",
        "            best_unassigned = len(un)\n",
        "            best = (det, fs, sm, un)\n",
        "    return best\n",
        "\n",
        "central_detailed, central_floor_sum, central_space_mix, central_unassigned = best_plan('centralized', trials=50)\n",
        "semi_detailed,    semi_floor_sum,    semi_space_mix,    semi_unassigned    = best_plan('semi', trials=50)\n",
        "decentral_detailed, decentral_floor_sum, decentral_space_mix, decentral_unassigned = best_plan('decentralized', trials=50)\n",
        "\n",
        "\n",
        "# File names\n",
        "central_file    = 'stack_plan_centralized28.xlsx'\n",
        "semi_file       = 'stack_plan_semi_centralized28.xlsx'\n",
        "decentral_file  = 'stack_plan_decentralized28.xlsx'\n",
        "\n",
        "# --- ExcelWriter blocks with an extra sheet \"Unassigned\" ---\n",
        "with pd.ExcelWriter(central_file) as writer:\n",
        "    central_detailed.to_excel(writer, sheet_name='Detailed', index=False)\n",
        "    central_floor_sum.to_excel(writer, sheet_name='Floor_Summary', index=False)\n",
        "    central_space_mix.to_excel(writer, sheet_name='SpaceMix_By_Units', index=False)\n",
        "    central_unassigned.to_excel(writer, sheet_name='Unassigned', index=False)\n",
        "\n",
        "with pd.ExcelWriter(semi_file) as writer:\n",
        "    semi_detailed.to_excel(writer, sheet_name='Detailed', index=False)\n",
        "    semi_floor_sum.to_excel(writer, sheet_name='Floor_Summary', index=False)\n",
        "    semi_space_mix.to_excel(writer, sheet_name='SpaceMix_By_Units', index=False)\n",
        "    semi_unassigned.to_excel(writer, sheet_name='Unassigned', index=False)\n",
        "\n",
        "with pd.ExcelWriter(decentral_file) as writer:\n",
        "    decentral_detailed.to_excel(writer, sheet_name='Detailed', index=False)\n",
        "    decentral_floor_sum.to_excel(writer, sheet_name='Floor_Summary', index=False)\n",
        "    decentral_space_mix.to_excel(writer, sheet_name='SpaceMix_By_Units', index=False)\n",
        "    decentral_unassigned.to_excel(writer, sheet_name='Unassigned', index=False)\n",
        "\n",
        "print(\"✅ Generated three Excel outputs (each with an 'Unassigned' sheet):\")\n",
        "print(f\"    • {central_file}\")\n",
        "print(f\"    • {semi_file}\")\n",
        "print(f\"    • {decentral_file}\")\n",
        "\n",
        "\n",
        "# --- (Optional) Also export CSVs, if desired ---\n",
        "#central_detailed.to_csv('stack_plan_centralized_detailed.csv', index=False)\n",
        "#central_floor_sum.to_csv('stack_plan_centralized_floor_summary.csv', index=False)\n",
        "#central_space_mix.to_csv('stack_plan_centralized_space_mix.csv', index=False)\n",
        "#central_unassigned.to_csv('stack_plan_centralized_unassigned.csv', index=False)\n",
        "#\n",
        "#semi_detailed.to_csv('stack_plan_semi_centralized_detailed.csv', index=False)\n",
        "#semi_floor_sum.to_csv('stack_plan_semi_centralized_floor_summary.csv', index=False)\n",
        "#semi_space_mix.to_csv('stack_plan_semi_centralized_space_mix.csv', index=False)\n",
        "#semi_unassigned.to_csv('stack_plan_semi_centralized_unassigned.csv', index=False)\n",
        "#\n",
        "#decentral_detailed.to_csv('stack_plan_decentralized_detailed.csv', index=False)\n",
        "#decentral_floor_sum.to_csv('stack_plan_decentralized_floor_summary.csv', index=False)\n",
        "#decentral_space_mix.to_csv('stack_plan_decentralized_space_mix.csv', index=False)\n",
        "#decentral_unassigned.to_csv('stack_plan_decentralized_unassigned.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AR-1(2/07/2025)"
      ],
      "metadata": {
        "id": "JyCSfIyZl8Ja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import math\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 1: Load Input Sheets\n",
        "# ----------------------------------------\n",
        "\n",
        "excel_path = '/content/AR--1.xlsx'  # adjust if needed\n",
        "\n",
        "# 1.1 Floors sheet\n",
        "all_floor_data = pd.read_excel(excel_path, sheet_name='Program Table Input 2 - Floor')\n",
        "all_floor_data.columns = all_floor_data.columns.str.strip()\n",
        "\n",
        "# 1.2 Blocks sheet\n",
        "all_block_data = pd.read_excel(excel_path, sheet_name='Program Table Input 1 - Block')\n",
        "all_block_data.columns = all_block_data.columns.str.strip()\n",
        "\n",
        "# 1.3 Department Split sheet\n",
        "department_split_data = pd.read_excel(excel_path, sheet_name='Department Split', skiprows=1)\n",
        "department_split_data.columns = department_split_data.columns.str.strip()\n",
        "department_split_data = department_split_data.rename(\n",
        "    columns={'BU_Department_Sub-Department': 'Department_Sub-Department'}\n",
        ")\n",
        "\n",
        "# 1.4 Adjacency sheet\n",
        "xls = pd.ExcelFile(excel_path)\n",
        "adjacency_sheet_name = [name for name in xls.sheet_names if \"Adjacency\" in name][0]\n",
        "raw_data = xls.parse(adjacency_sheet_name, header=1, index_col=0)\n",
        "adjacency_data = raw_data.apply(pd.to_numeric, errors='coerce')\n",
        "adjacency_data.index = adjacency_data.index.str.strip()\n",
        "adjacency_data.columns = adjacency_data.columns.str.strip()\n",
        "\n",
        "# 1.5 De-Centralized Logic sheet\n",
        "df_logic = pd.read_excel(excel_path, sheet_name='De-Centralized Logic', header=None)\n",
        "De_Centralized_data = {}\n",
        "current_section = None\n",
        "for _, row in df_logic.iterrows():\n",
        "    first_cell = str(row[0]).strip() if pd.notna(row[0]) else \"\"\n",
        "    if first_cell in [\"Centralised\", \"Semi Centralized\", \"DeCentralised\"]:\n",
        "        current_section = first_cell\n",
        "        De_Centralized_data[current_section] = {\"Add\": 0}\n",
        "    elif current_section and first_cell == \"( Add into cetralised destination Block)\":\n",
        "        De_Centralized_data[current_section][\"Add\"] = int(row[1]) if pd.notna(row[1]) else 0\n",
        "\n",
        "# Ensure keys exist\n",
        "for key in [\"Centralised\", \"Semi Centralized\", \"DeCentralised\"]:\n",
        "    if key not in De_Centralized_data:\n",
        "        De_Centralized_data[key] = {\"Add\": 0}\n",
        "    elif \"Add\" not in De_Centralized_data[key]:\n",
        "        De_Centralized_data[key][\"Add\"] = 0\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 2: Preprocess Blocks & Department Split\n",
        "# ----------------------------------------\n",
        "\n",
        "# 2.1 Separate Destination vs. Typical blocks\n",
        "destination_blocks = all_block_data[all_block_data['Typical_Destination'].isin(['Destination', 'both'])].copy()\n",
        "typical_blocks = all_block_data[all_block_data['Typical_Destination'] == 'Typical'].copy()\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 3: Initialize Floor Assignments\n",
        "# ----------------------------------------\n",
        "\n",
        "def initialize_floor_assignments(floor_df):\n",
        "    \"\"\"\n",
        "    Returns a dict keyed by floor name. Each entry tracks:\n",
        "      - remaining_area\n",
        "      - remaining_capacity\n",
        "      - assigned_blocks      (list of block‐row dicts)\n",
        "      - assigned_departments (set of sub‐departments)\n",
        "      - ME_area, WE_area, US_area, Support_area, Speciality_area (floats)\n",
        "    \"\"\"\n",
        "    assignments = {}\n",
        "    for _, row in floor_df.iterrows():\n",
        "        floor = row['Name'].strip()\n",
        "        assignments[floor] = {\n",
        "            'remaining_area': row['Usable_Area'],\n",
        "            'remaining_capacity': row['Max_Assignable_Floor_loading_Capacity'],\n",
        "            'assigned_blocks': [],\n",
        "            'assigned_departments': set(),\n",
        "            'ME_area': 0.0,\n",
        "            'WE_area': 0.0,\n",
        "            'US_area': 0.0,\n",
        "            'Support_area': 0.0,\n",
        "            'Speciality_area': 0.0\n",
        "        }\n",
        "    return assignments\n",
        "\n",
        "floors = list(all_floor_data['Name'].str.strip())\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 4: Core Stacking Function\n",
        "# ----------------------------------------\n",
        "\n",
        "def run_stack_plan(mode):\n",
        "    \"\"\"\n",
        "    mode: 'centralized', 'semi', or 'decentralized'\n",
        "    Returns four DataFrames:\n",
        "      1) detailed_df      – each block's assigned floor, department, block name, destination group, space mix, area, occupancy\n",
        "      2) floor_summary_df – floor‐wise totals (block count, total area, total occupancy)\n",
        "      3) space_mix_df     – for each floor and each category {ME, WE, US, Support, Speciality}\n",
        "      4) unassigned_df    – blocks that couldn't be placed\n",
        "    \"\"\"\n",
        "    assignments = initialize_floor_assignments(all_floor_data)\n",
        "    unassigned_blocks = []\n",
        "\n",
        "    # Determine how many floors to use for destination blocks\n",
        "    def destination_floor_count():\n",
        "        if mode == 'centralized':\n",
        "            return 2\n",
        "        elif mode == 'semi':\n",
        "            return 2 + De_Centralized_data[\"Semi Centralized\"][\"Add\"]\n",
        "        elif mode == 'decentralized':\n",
        "            return 2 + De_Centralized_data[\"DeCentralised\"][\"Add\"]\n",
        "        else:\n",
        "            return 2\n",
        "\n",
        "    max_dest_floors = destination_floor_count()\n",
        "    # Cap at total number of floors\n",
        "    max_dest_floors = min(max_dest_floors, len(floors))\n",
        "\n",
        "    # Pre‐compute each group's total area and total capacity\n",
        "    dest_groups = {}\n",
        "    for _, blk in destination_blocks.iterrows():\n",
        "        grp = blk['Destination_Group']\n",
        "        if grp not in dest_groups:\n",
        "            dest_groups[grp] = {'blocks': [], 'total_area': 0.0, 'total_capacity': 0}\n",
        "        dest_groups[grp]['blocks'].append(blk.to_dict())\n",
        "        dest_groups[grp]['total_area'] += blk['Cumulative_Block_Circulation_Area']\n",
        "        dest_groups[grp]['total_capacity'] += blk['Max_Occupancy_with_Capacity']\n",
        "\n",
        "    # Phase 1: Assign destination groups\n",
        "    group_names = list(dest_groups.keys())\n",
        "    random.shuffle(group_names)\n",
        "    for grp in group_names:\n",
        "        info_grp = dest_groups[grp]\n",
        "        grp_area = info_grp['total_area']\n",
        "        grp_cap = info_grp['total_capacity']\n",
        "        placed_whole = False\n",
        "\n",
        "        # 4.2.a Attempt to place entire group on any of the first max_dest_floors\n",
        "        candidate_floors = floors[:max_dest_floors].copy()\n",
        "\n",
        "        for fl in candidate_floors:\n",
        "            if (assignments[fl]['remaining_area'] >= grp_area and\n",
        "                assignments[fl]['remaining_capacity'] >= grp_cap):\n",
        "                # Entire group fits here—place all blocks\n",
        "                for blk in info_grp['blocks']:\n",
        "                    assignments[fl]['assigned_blocks'].append(blk)\n",
        "                    assignments[fl]['assigned_departments'].add(\n",
        "                        blk['Department_Sub_Department']\n",
        "                    )\n",
        "                assignments[fl]['remaining_area'] -= grp_area\n",
        "                assignments[fl]['remaining_capacity'] -= grp_cap\n",
        "                placed_whole = True\n",
        "                break\n",
        "\n",
        "        # 4.2.b If not yet placed, try the remaining floors (beyond max_dest_floors)\n",
        "        if not placed_whole:\n",
        "            for fl in floors[max_dest_floors:]:\n",
        "                if (assignments[fl]['remaining_area'] >= grp_area and\n",
        "                    assignments[fl]['remaining_capacity'] >= grp_cap):\n",
        "                    for blk in info_grp['blocks']:\n",
        "                        assignments[fl]['assigned_blocks'].append(blk)\n",
        "                        assignments[fl]['assigned_departments'].add(\n",
        "                            blk['Department_Sub_Department'].strip()\n",
        "                        )\n",
        "                    assignments[fl]['remaining_area'] -= grp_area\n",
        "                    assignments[fl]['remaining_capacity'] -= grp_cap\n",
        "                    placed_whole = True\n",
        "                    break\n",
        "\n",
        "        # If still not placed as a whole, add to unassigned\n",
        "        if not placed_whole:\n",
        "            for blk in info_grp['blocks']:\n",
        "                unassigned_blocks.append(blk)\n",
        "\n",
        "    # Phase 2: Dynamic, per-block-type distribution of typical blocks across floors\n",
        "    # 2.1 Group typical blocks by Block_Name\n",
        "    typical_recs = typical_blocks.to_dict('records')\n",
        "    types = {}\n",
        "    for blk in typical_recs:\n",
        "        name = blk['Block_Name']\n",
        "        types.setdefault(name, []).append(blk)\n",
        "\n",
        "    # 2.2 Compute each floor's available area for typical\n",
        "    avail = {fl: assignments[fl]['remaining_area'] for fl in floors}\n",
        "    total_avail = sum(avail.values())\n",
        "\n",
        "    # 2.3 For each block type, compute target counts per floor\n",
        "    for btype, blks in types.items():\n",
        "        count = len(blks)\n",
        "        ratios = {fl: (avail[fl] / total_avail if total_avail > 0 else 1/len(floors))\n",
        "                  for fl in floors}\n",
        "        raw = {fl: ratios[fl] * count for fl in floors}\n",
        "        targ = {fl: int(round(raw[fl])) for fl in floors}\n",
        "\n",
        "        diff = count - sum(targ.values())\n",
        "        if diff:\n",
        "            frac = {fl: raw[fl] - math.floor(raw[fl]) for fl in floors}\n",
        "            if diff > 0:\n",
        "                for fl in sorted(floors, key=lambda x: frac[x], reverse=True)[:diff]:\n",
        "                    targ[fl] += 1\n",
        "            else:\n",
        "                for fl in sorted(floors, key=lambda x: frac[x])[: -diff]:\n",
        "                    targ[fl] -= 1\n",
        "\n",
        "        random.shuffle(blks)\n",
        "        idx = 0\n",
        "        for fl in floors:\n",
        "            for _ in range(targ[fl]):\n",
        "                if idx >= count:\n",
        "                    break\n",
        "                blk = blks[idx]\n",
        "                idx += 1\n",
        "                area = blk['Cumulative_Block_Circulation_Area']\n",
        "                cap = blk['Max_Occupancy_with_Capacity']\n",
        "                if (assignments[fl]['remaining_area'] >= area\n",
        "                    and assignments[fl]['remaining_capacity'] >= cap):\n",
        "                    assignments[fl]['assigned_blocks'].append(blk)\n",
        "                    assignments[fl]['assigned_departments'].add(\n",
        "                        blk['Department_Sub_Department']\n",
        "                    )\n",
        "                    assignments[fl]['remaining_area'] -= area\n",
        "                    assignments[fl]['remaining_capacity'] -= cap\n",
        "                else:\n",
        "                    unassigned_blocks.append(blk)\n",
        "\n",
        "        # any leftovers\n",
        "        while idx < count:\n",
        "            unassigned_blocks.append(blks[idx])\n",
        "            idx += 1\n",
        "\n",
        "    # Phase 3: Build Detailed & Summary DataFrames\n",
        "\n",
        "    # 3.1 Detailed DataFrame\n",
        "    assignment_list = []\n",
        "    for fl, info in assignments.items():\n",
        "        for blk in info['assigned_blocks']:\n",
        "            assignment_list.append({\n",
        "                'Block_id': blk['Block_ID'],\n",
        "                'Floor': fl,\n",
        "                'Department': blk['Department_Sub_Department'],\n",
        "                'Block_Name': blk['Block_Name'],\n",
        "                'Destination_Group': blk['Destination_Group'],\n",
        "                'SpaceMix': blk['SpaceMix_(ME_WE_US_Support_Speciality)'],\n",
        "                'Assigned_Area_SQM': blk['Cumulative_Block_Circulation_Area'],\n",
        "                'Max_Occupancy': blk['Max_Occupancy_with_Capacity']\n",
        "            })\n",
        "    detailed_df = pd.DataFrame(assignment_list)\n",
        "\n",
        "    # 3.2 Floor_Summary DataFrame\n",
        "    if not detailed_df.empty:\n",
        "        floor_summary_df = (\n",
        "            detailed_df\n",
        "            .groupby('Floor')\n",
        "            .agg(\n",
        "                Assgn_Blocks=('Block_Name', 'count'),\n",
        "                Assgn_Area_SQM=('Assigned_Area_SQM', 'sum'),\n",
        "                Total_Occupancy=('Max_Occupancy', 'sum')\n",
        "            )\n",
        "            .reset_index()\n",
        "        )\n",
        "    else:\n",
        "        floor_summary_df = pd.DataFrame(columns=['Floor', 'Assgn_Blocks', 'Assgn_Area_SQM', 'Total_Occupancy'])\n",
        "\n",
        "    # Merge with original floor input data to get base values\n",
        "    floor_input_subset = all_floor_data[[\n",
        "        'Name', 'Usable_Area', 'Max_Assignable_Floor_loading_Capacity'\n",
        "    ]].rename(columns={\n",
        "        'Name': 'Floor',\n",
        "        'Usable_Area': 'Input_Usable_Area',\n",
        "        'Max_Assignable_Floor_loading_Capacity': 'Input_Max_Capacity'\n",
        "    })\n",
        "\n",
        "    # Join input data with summary\n",
        "    floor_summary_df = pd.merge(\n",
        "        floor_input_subset,\n",
        "        floor_summary_df,\n",
        "        on='Floor',\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    # Fill NaNs (if any floor didn't get any assignments)\n",
        "    floor_summary_df[[\n",
        "        'Assgn_Blocks',\n",
        "        'Assgn_Area_SQM',\n",
        "        'Total_Occupancy'\n",
        "    ]] = floor_summary_df[[\n",
        "        'Assgn_Blocks',\n",
        "        'Assgn_Area_SQM',\n",
        "        'Total_Occupancy'\n",
        "    ]].fillna(0)\n",
        "\n",
        "    # 3.3 SpaceMix_By_Units DataFrame\n",
        "    all_categories = ['ME', 'WE', 'US', 'Support', 'Speciality']\n",
        "    category_totals = {\n",
        "        cat: len(typical_blocks[\n",
        "            typical_blocks['SpaceMix_(ME_WE_US_Support_Speciality)'].str.strip() == cat\n",
        "        ])\n",
        "        for cat in all_categories\n",
        "    }\n",
        "\n",
        "    rows = []\n",
        "    for fl, info in assignments.items():\n",
        "        counts = {cat: 0 for cat in all_categories}\n",
        "        for blk in info['assigned_blocks']:\n",
        "            cat = blk['SpaceMix_(ME_WE_US_Support_Speciality)'].strip()\n",
        "            if cat in counts:\n",
        "                counts[cat] += 1\n",
        "        total_blocks_on_floor = sum(counts.values())\n",
        "\n",
        "        for cat in all_categories:\n",
        "            cnt = counts[cat]\n",
        "            pct_of_floor = (cnt / total_blocks_on_floor * 100) if total_blocks_on_floor else 0.0\n",
        "            total_cat = category_totals[cat]\n",
        "            pct_overall = (cnt / total_cat * 100) if total_cat else 0.0\n",
        "\n",
        "            rows.append({\n",
        "                'Floor': fl,\n",
        "                'SpaceMix': cat,\n",
        "                'Unit_Count_on_Floor': cnt,\n",
        "                'Pct_of_Floor_UC': round(pct_of_floor, 2),\n",
        "                'Pct_of_Overall_UC': round(pct_overall, 2)\n",
        "            })\n",
        "\n",
        "    space_mix_df = pd.DataFrame(rows)\n",
        "\n",
        "    # 3.4 Unassigned DataFrame\n",
        "    unassigned_list = []\n",
        "    for blk in unassigned_blocks:\n",
        "        unassigned_list.append({\n",
        "            'Department': blk.get('Department_Sub_Department', ''),\n",
        "            'Block_Name': blk.get('Block_Name', ''),\n",
        "            'Destination_Group': blk.get('Destination_Group', ''),\n",
        "            'SpaceMix': blk.get('SpaceMix_(ME_WE_US_Support_Speciality)', ''),\n",
        "            'Area_SQM': blk.get('Cumulative_Block_Circulation_Area', 0),\n",
        "            'Max_Occupancy': blk.get('Max_Occupancy_with_Capacity', 0)\n",
        "        })\n",
        "    unassigned_df = pd.DataFrame(unassigned_list)\n",
        "\n",
        "    return detailed_df, floor_summary_df, space_mix_df, unassigned_df\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 5: Generate & Export Three Excel Files\n",
        "# ----------------------------------------\n",
        "\n",
        "# Generate plans\n",
        "central_detailed, central_floor_sum, central_space_mix, central_unassigned = run_stack_plan('centralized')\n",
        "semi_detailed, semi_floor_sum, semi_space_mix, semi_unassigned = run_stack_plan('semi')\n",
        "decentral_detailed, decentral_floor_sum, decentral_space_mix, decentral_unassigned = run_stack_plan('decentralized')\n",
        "\n",
        "# Build dynamic summary for each plan\n",
        "def make_typical_summary(detailed_df):\n",
        "    \"\"\"Create typical block summary\"\"\"\n",
        "    if detailed_df.empty:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Get all typical block types from the original data\n",
        "    types = typical_blocks['Block_Name'].dropna().str.strip().unique()\n",
        "\n",
        "    # Filter detailed_df for typical blocks only\n",
        "    typical_detailed = detailed_df[detailed_df['Block_Name'].isin(types)]\n",
        "\n",
        "    if typical_detailed.empty:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Group by Block_Name and Floor\n",
        "    df = (typical_detailed\n",
        "          .groupby(['Block_Name', 'Floor'])\n",
        "          .size()\n",
        "          .unstack(fill_value=0))\n",
        "\n",
        "    df['Total_Assigned'] = df.sum(axis=1)\n",
        "\n",
        "    # Calculate assignment ratio for each block type\n",
        "    for block_type in df.index:\n",
        "        total_blocks_of_type = len(typical_blocks[typical_blocks['Block_Name'].str.strip() == block_type])\n",
        "        df.loc[block_type, 'Assignment_Ratio'] = round(df.loc[block_type, 'Total_Assigned'] / total_blocks_of_type, 3) if total_blocks_of_type > 0 else 0\n",
        "\n",
        "    return df\n",
        "\n",
        "# Create summaries\n",
        "central_summary = make_typical_summary(central_detailed)\n",
        "semi_summary = make_typical_summary(semi_detailed)\n",
        "decentral_summary = make_typical_summary(decentral_detailed)\n",
        "\n",
        "# Export to Excel files\n",
        "# Centralized\n",
        "with pd.ExcelWriter('stack_plan_centralized.xlsx') as writer:\n",
        "    central_detailed.to_excel(writer, sheet_name='Detailed', index=False)\n",
        "    central_floor_sum.to_excel(writer, sheet_name='Floor_Summary', index=False)\n",
        "    central_space_mix.to_excel(writer, sheet_name='SpaceMix_By_Units', index=False)\n",
        "    central_unassigned.to_excel(writer, sheet_name='Unassigned', index=False)\n",
        "    central_summary.to_excel(writer, sheet_name='Typical_Summary')\n",
        "\n",
        "# Semi‐centralized\n",
        "with pd.ExcelWriter('stack_plan_semi_centralized.xlsx') as writer:\n",
        "    semi_detailed.to_excel(writer, sheet_name='Detailed', index=False)\n",
        "    semi_floor_sum.to_excel(writer, sheet_name='Floor_Summary', index=False)\n",
        "    semi_space_mix.to_excel(writer, sheet_name='SpaceMix_By_Units', index=False)\n",
        "    semi_unassigned.to_excel(writer, sheet_name='Unassigned', index=False)\n",
        "    semi_summary.to_excel(writer, sheet_name='Typical_Summary')\n",
        "\n",
        "# Decentralized\n",
        "with pd.ExcelWriter('stack_plan_decentralized.xlsx') as writer:\n",
        "    decentral_detailed.to_excel(writer, sheet_name='Detailed', index=False)\n",
        "    decentral_floor_sum.to_excel(writer, sheet_name='Floor_Summary', index=False)\n",
        "    decentral_space_mix.to_excel(writer, sheet_name='SpaceMix_By_Units', index=False)\n",
        "    decentral_unassigned.to_excel(writer, sheet_name='Unassigned', index=False)\n",
        "    decentral_summary.to_excel(writer, sheet_name='Typical_Summary')\n",
        "\n",
        "print(\"✅ Generated three Excel outputs:\")\n",
        "print(\"    • stack_plan_centralized.xlsx\")\n",
        "print(\"    • stack_plan_semi_centralized.xlsx\")\n",
        "print(\"    • stack_plan_decentralized.xlsx\")"
      ],
      "metadata": {
        "id": "lTP2otYSmAb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BR-1"
      ],
      "metadata": {
        "id": "86-z5YyjKjta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import math\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 1: Load All Input Sheets from AR-1.xlsx\n",
        "\n",
        "# ----------------------------------------\n",
        "\n",
        "excel_path = '/content/BR-1.xlsx'  # ← adjust if needed\n",
        "\n",
        "# 1.1 Floors sheet (skip the first row)\n",
        "all_floor_data = pd.read_excel(\n",
        "    excel_path,\n",
        "    sheet_name='Program Table Input 2 - Floor',\n",
        "    skiprows=0  # Don't skip header\n",
        ")\n",
        "all_floor_data.columns = all_floor_data.columns.str.strip()\n",
        "print(all_floor_data.columns.tolist())\n",
        "\n",
        "all_floor_data = all_floor_data.rename(columns={\n",
        "    all_floor_data.columns[0]: 'Name',\n",
        "    all_floor_data.columns[1]: 'Usable_Area_(SQM)',\n",
        "    all_floor_data.columns[2]: 'Max_Assignable_Floor_loading_Capacity'\n",
        "})\n",
        "print(all_floor_data.columns.tolist())\n",
        "# Coerce floor‐area and capacity to numeric\n",
        "all_floor_data['Usable_Area_(SQM)'] = pd.to_numeric(\n",
        "    all_floor_data['Usable_Area_(SQM)'], errors='raise'\n",
        ")\n",
        "all_floor_data['Max_Assignable_Floor_loading_Capacity'] = pd.to_numeric(\n",
        "    all_floor_data['Max_Assignable_Floor_loading_Capacity'], errors='raise'\n",
        ")\n",
        "\n",
        "# 1.2 Blocks sheet\n",
        "all_block_data = pd.read_excel(\n",
        "    excel_path,\n",
        "    sheet_name='Program Table Input 1 - Block'\n",
        ")\n",
        "all_block_data.columns = all_block_data.columns.str.strip()\n",
        "\n",
        "# Ensure these columns are numeric\n",
        "all_block_data['Cumulative_Area_SQM'] = pd.to_numeric(\n",
        "    all_block_data['Cumulative_Block_Circulation_Area'], errors='raise'\n",
        ")\n",
        "all_block_data['Max_Occupancy_with_Capacity'] = pd.to_numeric(\n",
        "    all_block_data['Max_Occupancy_with_Capacity'], errors='raise'\n",
        ")\n",
        "\n",
        "# 1.3 Department Split sheet (skip header row)\n",
        "department_split_data = pd.read_excel(\n",
        "    excel_path,\n",
        "    sheet_name='Department Split',\n",
        "    skiprows=1 # Skip the first row which is not the header\n",
        ")\n",
        "# Set column names explicitly based on expected structure\n",
        "department_split_data.columns = [\n",
        "    'Department_Sub-Department',\n",
        "    'Splittable',\n",
        "    'Min_%_of_Block_per_department',\n",
        "    'Unknown1', # Assuming these are the extra columns\n",
        "    'Unknown2'\n",
        "]\n",
        "department_split_data = department_split_data[['Department_Sub-Department', 'Splittable', 'Min_%_of_Block_per_department']].copy()\n",
        "\n",
        "department_split_data.columns = department_split_data.columns.str.strip()\n",
        "print(department_split_data.columns.tolist())\n",
        "# Build dictionaries:\n",
        "dept_splittable = department_split_data.set_index('Department_Sub-Department')['Splittable'].to_dict()\n",
        "dept_min_pct    = department_split_data.set_index('Department_Sub-Department')['Min_%_of_Block_per_department'].to_dict()\n",
        "\n",
        "# 1.4 Min%Split sheet (not used below but loaded)\n",
        "min_split_data = pd.read_excel(\n",
        "    excel_path,\n",
        "    sheet_name='Min % Split'\n",
        ")\n",
        "min_split_data.columns = min_split_data.columns.str.strip()\n",
        "\n",
        "# 1.5 Adjacency sheet\n",
        "xls = pd.ExcelFile(excel_path)\n",
        "adjacency_sheet_name = [name for name in xls.sheet_names if \"Adjacency\" in name][0]\n",
        "raw_data = xls.parse(adjacency_sheet_name, header=1, index_col=0)\n",
        "adjacency_data = raw_data.apply(pd.to_numeric, errors='coerce')\n",
        "adjacency_data.index   = adjacency_data.index.str.strip()\n",
        "adjacency_data.columns = adjacency_data.columns.str.strip()\n",
        "\n",
        "# 1.6 De-Centralized Logic sheet\n",
        "df_logic = pd.read_excel(\n",
        "    excel_path,\n",
        "    sheet_name='De-Centralized Logic',\n",
        "    header=None\n",
        ")\n",
        "De_Centralized_data = {}\n",
        "current_section = None\n",
        "for _, row in df_logic.iterrows():\n",
        "    first_cell = str(row[0]).strip() if pd.notna(row[0]) else \"\"\n",
        "    if first_cell in [\"Centralised\", \"Semi Centralized\", \"DeCentralised\"]:\n",
        "        current_section = first_cell\n",
        "        De_Centralized_data[current_section] = {\"Add\": 0}\n",
        "    elif current_section and first_cell == \"( Add into cetralised destination Block)\":\n",
        "        De_Centralized_data[current_section][\"Add\"] = int(row[1]) if pd.notna(row[1]) else 0\n",
        "\n",
        "for key in [\"Centralised\", \"Semi Centralized\", \"DeCentralised\"]:\n",
        "    if key not in De_Centralized_data:\n",
        "        De_Centralized_data[key] = {\"Add\": 0}\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 2: Preprocess Blocks & Department Split\n",
        "# ----------------------------------------\n",
        "\n",
        "# 2.2 Separate Destination vs. Typical blocks\n",
        "destination_blocks = all_block_data[\n",
        "    all_block_data['Typical_Destination'] == 'Destination'\n",
        "].copy()\n",
        "typical_blocks = all_block_data[\n",
        "    all_block_data['Typical_Destination'] == 'Typical'\n",
        "].copy()\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 3: Initialize Floor Assignments\n",
        "# ----------------------------------------\n",
        "\n",
        "def initialize_floor_assignments(floor_df):\n",
        "    \"\"\"\n",
        "    Returns a dict keyed by floor name. Each entry has:\n",
        "      - remaining_area\n",
        "      - remaining_capacity\n",
        "      - assigned_blocks      (list of block‐row dicts)\n",
        "      - assigned_departments (set of sub‐departments)\n",
        "      - ME_area, WE_area, US_area, Support_area, Speciality_area (floats)\n",
        "    \"\"\"\n",
        "    assignments = {}\n",
        "    for _, row in floor_df.iterrows():\n",
        "        floor = row['Name'].strip()\n",
        "        assignments[floor] = {\n",
        "            'remaining_area': row['Usable_Area_(SQM)'],\n",
        "            'remaining_capacity': row['Max_Assignable_Floor_loading_Capacity'], # Fixed: removed .iloc[0]\n",
        "            'assigned_blocks': [],\n",
        "            'assigned_departments': set(),\n",
        "            'ME_area': 0.0,\n",
        "            'WE_area': 0.0,\n",
        "            'US_area': 0.0,\n",
        "            'Support_area': 0.0,\n",
        "            'Speciality_area': 0.0\n",
        "        }\n",
        "    return assignments\n",
        "\n",
        "floors = list(initialize_floor_assignments(all_floor_data).keys())\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 4: Core Stacking Function (with updated department splitting logic)\n",
        "# ----------------------------------------\n",
        "\n",
        "def run_stack_plan(mode):\n",
        "    \"\"\"\n",
        "    mode: 'centralized', 'semi', or 'decentralized'\n",
        "    Returns four DataFrames:\n",
        "      detailed_df      – block‐to‐floor assignments\n",
        "      floor_summary_df – floor totals (count, area, occupancy)\n",
        "      space_mix_df     – for each floor & category {ME, WE, US, Support, Speciality}:\n",
        "                          Unit_Count_on_Floor,\n",
        "                          Pct_of_Floor_UC,\n",
        "                          Pct_of_Overall_UC\n",
        "      unassigned_df    – blocks that couldn't be placed\n",
        "    \"\"\"\n",
        "    assignments = initialize_floor_assignments(all_floor_data)\n",
        "    unassigned_blocks = []\n",
        "\n",
        "    # 4.1 Determine how many floors to use for destination blocks\n",
        "    def destination_floor_count():\n",
        "        if mode == 'centralized':\n",
        "            return 2\n",
        "        elif mode == 'semi':\n",
        "            return 2 + De_Centralized_data[\"Semi Centralized\"][\"Add\"]\n",
        "        elif mode == 'decentralized':\n",
        "            return 2 + De_Centralized_data[\"DeCentralised\"][\"Add\"]\n",
        "        else:\n",
        "            return 2\n",
        "\n",
        "    max_dest_floors = min(destination_floor_count(), len(floors))\n",
        "\n",
        "    # 4.2 Group destination blocks by Destination_Group\n",
        "    dest_groups = {}\n",
        "    for _, blk in destination_blocks.iterrows():\n",
        "        grp = blk['Destination_Group']\n",
        "        if grp not in dest_groups:\n",
        "            dest_groups[grp] = {'blocks': [], 'total_area': 0.0, 'total_capacity': 0}\n",
        "        dest_groups[grp]['blocks'].append(blk.to_dict())\n",
        "        dest_groups[grp]['total_area'] += blk['Cumulative_Area_SQM']\n",
        "        dest_groups[grp]['total_capacity'] += blk['Max_Occupancy_with_Capacity']\n",
        "\n",
        "    # Phase 1: Assign destination groups (try whole‐group first; if that fails, split across floors)\n",
        "    group_names = list(dest_groups.keys())\n",
        "    random.shuffle(group_names)\n",
        "    for grp in group_names:\n",
        "        info_grp = dest_groups[grp]\n",
        "        grp_area = info_grp['total_area']\n",
        "        grp_cap  = info_grp['total_capacity']\n",
        "        placed_whole = False\n",
        "\n",
        "        # 4.2.a Attempt to place entire group on any of the first max_dest_floors\n",
        "        candidate_floors = floors[:max_dest_floors].copy()\n",
        "\n",
        "        for fl in candidate_floors:\n",
        "            if (assignments[fl]['remaining_area'] >= grp_area and\n",
        "                assignments[fl]['remaining_capacity'] >= grp_cap):\n",
        "                # Entire group fits here—place all blocks\n",
        "                for blk in info_grp['blocks']:\n",
        "                    assignments[fl]['assigned_blocks'].append(blk)\n",
        "                    assignments[fl]['assigned_departments'].add(\n",
        "                        blk['Department_Sub_Department']\n",
        "                    )\n",
        "                assignments[fl]['remaining_area'] -= grp_area\n",
        "                assignments[fl]['remaining_capacity'] -= grp_cap\n",
        "                placed_whole = True\n",
        "                break\n",
        "\n",
        "        # 4.2.b If not yet placed, try the remaining floors (beyond max_dest_floors)\n",
        "        if not placed_whole:\n",
        "            for fl in floors[max_dest_floors:]:\n",
        "                if (assignments[fl]['remaining_area'] >= grp_area and\n",
        "                    assignments[fl]['remaining_capacity'] >= grp_cap):\n",
        "                    for blk in info_grp['blocks']:\n",
        "                        assignments[fl]['assigned_blocks'].append(blk)\n",
        "                        assignments[fl]['assigned_departments'].add(\n",
        "                            blk['Department_Sub_Department'].strip()\n",
        "                        )\n",
        "                    assignments[fl]['remaining_area'] -= grp_area\n",
        "                    assignments[fl]['remaining_capacity'] -= grp_cap\n",
        "                    placed_whole = True\n",
        "                    break\n",
        "\n",
        "        # 4.2.c If still not placed as a whole, split the group block‐by‐block across floors\n",
        "        if not placed_whole:\n",
        "            total_remaining_area = sum(assignments[f]['remaining_area'] for f in floors)\n",
        "            if total_remaining_area >= grp_area:\n",
        "                # Try placing group by removing the largest blocks one-by-one until remaining can be placed whole\n",
        "                blocks_sorted = sorted(info_grp['blocks'], key=lambda b: b['Cumulative_Area_SQM'], reverse=True)\n",
        "                removed_blocks = []\n",
        "                trial_blocks = blocks_sorted.copy()\n",
        "\n",
        "                while trial_blocks:\n",
        "                    trial_area = sum(b['Cumulative_Area_SQM'] for b in trial_blocks)\n",
        "                    trial_capacity = sum(b['Max_Occupancy_with_Capacity'] for b in trial_blocks)\n",
        "\n",
        "                    # Try to place this reduced group\n",
        "                    floor_combination = []\n",
        "                    temp_assignments = {f: assignments[f].copy() for f in floors}\n",
        "                    temp_floors_by_space = sorted(floors, key=lambda f: assignments[f]['remaining_area'], reverse=True)\n",
        "\n",
        "                    temp_success = True\n",
        "                    for blk in trial_blocks:\n",
        "                        blk_area = blk['Cumulative_Area_SQM']\n",
        "                        blk_capacity = blk['Max_Occupancy_with_Capacity']\n",
        "                        placed_block = False\n",
        "\n",
        "                        for fl in temp_floors_by_space:\n",
        "                            if (temp_assignments[fl]['remaining_area'] >= blk_area and\n",
        "                                temp_assignments[fl]['remaining_capacity'] >= blk_capacity):\n",
        "                                temp_assignments[fl]['remaining_area'] -= blk_area\n",
        "                                temp_assignments[fl]['remaining_capacity'] -= blk_capacity\n",
        "                                floor_combination.append((blk, fl))\n",
        "                                placed_block = True\n",
        "                                break\n",
        "\n",
        "                        if not placed_block:\n",
        "                            temp_success = False\n",
        "                            break\n",
        "\n",
        "                    if temp_success:\n",
        "                        # Apply final assignment for successfully placed trial blocks\n",
        "                        for blk, fl in floor_combination:\n",
        "                            assignments[fl]['assigned_blocks'].append(blk)\n",
        "                            assignments[fl]['assigned_departments'].add(blk['Department_Sub_Department'].strip())\n",
        "                            assignments[fl]['remaining_area'] -= blk['Cumulative_Area_SQM']\n",
        "                            assignments[fl]['remaining_capacity'] -= blk['Max_Occupancy_with_Capacity']\n",
        "                        placed_whole = True\n",
        "                        break\n",
        "                    else:\n",
        "                        # Remove one largest block and retry\n",
        "                        removed_blocks.append(trial_blocks.pop(0))\n",
        "\n",
        "                # Place removed blocks one-by-one\n",
        "                for blk in removed_blocks:\n",
        "                    blk_area = blk['Cumulative_Area_SQM']\n",
        "                    blk_capacity = blk['Max_Occupancy_with_Capacity']\n",
        "                    placed_block = False\n",
        "                    floors_by_space = sorted(floors, key=lambda f: assignments[f]['remaining_area'], reverse=True)\n",
        "\n",
        "                    for fl in floors_by_space:\n",
        "                        if (assignments[fl]['remaining_area'] >= blk_area and\n",
        "                            assignments[fl]['remaining_capacity'] >= blk_capacity):\n",
        "                            assignments[fl]['assigned_blocks'].append(blk)\n",
        "                            assignments[fl]['assigned_departments'].add(blk['Department_Sub_Department'].strip())\n",
        "                            assignments[fl]['remaining_area'] -= blk_area\n",
        "                            assignments[fl]['remaining_capacity'] -= blk_capacity\n",
        "                            placed_block = True\n",
        "                            break\n",
        "\n",
        "                    if not placed_block:\n",
        "                        unassigned_blocks.append(blk)\n",
        "            else:\n",
        "                # Even splitting won't fit all blocks, place block-by-block\n",
        "                for blk in sorted(info_grp['blocks'], key=lambda b: b['Cumulative_Area_SQM'], reverse=True):\n",
        "                    blk_area     = blk['Cumulative_Area_SQM']\n",
        "                    blk_capacity = blk['Max_Occupancy_with_Capacity']\n",
        "                    placed_block = False\n",
        "\n",
        "                    floors_by_space = sorted(floors, key=lambda f: assignments[f]['remaining_area'], reverse=True)\n",
        "                    for fl in floors_by_space:\n",
        "                        if (assignments[fl]['remaining_area'] >= blk_area and\n",
        "                            assignments[fl]['remaining_capacity'] >= blk_capacity):\n",
        "                            assignments[fl]['assigned_blocks'].append(blk)\n",
        "                            assignments[fl]['assigned_departments'].add(blk['Department_Sub_Department'].strip())\n",
        "                            assignments[fl]['remaining_area'] -= blk_area\n",
        "                            assignments[fl]['remaining_capacity'] -= blk_capacity\n",
        "                            placed_block = True\n",
        "                            break\n",
        "\n",
        "                    if not placed_block:\n",
        "                        unassigned_blocks.append(blk)\n",
        "\n",
        "    # ----------------------------------------\n",
        "    # Phase 2: Handle typical blocks with UPDATED department‐splittable logic\n",
        "    # ----------------------------------------\n",
        "\n",
        "    # 4.3 Categorize typical blocks by department splittable values\n",
        "    # Categories:\n",
        "    # - not_splittable: splittable values 1 and 0.75\n",
        "    # - order_by_area: splittable value 0 (assign in descending order of remaining floor area)\n",
        "    # - fully_splittable: splittable value -1 (can be split across all floors)\n",
        "\n",
        "    def add_space_mix_area(floor, block, area):\n",
        "        \"\"\"Helper function to add area to appropriate space mix category\"\"\"\n",
        "        cat = block['SpaceMix_(ME_WE_US_Support_Speciality)'].strip()\n",
        "        if cat == 'ME':\n",
        "            assignments[floor]['ME_area'] += area\n",
        "        elif cat == 'WE':\n",
        "            assignments[floor]['WE_area'] += area\n",
        "        elif cat == 'US':\n",
        "            assignments[floor]['US_area'] += area\n",
        "        elif cat.lower() == 'support':\n",
        "            assignments[floor]['Support_area'] += area\n",
        "        elif cat.lower() == 'speciality':\n",
        "            assignments[floor]['Speciality_area'] += area\n",
        "\n",
        "    not_splittable_groups = {}  # dept -> [blocks] for splittable in [1, 0.75]\n",
        "    order_by_area_groups = {}   # dept -> [blocks] for splittable = 0\n",
        "    fully_splittable_blocks = []  # individual blocks for splittable = -1\n",
        "\n",
        "    for blk in typical_blocks.to_dict('records'):\n",
        "        dept = blk['Department_Sub_Department'].strip()\n",
        "        # Default to -1 (fully splittable) if missing\n",
        "        spl = dept_splittable.get(dept, -1)\n",
        "\n",
        "        if spl in [1, 0.75]:\n",
        "            # Not splittable - keep department together\n",
        "            not_splittable_groups.setdefault(dept, []).append(blk)\n",
        "        elif spl == 0:\n",
        "            # Assign in descending order of remaining floor area\n",
        "            order_by_area_groups.setdefault(dept, []).append(blk)\n",
        "        else:  # spl == -1 or any other value\n",
        "            # Fully splittable across all floors\n",
        "            fully_splittable_blocks.append(blk)\n",
        "\n",
        "    # 4.4 Phase 2A: Assign not_splittable departments (splittable = 1 or 0.75)\n",
        "    print(f\"Processing {len(not_splittable_groups)} not-splittable departments...\")\n",
        "    for dept, blocks_list in not_splittable_groups.items():\n",
        "        total_area = sum(b['Cumulative_Area_SQM'] for b in blocks_list)\n",
        "        total_cap  = sum(b['Max_Occupancy_with_Capacity'] for b in blocks_list)\n",
        "        placed = False\n",
        "\n",
        "        # Try to place entire department on one floor\n",
        "        candidate_floors = sorted(\n",
        "            floors,\n",
        "            key=lambda f: assignments[f]['remaining_area'],\n",
        "            reverse=True\n",
        "        )\n",
        "        for fl in candidate_floors:\n",
        "            if (assignments[fl]['remaining_area'] >= total_area and\n",
        "                assignments[fl]['remaining_capacity'] >= total_cap):\n",
        "                for blk in blocks_list:\n",
        "                    assignments[fl]['assigned_blocks'].append(blk)\n",
        "                    assignments[fl]['assigned_departments'].add(dept)\n",
        "                    add_space_mix_area(fl, blk, blk['Cumulative_Area_SQM'])\n",
        "                assignments[fl]['remaining_area'] -= total_area\n",
        "                assignments[fl]['remaining_capacity'] -= total_cap\n",
        "                placed = True\n",
        "                print(f\"  Placed dept {dept} on floor {fl}\")\n",
        "                break\n",
        "\n",
        "        if not placed:\n",
        "            # Mark entire department group as unassigned\n",
        "            unassigned_blocks.extend(blocks_list)\n",
        "            print(f\"  Could not place dept {dept} - added to unassigned\")\n",
        "\n",
        "    # 4.5 Phase 2B: Assign order_by_area departments (splittable = 0)\n",
        "    print(f\"Processing {len(order_by_area_groups)} order-by-area departments...\")\n",
        "    for dept, blocks_list in order_by_area_groups.items():\n",
        "        total_area = sum(b['Cumulative_Area_SQM'] for b in blocks_list)\n",
        "        total_cap  = sum(b['Max_Occupancy_with_Capacity'] for b in blocks_list)\n",
        "\n",
        "        # First try to place entire department on one floor\n",
        "        placed_whole = False\n",
        "        floors_by_remaining_area = sorted(\n",
        "            floors,\n",
        "            key=lambda f: assignments[f]['remaining_area'],\n",
        "            reverse=True\n",
        "        )\n",
        "\n",
        "        for fl in floors_by_remaining_area:\n",
        "            if (assignments[fl]['remaining_area'] >= total_area and\n",
        "                assignments[fl]['remaining_capacity'] >= total_cap):\n",
        "                for blk in blocks_list:\n",
        "                    assignments[fl]['assigned_blocks'].append(blk)\n",
        "                    assignments[fl]['assigned_departments'].add(dept)\n",
        "                    add_space_mix_area(fl, blk, blk['Cumulative_Area_SQM'])\n",
        "                assignments[fl]['remaining_area'] -= total_area\n",
        "                assignments[fl]['remaining_capacity'] -= total_cap\n",
        "                placed_whole = True\n",
        "                print(f\"  Placed dept {dept} entirely on floor {fl}\")\n",
        "                break\n",
        "\n",
        "        # If can't place whole department, place blocks individually in descending order of floor area\n",
        "        if not placed_whole:\n",
        "            print(f\"  Splitting dept {dept} across floors...\")\n",
        "            for blk in blocks_list:\n",
        "                blk_area = blk['Cumulative_Area_SQM']\n",
        "                blk_capacity = blk['Max_Occupancy_with_Capacity']\n",
        "                placed_block = False\n",
        "\n",
        "                # Get current floor order by remaining area (descending)\n",
        "                floors_by_remaining_area = sorted(\n",
        "                    floors,\n",
        "                    key=lambda f: assignments[f]['remaining_area'],\n",
        "                    reverse=True\n",
        "                )\n",
        "\n",
        "                for fl in floors_by_remaining_area:\n",
        "                    if (assignments[fl]['remaining_area'] >= blk_area and\n",
        "                        assignments[fl]['remaining_capacity'] >= blk_capacity):\n",
        "                        assignments[fl]['assigned_blocks'].append(blk)\n",
        "                        assignments[fl]['assigned_departments'].add(dept)\n",
        "                        add_space_mix_area(fl, blk, blk_area)\n",
        "                        assignments[fl]['remaining_area'] -= blk_area\n",
        "                        assignments[fl]['remaining_capacity'] -= blk_capacity\n",
        "                        placed_block = True\n",
        "                        break\n",
        "\n",
        "                if not placed_block:\n",
        "                    unassigned_blocks.append(blk)\n",
        "\n",
        "    # 4.6 Phase 2C: Assign fully_splittable blocks (splittable = -1) using space-mix proportional logic\n",
        "    print(f\"Processing {len(fully_splittable_blocks)} fully-splittable blocks...\")\n",
        "\n",
        "    # 4.6.a Assign all ME blocks randomly first\n",
        "    me_blocks = [\n",
        "        blk for blk in fully_splittable_blocks\n",
        "        if blk['SpaceMix_(ME_WE_US_Support_Speciality)'].strip() == 'ME'\n",
        "    ]\n",
        "    random.shuffle(me_blocks)\n",
        "    for blk in me_blocks:\n",
        "        blk_area     = blk['Cumulative_Area_SQM']\n",
        "        blk_capacity = blk['Max_Occupancy_with_Capacity']\n",
        "        blk_dept     = blk['Department_Sub_Department'].strip()\n",
        "\n",
        "        candidate_floors = floors.copy()\n",
        "        random.shuffle(candidate_floors)\n",
        "        placed = False\n",
        "        for fl in candidate_floors:\n",
        "            if (assignments[fl]['remaining_area'] >= blk_area and\n",
        "                assignments[fl]['remaining_capacity'] >= blk_capacity):\n",
        "                assignments[fl]['assigned_blocks'].append(blk)\n",
        "                assignments[fl]['remaining_area'] -= blk_area\n",
        "                assignments[fl]['remaining_capacity'] -= blk_capacity\n",
        "                assignments[fl]['assigned_departments'].add(blk_dept)\n",
        "                assignments[fl]['ME_area'] += blk_area\n",
        "                placed = True\n",
        "                break\n",
        "        if not placed:\n",
        "            unassigned_blocks.append(blk)\n",
        "\n",
        "    # 4.6.b Compute ME distribution per floor (unit counts)\n",
        "    me_count_per_floor = {fl: 0 for fl in floors}\n",
        "    for fl, info in assignments.items():\n",
        "        me_count_per_floor[fl] = sum(\n",
        "            1 for blk in info['assigned_blocks']\n",
        "            if blk['SpaceMix_(ME_WE_US_Support_Speciality)'].strip() == 'ME'\n",
        "        )\n",
        "    total_me = sum(me_count_per_floor.values())\n",
        "    if total_me == 0:\n",
        "        me_frac_per_floor = {fl: 1 / len(floors) for fl in floors}\n",
        "    else:\n",
        "        me_frac_per_floor = {\n",
        "            fl: me_count_per_floor[fl] / total_me for fl in floors\n",
        "        }\n",
        "\n",
        "    # 4.6.c Assign other categories proportionally\n",
        "    other_categories = ['WE', 'US', 'Support', 'Speciality']\n",
        "    for category in other_categories:\n",
        "        cat_blocks = [\n",
        "            blk for blk in fully_splittable_blocks\n",
        "            if blk['SpaceMix_(ME_WE_US_Support_Speciality)'].strip() == category\n",
        "        ]\n",
        "        total_cat = len(cat_blocks)\n",
        "        if total_cat == 0:\n",
        "            continue\n",
        "\n",
        "        raw_targets = {fl: me_frac_per_floor[fl] * total_cat for fl in floors}\n",
        "        target_counts = {fl: int(round(raw_targets[fl])) for fl in floors}\n",
        "\n",
        "        diff = total_cat - sum(target_counts.values())\n",
        "        if diff != 0:\n",
        "            fractional_parts = {\n",
        "                fl: raw_targets[fl] - math.floor(raw_targets[fl]) for fl in floors\n",
        "            }\n",
        "            if diff > 0:\n",
        "                for fl in sorted(floors, key=lambda x: fractional_parts[x], reverse=True)[:diff]:\n",
        "                    target_counts[fl] += 1\n",
        "            else:\n",
        "                for fl in sorted(floors, key=lambda x: fractional_parts[x])[: -diff]:\n",
        "                    target_counts[fl] -= 1\n",
        "\n",
        "        random.shuffle(cat_blocks)\n",
        "        assigned_counts = {fl: 0 for fl in floors}\n",
        "\n",
        "        for blk in cat_blocks:\n",
        "            blk_area     = blk['Cumulative_Area_SQM']\n",
        "            blk_capacity = blk['Max_Occupancy_with_Capacity']\n",
        "            blk_dept     = blk['Department_Sub_Department'].strip()\n",
        "\n",
        "            deficits = {fl: target_counts[fl] - assigned_counts[fl] for fl in floors}\n",
        "            floors_with_deficit = [fl for fl, d in deficits.items() if d > 0]\n",
        "            if floors_with_deficit:\n",
        "                candidate_floors = sorted(\n",
        "                    floors_with_deficit,\n",
        "                    key=lambda x: deficits[x],\n",
        "                    reverse=True\n",
        "                )\n",
        "            else:\n",
        "                candidate_floors = floors.copy()\n",
        "\n",
        "            placed = False\n",
        "            for fl in candidate_floors:\n",
        "                if (assignments[fl]['remaining_area'] >= blk_area and\n",
        "                    assignments[fl]['remaining_capacity'] >= blk_capacity):\n",
        "                    assignments[fl]['assigned_blocks'].append(blk)\n",
        "                    assignments[fl]['remaining_area'] -= blk_area\n",
        "                    assignments[fl]['remaining_capacity'] -= blk_capacity\n",
        "                    assignments[fl]['assigned_departments'].add(blk_dept)\n",
        "                    add_space_mix_area(fl, blk, blk_area)\n",
        "                    assigned_counts[fl] += 1\n",
        "                    placed = True\n",
        "                    break\n",
        "\n",
        "            if not placed:\n",
        "                # Try fallback random floors\n",
        "                fallback = floors.copy()\n",
        "                random.shuffle(fallback)\n",
        "                for fl in fallback:\n",
        "                    if (assignments[fl]['remaining_area'] >= blk_area and\n",
        "                        assignments[fl]['remaining_capacity'] >= blk_capacity):\n",
        "                        assignments[fl]['assigned_blocks'].append(blk)\n",
        "                        assignments[fl]['remaining_area'] -= blk_area\n",
        "                        assignments[fl]['remaining_capacity'] -= blk_capacity\n",
        "                        assignments[fl]['assigned_departments'].add(blk_dept)\n",
        "                        add_space_mix_area(fl, blk, blk_area)\n",
        "                        assigned_counts[fl] += 1\n",
        "                        placed = True\n",
        "                        break\n",
        "\n",
        "            if not placed:\n",
        "                unassigned_blocks.append(blk)\n",
        "\n",
        "    # Final pass: try to place any still‐unassigned blocks\n",
        "    for blk in unassigned_blocks.copy():\n",
        "        ba = blk['Cumulative_Area_SQM']\n",
        "        bc = blk['Max_Occupancy_with_Capacity']\n",
        "        for fl in floors:\n",
        "            if (assignments[fl]['remaining_area'] >= ba and\n",
        "                assignments[fl]['remaining_capacity'] >= bc):\n",
        "                assignments[fl]['assigned_blocks'].append(blk)\n",
        "                assignments[fl]['assigned_departments'].add(\n",
        "                    blk['Department_Sub_Department'].strip()\n",
        "                )\n",
        "                assignments[fl]['remaining_area'] -= ba\n",
        "                assignments[fl]['remaining_capacity'] -= bc\n",
        "                unassigned_blocks.remove(blk)\n",
        "                break\n",
        "\n",
        "    # 4.6 Phase 3: Build Output DataFrames\n",
        "\n",
        "    # 4.6.1 Detailed DataFrame\n",
        "    assignment_list = []\n",
        "    for fl, info in assignments.items():\n",
        "        for blk in info['assigned_blocks']:\n",
        "            assignment_list.append({\n",
        "                'Floor': fl,\n",
        "                'Department': blk['Department_Sub_Department'],\n",
        "                'Block_Name': blk['Block_Name'],\n",
        "                'Destination_Group': blk['Destination_Group'],\n",
        "                'SpaceMix': blk['SpaceMix_(ME_WE_US_Support_Speciality)'],\n",
        "                'Assigned_Area_SQM': blk['Cumulative_Area_SQM'],\n",
        "                'Max_Occupancy': blk['Max_Occupancy_with_Capacity']\n",
        "            })\n",
        "    detailed_df = pd.DataFrame(assignment_list)\n",
        "\n",
        "    # 4.6.2 Floor_Summary DataFrame\n",
        "     # 3.2 “Floor_Summary” DataFrame\n",
        "    floor_summary_df = (\n",
        "    detailed_df\n",
        "    .groupby('Floor')\n",
        "    .agg(\n",
        "        Assgn_Blocks=('Block_Name', 'count'),\n",
        "        Assgn_Area_SQM=('Assigned_Area_SQM', 'sum'),\n",
        "        Total_Occupancy=('Max_Occupancy', 'sum')\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "    # Merge with original floor input data to get base values\n",
        "    floor_input_subset = all_floor_data[[\n",
        "    'Name', 'Usable_Area_(SQM)', 'Max_Assignable_Floor_loading_Capacity'\n",
        "]].rename(columns={\n",
        "    'Name': 'Floor',\n",
        "    'Usable_Area_(SQM)': 'Input_Usable_Area_SQM',\n",
        "    'Max_Assignable_Floor_loading_Capacity': 'Input_Max_Capacity'\n",
        "})\n",
        "\n",
        "    # Join input data with summary\n",
        "    floor_summary_df = pd.merge(\n",
        "    floor_input_subset,\n",
        "    floor_summary_df,\n",
        "    on='Floor',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "    # Fill NaNs (if any floor didn't get any assignments)\n",
        "    floor_summary_df[[\n",
        "    'Assgn_Blocks',\n",
        "    'Assgn_Area_SQM',\n",
        "    'Total_Occupancy'\n",
        "]] = floor_summary_df[[\n",
        "    'Assgn_Blocks',\n",
        "    'Assgn_Area_SQM',\n",
        "    'Total_Occupancy'\n",
        "]].fillna(0)\n",
        "\n",
        "    # 3.3 “SpaceMix_By_Units” DataFrame\n",
        "    all_categories = ['ME', 'WE', 'US', 'Support', 'Speciality']\n",
        "    category_totals = {\n",
        "        cat: len(typical_blocks[\n",
        "            typical_blocks['SpaceMix_(ME_WE_US_Support_Speciality)'].str.strip() == cat\n",
        "        ])\n",
        "        for cat in all_categories\n",
        "    }\n",
        "\n",
        "    rows = []\n",
        "    for fl, info in assignments.items():\n",
        "        counts = {cat: 0 for cat in all_categories}\n",
        "        for blk in info['assigned_blocks']:\n",
        "            cat = blk['SpaceMix_(ME_WE_US_Support_Speciality)'].strip()\n",
        "            if cat in counts:\n",
        "                counts[cat] += 1\n",
        "        total_blocks_on_floor = sum(counts.values())\n",
        "\n",
        "        for cat in all_categories:\n",
        "            cnt = counts[cat]\n",
        "            # Percent of floor’s blocks\n",
        "            pct_of_floor = (cnt / total_blocks_on_floor * 100) if total_blocks_on_floor else 0.0\n",
        "            # Percent of overall blocks of that category\n",
        "            total_cat = category_totals[cat]\n",
        "            pct_overall = (cnt / total_cat * 100) if total_cat else 0.0\n",
        "\n",
        "            rows.append({\n",
        "                'Floor': fl,\n",
        "                'SpaceMix': cat,\n",
        "                '%spaceMix': round(pct_overall, 2)\n",
        "\n",
        "            })\n",
        "\n",
        "    space_mix_df = pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # 4.6.4 Unassigned DataFrame\n",
        "    unassigned_list = []\n",
        "    for blk in unassigned_blocks:\n",
        "        unassigned_list.append({\n",
        "            'Department': blk.get('Department_Sub_Department', ''),\n",
        "            'Block_Name': blk.get('Block_Name', ''),\n",
        "            'Destination_Group': blk.get('Destination_Group', ''),\n",
        "            'SpaceMix': blk.get('SpaceMix_(ME_WE_US_Support_Speciality)', ''),\n",
        "            'Area_SQM': blk.get('Cumulative_Area_SQM', 0),\n",
        "            'Max_Occupancy': blk.get('Max_Occupancy_with_Capacity', 0)\n",
        "        })\n",
        "    unassigned_df = pd.DataFrame(unassigned_list)\n",
        "\n",
        "    return detailed_df, floor_summary_df, space_mix_df, unassigned_df\n",
        "\n",
        "\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 5: Generate & Export Excel + CSV Files (including Unassigned)\n",
        "# ----------------------------------------\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 5: Run & Export (with sampling to minimize unassigned)\n",
        "# ----------------------------------------\n",
        "\n",
        "def best_plan(mode, trials=50):\n",
        "    best = None\n",
        "    best_unassigned = float('inf')\n",
        "    for seed in range(trials):\n",
        "        random.seed(seed)\n",
        "        det, fs, sm, un = run_stack_plan(mode)\n",
        "        if len(un) < best_unassigned:\n",
        "            best_unassigned = len(un)\n",
        "            best = (det, fs, sm, un)\n",
        "    return best\n",
        "\n",
        "central_detailed, central_floor_sum, central_space_mix, central_unassigned = best_plan('centralized', trials=50)\n",
        "semi_detailed,    semi_floor_sum,    semi_space_mix,    semi_unassigned    = best_plan('semi', trials=50)\n",
        "decentral_detailed, decentral_floor_sum, decentral_space_mix, decentral_unassigned = best_plan('decentralized', trials=50)\n",
        "\n",
        "\n",
        "# File names\n",
        "central_file    = 'stack_plan_centralized28.xlsx'\n",
        "semi_file       = 'stack_plan_semi_centralized28.xlsx'\n",
        "decentral_file  = 'stack_plan_decentralized28.xlsx'\n",
        "\n",
        "# --- ExcelWriter blocks with an extra sheet \"Unassigned\" ---\n",
        "with pd.ExcelWriter(central_file) as writer:\n",
        "    central_detailed.to_excel(writer, sheet_name='Detailed', index=False)\n",
        "    central_floor_sum.to_excel(writer, sheet_name='Floor_Summary', index=False)\n",
        "    central_space_mix.to_excel(writer, sheet_name='SpaceMix_By_Units', index=False)\n",
        "    central_unassigned.to_excel(writer, sheet_name='Unassigned', index=False)\n",
        "\n",
        "with pd.ExcelWriter(semi_file) as writer:\n",
        "    semi_detailed.to_excel(writer, sheet_name='Detailed', index=False)\n",
        "    semi_floor_sum.to_excel(writer, sheet_name='Floor_Summary', index=False)\n",
        "    semi_space_mix.to_excel(writer, sheet_name='SpaceMix_By_Units', index=False)\n",
        "    semi_unassigned.to_excel(writer, sheet_name='Unassigned', index=False)\n",
        "\n",
        "with pd.ExcelWriter(decentral_file) as writer:\n",
        "    decentral_detailed.to_excel(writer, sheet_name='Detailed', index=False)\n",
        "    decentral_floor_sum.to_excel(writer, sheet_name='Floor_Summary', index=False)\n",
        "    decentral_space_mix.to_excel(writer, sheet_name='SpaceMix_By_Units', index=False)\n",
        "    decentral_unassigned.to_excel(writer, sheet_name='Unassigned', index=False)\n",
        "\n",
        "print(\"✅ Generated three Excel outputs (each with an 'Unassigned' sheet):\")\n",
        "print(f\"    • {central_file}\")\n",
        "print(f\"    • {semi_file}\")\n",
        "print(f\"    • {decentral_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFd2FgvTKfZL",
        "outputId": "07e07498-e309-4854-b680-29f57cf8a298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Name', 'Usable Area', 'Max Assignable Floor loading Capacity']\n",
            "['Name', 'Usable_Area_(SQM)', 'Max_Assignable_Floor_loading_Capacity']\n",
            "['Department_Sub-Department', 'Splittable', 'Min_%_of_Block_per_department']\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "Processing 0 not-splittable departments...\n",
            "Processing 0 order-by-area departments...\n",
            "Processing 2573 fully-splittable blocks...\n",
            "✅ Generated three Excel outputs (each with an 'Unassigned' sheet):\n",
            "    • stack_plan_centralized28.xlsx\n",
            "    • stack_plan_semi_centralized28.xlsx\n",
            "    • stack_plan_decentralized28.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AR-1(06/07/2025)"
      ],
      "metadata": {
        "id": "USGdsEWnZgNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import PyPDF2\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 1: Load Input Sheets\n",
        "# ----------------------------------------\n",
        "\n",
        "excel_path = '/content/A- R1.xlsx'  # adjust if needed\n",
        "\n",
        "# 1.1 Floors sheet\n",
        "all_floor_data = pd.read_excel(excel_path, sheet_name='Program Table Input 2 - Floor')\n",
        "all_floor_data.columns = all_floor_data.columns.str.strip()\n",
        "\n",
        "# 1.2 Blocks sheet\n",
        "all_block_data = pd.read_excel(excel_path, sheet_name='Program Table Input 1 - Block')\n",
        "all_block_data.columns = all_block_data.columns.str.strip()\n",
        "\n",
        "# 1.3 Department Split sheet\n",
        "department_split_data = pd.read_excel(excel_path, sheet_name='Department Split', skiprows=1)\n",
        "department_split_data.columns = department_split_data.columns.str.strip()\n",
        "department_split_data = department_split_data.rename(\n",
        "    columns={'BU_Department_Sub-Department': 'Department_Sub-Department'}\n",
        ")\n",
        "\n",
        "# 1.4 Adjacency sheet (original)\n",
        "xls = pd.ExcelFile(excel_path)\n",
        "adjacency_sheet_name = [name for name in xls.sheet_names if \"Adjacency\" in name][0]\n",
        "raw_data = xls.parse(adjacency_sheet_name, header=1, index_col=0)\n",
        "adjacency_data = raw_data.apply(pd.to_numeric, errors='coerce')\n",
        "adjacency_data.index = adjacency_data.index.str.strip()\n",
        "adjacency_data.columns = adjacency_data.columns.str.strip()\n",
        "\n",
        "# 1.5 De-Centralized Logic sheet\n",
        "df_logic = pd.read_excel(excel_path, sheet_name='De-Centralized Logic', header=None)\n",
        "De_Centralized_data = {}\n",
        "current_section = None\n",
        "for _, row in df_logic.iterrows():\n",
        "    first_cell = str(row[0]).strip() if pd.notna(row[0]) else \"\"\n",
        "    if first_cell in [\"Centralised\", \"Semi Centralized\", \"DeCentralised\"]:\n",
        "        current_section = first_cell\n",
        "        De_Centralized_data[current_section] = {\"Add\": 0}\n",
        "    elif current_section and first_cell == \"( Add into cetralised destination Block)\":\n",
        "        De_Centralized_data[current_section][\"Add\"] = int(row[1]) if pd.notna(row[1]) else 0\n",
        "\n",
        "# Ensure keys exist\n",
        "for key in [\"Centralised\", \"Semi Centralized\", \"DeCentralised\"]:\n",
        "    if key not in De_Centralized_data:\n",
        "        De_Centralized_data[key] = {\"Add\": 0}\n",
        "    elif \"Add\" not in De_Centralized_data[key]:\n",
        "        De_Centralized_data[key][\"Add\"] = 0\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 2: Read Adjacency Rules from PDF Files\n",
        "# ----------------------------------------\n",
        "\n",
        "def read_pdf_adjacency_rules(pdf_path):\n",
        "    \"\"\"Read adjacency rules from PDF file\"\"\"\n",
        "    adjacency_rules = {}\n",
        "\n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            pdf_reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page in pdf_reader.pages:\n",
        "                text += page.extract_text()\n",
        "\n",
        "        # Parse the text to extract adjacency rules\n",
        "        lines = text.split('\\n')\n",
        "        current_dept = None\n",
        "        current_block = None\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            # Look for department_subdepartment pattern\n",
        "            if '_' in line and any(keyword in line for keyword in ['Common', 'External']):\n",
        "                parts = line.split()\n",
        "                if len(parts) >= 2:\n",
        "                    dept_sub = parts[0]\n",
        "                    block_name = ' '.join(parts[1:])\n",
        "                    current_dept = dept_sub\n",
        "                    current_block = block_name\n",
        "\n",
        "                    if current_dept not in adjacency_rules:\n",
        "                        adjacency_rules[current_dept] = {}\n",
        "                    if current_block not in adjacency_rules[current_dept]:\n",
        "                        adjacency_rules[current_dept][current_block] = {}\n",
        "\n",
        "            # Look for priority values (1, 0.3, 0)\n",
        "            elif current_dept and current_block:\n",
        "                numbers = re.findall(r'\\b(?:1|0\\.3|0)\\b', line)\n",
        "                if numbers:\n",
        "                    # Store priority values\n",
        "                    adjacency_rules[current_dept][current_block]['priorities'] = [float(n) for n in numbers]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading PDF {pdf_path}: {e}\")\n",
        "\n",
        "    return adjacency_rules\n",
        "\n",
        "# Read adjacency rules from both PDF files\n",
        "adjacency_rules_1 = read_pdf_adjacency_rules('Auto Stacking Input New Build - Case Study A- R1 (with block instances) - Split priority-destination grouping.pdf')\n",
        "adjacency_rules_2 = read_pdf_adjacency_rules('Auto Stacking Input New Build - Case Study A- R1 (with block instances) - Adjacency-destination grouping.pdf')\n",
        "\n",
        "# Combine adjacency rules\n",
        "combined_adjacency_rules = {}\n",
        "for rules in [adjacency_rules_1, adjacency_rules_2]:\n",
        "    for dept, blocks in rules.items():\n",
        "        if dept not in combined_adjacency_rules:\n",
        "            combined_adjacency_rules[dept] = {}\n",
        "        combined_adjacency_rules[dept].update(blocks)\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 3: Create Destination Groups Based on Adjacency Rules\n",
        "# ----------------------------------------\n",
        "\n",
        "def create_adjacency_based_destination_groups(block_data, adjacency_rules):\n",
        "    \"\"\"\n",
        "    Create destination groups based on adjacency rules instead of block information\n",
        "    \"\"\"\n",
        "    # Create a copy of block data to work with\n",
        "    blocks_df = block_data.copy()\n",
        "\n",
        "    # Initialize Destination_Group and Adjacency_Priority columns\n",
        "    blocks_df['Destination_Group'] = None\n",
        "    blocks_df['Adjacency_Priority'] = None\n",
        "\n",
        "    # Initialize destination group counter\n",
        "    group_counter = 1\n",
        "\n",
        "    # Dictionary to store formed groups\n",
        "    destination_groups = {}\n",
        "\n",
        "    # Process blocks marked as destination or both\n",
        "    destination_blocks = blocks_df[blocks_df['Typical_Destination'].isin(['Destination', 'both'])].copy()\n",
        "\n",
        "    # Create adjacency-based groups\n",
        "    for dept_sub, dept_rules in adjacency_rules.items():\n",
        "        # Find blocks belonging to this department\n",
        "        dept_blocks = destination_blocks[\n",
        "            destination_blocks['Department_Sub_Department'].str.strip() == dept_sub\n",
        "        ].copy()\n",
        "\n",
        "        if dept_blocks.empty:\n",
        "            continue\n",
        "\n",
        "        # Group blocks based on adjacency rules and priorities\n",
        "        for block_name, rule_info in dept_rules.items():\n",
        "            # Find blocks with this block name\n",
        "            matching_blocks = dept_blocks[\n",
        "                dept_blocks['Block_Name'].str.strip() == block_name\n",
        "            ].copy()\n",
        "\n",
        "            if matching_blocks.empty:\n",
        "                continue\n",
        "\n",
        "            # Get priority for this block type\n",
        "            priorities = rule_info.get('priorities', [0])\n",
        "            max_priority = max(priorities) if priorities else 0\n",
        "\n",
        "            # Create group name based on department and priority\n",
        "            if max_priority >= 1.0:\n",
        "                group_name = f\"High_Priority_Group_{group_counter}\"\n",
        "            elif max_priority >= 0.3:\n",
        "                group_name = f\"Medium_Priority_Group_{group_counter}\"\n",
        "            else:\n",
        "                group_name = f\"Low_Priority_Group_{group_counter}\"\n",
        "\n",
        "            # Assign all matching blocks to this group\n",
        "            for idx in matching_blocks.index:\n",
        "                blocks_df.loc[idx, 'Destination_Group'] = group_name\n",
        "                blocks_df.loc[idx, 'Adjacency_Priority'] = max_priority\n",
        "\n",
        "            # Store group information\n",
        "            if group_name not in destination_groups:\n",
        "                destination_groups[group_name] = {\n",
        "                    'blocks': [],\n",
        "                    'department': dept_sub,\n",
        "                    'priority': max_priority,\n",
        "                    'total_area': 0,\n",
        "                    'total_capacity': 0\n",
        "                }\n",
        "\n",
        "            for _, block in matching_blocks.iterrows():\n",
        "                destination_groups[group_name]['blocks'].append(block.to_dict())\n",
        "                destination_groups[group_name]['total_area'] += block['Cumulative_Block_Circulation_Area']\n",
        "                destination_groups[group_name]['total_capacity'] += block['Max_Occupancy_with_Capacity']\n",
        "\n",
        "            group_counter += 1\n",
        "\n",
        "    # Handle any remaining destination blocks that weren't matched\n",
        "    unmatched_dest_blocks = destination_blocks[\n",
        "        ~destination_blocks.index.isin(blocks_df[blocks_df['Destination_Group'].notna()].index)\n",
        "    ]\n",
        "\n",
        "    if not unmatched_dest_blocks.empty:\n",
        "        # Group unmatched blocks by department\n",
        "        for dept in unmatched_dest_blocks['Department_Sub_Department'].unique():\n",
        "            dept_unmatched = unmatched_dest_blocks[\n",
        "                unmatched_dest_blocks['Department_Sub_Department'] == dept\n",
        "            ]\n",
        "\n",
        "            group_name = f\"Unmatched_Dest_Group_{group_counter}\"\n",
        "\n",
        "            for idx in dept_unmatched.index:\n",
        "                blocks_df.loc[idx, 'Destination_Group'] = group_name\n",
        "                blocks_df.loc[idx, 'Adjacency_Priority'] = 0\n",
        "\n",
        "            destination_groups[group_name] = {\n",
        "                'blocks': dept_unmatched.to_dict('records'),\n",
        "                'department': dept,\n",
        "                'priority': 0,\n",
        "                'total_area': dept_unmatched['Cumulative_Block_Circulation_Area'].sum(),\n",
        "                'total_capacity': dept_unmatched['Max_Occupancy_with_Capacity'].sum()\n",
        "            }\n",
        "\n",
        "            group_counter += 1\n",
        "\n",
        "\n",
        "    # Handle typical blocks (ensure they don't have Destination_Group or Adjacency_Priority set)\n",
        "    typical_blocks_indices = blocks_df[blocks_df['Typical_Destination'] == 'Typical'].index\n",
        "    blocks_df.loc[typical_blocks_indices, 'Destination_Group'] = None\n",
        "    blocks_df.loc[typical_blocks_indices, 'Adjacency_Priority'] = None\n",
        "\n",
        "\n",
        "    return blocks_df, destination_groups\n",
        "\n",
        "# Apply adjacency-based grouping\n",
        "all_block_data, adjacency_destination_groups = create_adjacency_based_destination_groups(\n",
        "    all_block_data, combined_adjacency_rules\n",
        ")\n",
        "\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 4: Preprocess Blocks & Department Split\n",
        "# ----------------------------------------\n",
        "\n",
        "# 4.1 Separate Destination vs. Typical blocks (now with adjacency-based groups)\n",
        "destination_blocks = all_block_data[all_block_data['Typical_Destination'].isin(['Destination', 'both'])].copy()\n",
        "typical_blocks = all_block_data[all_block_data['Typical_Destination'] == 'Typical'].copy()\n",
        "\n",
        "# 4.2 Add priority information to destination blocks\n",
        "destination_blocks['Priority'] = destination_blocks.get('Adjacency_Priority', 0)\n",
        "\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 5: Initialize Floor Assignments\n",
        "# ----------------------------------------\n",
        "\n",
        "def initialize_floor_assignments(floor_df):\n",
        "    \"\"\"\n",
        "    Returns a dict keyed by floor name. Each entry tracks:\n",
        "      - remaining_area\n",
        "      - remaining_capacity\n",
        "      - assigned_blocks      (list of block‐row dicts)\n",
        "      - assigned_departments (set of sub‐departments)\n",
        "      - ME_area, WE_area, US_area, Support_area, Speciality_area (floats)\n",
        "    \"\"\"\n",
        "    assignments = {}\n",
        "    for _, row in floor_df.iterrows():\n",
        "        floor = row['Name'].strip()\n",
        "        assignments[floor] = {\n",
        "            'remaining_area': row['Usable_Area'],\n",
        "            'remaining_capacity': row['Max_Assignable_Floor_loading_Capacity'],\n",
        "            'assigned_blocks': [],\n",
        "            'assigned_departments': set(),\n",
        "            'ME_area': 0.0,\n",
        "            'WE_area': 0.0,\n",
        "            'US_area': 0.0,\n",
        "            'Support_area': 0.0,\n",
        "            'Speciality_area': 0.0\n",
        "        }\n",
        "    return assignments\n",
        "\n",
        "floors = list(all_floor_data['Name'].str.strip())\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 6: Enhanced Destination Block Assignment with Adjacency-Based Grouping\n",
        "# ----------------------------------------\n",
        "\n",
        "def can_groups_be_adjacent(group1_info, group2_info):\n",
        "    \"\"\"Check if two groups can be adjacent based on adjacency rules and priorities\"\"\"\n",
        "    # High priority groups (1.0) can be adjacent to any group\n",
        "    if group1_info['priority'] >= 1.0 or group2_info['priority'] >= 1.0:\n",
        "        return True\n",
        "\n",
        "    # Medium priority groups (0.3) can be adjacent to medium and high priority groups\n",
        "    if (group1_info['priority'] >= 0.3 and group2_info['priority'] >= 0.3):\n",
        "        return True\n",
        "\n",
        "    # Same department groups can be adjacent\n",
        "    if group1_info['department'] == group2_info['department']:\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "def split_destination_groups_by_adjacency(destination_groups):\n",
        "    \"\"\"Split destination groups based on adjacency rules and priorities\"\"\"\n",
        "    # Sort groups by priority (highest first)\n",
        "    sorted_groups = sorted(\n",
        "        destination_groups.items(),\n",
        "        key=lambda x: x[1]['priority'],\n",
        "        reverse=True\n",
        "    )\n",
        "\n",
        "    subgroups = []\n",
        "    current_subgroup = []\n",
        "\n",
        "    for group_name, group_info in sorted_groups:\n",
        "        if not current_subgroup:\n",
        "            current_subgroup.append((group_name, group_info))\n",
        "        else:\n",
        "            # Check if this group can be adjacent to any group in current subgroup\n",
        "            can_group = False\n",
        "            for existing_group_name, existing_group_info in current_subgroup:\n",
        "                if can_groups_be_adjacent(group_info, existing_group_info):\n",
        "                    can_group = True\n",
        "                    break\n",
        "\n",
        "            if can_group:\n",
        "                current_subgroup.append((group_name, group_info))\n",
        "            else:\n",
        "                # Start new subgroup\n",
        "                if current_subgroup:\n",
        "                    subgroups.append(current_subgroup)\n",
        "                current_subgroup = [(group_name, group_info)]\n",
        "\n",
        "    # Add the last subgroup\n",
        "    if current_subgroup:\n",
        "        subgroups.append(current_subgroup)\n",
        "\n",
        "    return subgroups\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 7: Core Stacking Function with Adjacency-Based Destination Logic\n",
        "# ----------------------------------------\n",
        "\n",
        "def run_stack_plan(mode, priority_category='ME'):\n",
        "    \"\"\"\n",
        "    mode: 'centralized', 'semi', or 'decentralized'\n",
        "    priority_category: 'ME', 'WE', 'US', or 'Support' - which category to prioritize in typical block assignment\n",
        "    Returns four DataFrames:\n",
        "      1) detailed_df      – each block's assigned floor, department, block name, destination group, space mix, area, occupancy\n",
        "      2) floor_summary_df – floor‐wise totals (block count, total area, total occupancy)\n",
        "      3) space_mix_df     – for each floor and each category {ME, WE, US, Support, Speciality}\n",
        "      4) unassigned_df    – blocks that couldn't be placed\n",
        "    \"\"\"\n",
        "    assignments = initialize_floor_assignments(all_floor_data)\n",
        "    unassigned_blocks = []\n",
        "\n",
        "    # Determine how many floors to use for destination blocks\n",
        "    def destination_floor_count():\n",
        "        if mode == 'centralized':\n",
        "            return 2\n",
        "        elif mode == 'semi':\n",
        "            return 2 + De_Centralized_data[\"Semi Centralized\"][\"Add\"]\n",
        "        elif mode == 'decentralized':\n",
        "            return 2 + De_Centralized_data[\"DeCentralised\"][\"Add\"]\n",
        "        else:\n",
        "            return 2\n",
        "\n",
        "    max_dest_floors = destination_floor_count()\n",
        "    # Cap at total number of floors\n",
        "    max_dest_floors = min(max_dest_floors, len(floors))\n",
        "\n",
        "    # Phase 1: Adjacency-Based Destination Group Assignment\n",
        "    # Sort destination groups by priority (highest first)\n",
        "    sorted_dest_groups = sorted(\n",
        "        adjacency_destination_groups.items(),\n",
        "        key=lambda item: item[1].get('priority', 0),  # Default to 0 if priority is missing\n",
        "        reverse=True\n",
        "    )\n",
        "\n",
        "    for grp_name, grp_info in sorted_dest_groups:\n",
        "        grp_area = grp_info['total_area']\n",
        "        grp_cap = grp_info['total_capacity']\n",
        "        placed_whole = False\n",
        "\n",
        "        # Try to place entire group first on designated destination floors\n",
        "        candidate_floors = floors[:max_dest_floors].copy()\n",
        "\n",
        "        for fl in candidate_floors:\n",
        "            if (assignments[fl]['remaining_area'] >= grp_area and\n",
        "                assignments[fl]['remaining_capacity'] >= grp_cap):\n",
        "                # Entire group fits here—place all blocks\n",
        "                for blk in grp_info['blocks']:\n",
        "                    assignments[fl]['assigned_blocks'].append(blk)\n",
        "                    assignments[fl]['assigned_departments'].add(\n",
        "                        blk['Department_Sub_Department']\n",
        "                    )\n",
        "                assignments[fl]['remaining_area'] -= grp_area\n",
        "                assignments[fl]['remaining_capacity'] -= grp_cap\n",
        "                placed_whole = True\n",
        "                break\n",
        "\n",
        "        # If not placed as whole, try remaining floors\n",
        "        if not placed_whole:\n",
        "            for fl in floors[max_dest_floors:]:\n",
        "                if (assignments[fl]['remaining_area'] >= grp_area and\n",
        "                    assignments[fl]['remaining_capacity'] >= grp_cap):\n",
        "                    for blk in grp_info['blocks']:\n",
        "                        assignments[fl]['assigned_blocks'].append(blk)\n",
        "                        assignments[fl]['assigned_departments'].add(\n",
        "                            blk['Department_Sub_Department'].strip()\n",
        "                        )\n",
        "                    assignments[fl]['remaining_area'] -= grp_area\n",
        "                    assignments[fl]['remaining_capacity'] -= grp_cap\n",
        "                    placed_whole = True\n",
        "                    break\n",
        "\n",
        "        # If still not placed, try splitting based on adjacency rules (handled implicitly by placing blocks one by one)\n",
        "        if not placed_whole:\n",
        "             for blk in sorted(grp_info['blocks'], key=lambda b: b.get('Cumulative_Block_Circulation_Area', 0), reverse=True):\n",
        "                blk_area = blk.get('Cumulative_Block_Circulation_Area', 0)\n",
        "                blk_capacity = blk.get('Max_Occupancy_with_Capacity', 0)\n",
        "                placed_block = False\n",
        "\n",
        "                # Prioritize floors that could potentially be adjacent based on the group's priority\n",
        "                candidate_floors = []\n",
        "                if grp_info.get('priority', 0) >= 1.0:\n",
        "                    candidate_floors = floors.copy() # High priority can be anywhere\n",
        "                elif grp_info.get('priority', 0) >= 0.3:\n",
        "                    # Medium priority: prioritize floors with other medium/high priority blocks or same department\n",
        "                     for fl, info in assignments.items():\n",
        "                         if any(can_groups_be_adjacent(grp_info, adjacency_destination_groups.get(b.get('Destination_Group', ''), {})) for b in info['assigned_blocks'] if b.get('Destination_Group')):\n",
        "                              candidate_floors.append(fl)\n",
        "                     candidate_floors.extend([fl for fl in floors if fl not in candidate_floors]) # Add remaining floors\n",
        "                else:\n",
        "                    # Low priority: prioritize floors with other low priority blocks or same department\n",
        "                    for fl, info in assignments.items():\n",
        "                         if any(can_groups_be_adjacent(grp_info, adjacency_destination_groups.get(b.get('Destination_Group', ''), {})) for b in info['assigned_blocks'] if b.get('Destination_Group')):\n",
        "                              candidate_floors.append(fl)\n",
        "                    candidate_floors.extend([fl for fl in floors if fl not in candidate_floors]) # Add remaining floors\n",
        "\n",
        "                random.shuffle(candidate_floors) # Add some randomness\n",
        "\n",
        "                for fl in candidate_floors:\n",
        "                    if (assignments[fl]['remaining_area'] >= blk_area and\n",
        "                        assignments[fl]['remaining_capacity'] >= blk_capacity):\n",
        "                        assignments[fl]['assigned_blocks'].append(blk)\n",
        "                        assignments[fl]['assigned_departments'].add(\n",
        "                            blk.get('Department_Sub_Department', '').strip()\n",
        "                        )\n",
        "                        assignments[fl]['remaining_area'] -= blk_area\n",
        "                        assignments[fl]['remaining_capacity'] -= blk_capacity\n",
        "                        placed_block = True\n",
        "                        break\n",
        "\n",
        "                if not placed_block:\n",
        "                    unassigned_blocks.append(blk)\n",
        "\n",
        "\n",
        "    # Phase 2: Category-prioritized distribution of typical blocks across floors\n",
        "    # 2.1 Group typical blocks by SpaceMix category and Block_Name\n",
        "    typical_recs = typical_blocks.to_dict('records')\n",
        "\n",
        "    # Define category order based on priority_category\n",
        "    all_categories = ['ME', 'WE', 'US', 'Support', 'Speciality']\n",
        "    if priority_category in all_categories:\n",
        "        category_order = [priority_category] + [cat for cat in all_categories if cat != priority_category]\n",
        "    else:\n",
        "        category_order = all_categories\n",
        "\n",
        "    # Group blocks by category and then by block name\n",
        "    category_blocks = {}\n",
        "    for cat in category_order:\n",
        "        category_blocks[cat] = {}\n",
        "        cat_blocks = typical_blocks[typical_blocks['SpaceMix_(ME_WE_US_Support_Speciality)'].str.strip() == cat]\n",
        "        for _, blk in cat_blocks.iterrows():\n",
        "            name = blk['Block_Name']\n",
        "            if name not in category_blocks[cat]:\n",
        "                category_blocks[cat][name] = []\n",
        "            category_blocks[cat][name].append(blk.to_dict())\n",
        "\n",
        "    # 2.2 Process categories in priority order\n",
        "    for cat in category_order:\n",
        "        if cat not in category_blocks:\n",
        "            continue\n",
        "\n",
        "        # Compute each floor's available area for this category\n",
        "        avail = {fl: assignments[fl]['remaining_area'] for fl in floors}\n",
        "        total_avail = sum(avail.values())\n",
        "\n",
        "        if total_avail <= 0:\n",
        "            # No more space available, add remaining blocks to unassigned\n",
        "            for btype, blks in category_blocks[cat].items():\n",
        "                for blk in blks:\n",
        "                    unassigned_blocks.append(blk)\n",
        "            continue\n",
        "\n",
        "        # 2.3 For each block type in this category, compute target counts per floor\n",
        "        for btype, blks in category_blocks[cat].items():\n",
        "            count = len(blks)\n",
        "            ratios = {fl: (avail[fl] / total_avail if total_avail > 0 else 1/len(floors))\n",
        "                      for fl in floors}\n",
        "            raw = {fl: ratios[fl] * count for fl in floors}\n",
        "            targ = {fl: int(round(raw[fl])) for fl in floors}\n",
        "\n",
        "            diff = count - sum(targ.values())\n",
        "            if diff:\n",
        "                frac = {fl: raw[fl] - math.floor(raw[fl]) for fl in floors}\n",
        "                if diff > 0:\n",
        "                    for fl in sorted(floors, key=lambda x: frac[x], reverse=True)[:diff]:\n",
        "                        targ[fl] += 1\n",
        "                else:\n",
        "                    for fl in sorted(floors, key=lambda x: frac[x])[: -diff]:\n",
        "                        targ[fl] -= 1\n",
        "\n",
        "            random.shuffle(blks)\n",
        "            idx = 0\n",
        "            for fl in floors:\n",
        "                for _ in range(targ[fl]):\n",
        "                    if idx >= count:\n",
        "                        break\n",
        "                    blk = blks[idx]\n",
        "                    idx += 1\n",
        "                    area = blk['Cumulative_Block_Circulation_Area']\n",
        "                    cap = blk['Max_Occupancy_with_Capacity']\n",
        "                    if (assignments[fl]['remaining_area'] >= area\n",
        "                        and assignments[fl]['remaining_capacity'] >= cap):\n",
        "                        assignments[fl]['assigned_blocks'].append(blk)\n",
        "                        assignments[fl]['assigned_departments'].add(\n",
        "                            blk['Department_Sub_Department']\n",
        "                        )\n",
        "                        assignments[fl]['remaining_area'] -= area\n",
        "                        assignments[fl]['remaining_capacity'] -= cap\n",
        "                    else:\n",
        "                        unassigned_blocks.append(blk)\n",
        "\n",
        "            # any leftovers\n",
        "            while idx < count:\n",
        "                unassigned_blocks.append(blks[idx])\n",
        "                idx += 1\n",
        "\n",
        "    # Phase 3: Build Detailed & Summary DataFrames\n",
        "    # 3.1 Detailed DataFrame\n",
        "    assignment_list = []\n",
        "    for fl, info in assignments.items():\n",
        "        for blk in info['assigned_blocks']:\n",
        "            assignment_list.append({\n",
        "                'Block_id': blk.get('Block_ID', ''),\n",
        "                'Floor': fl,\n",
        "                'Department': blk.get('Department_Sub_Department', ''),\n",
        "                'Block_Name': blk.get('Block_Name', ''),\n",
        "                'Destination_Group': blk.get('Destination_Group', ''),\n",
        "                'SpaceMix': blk.get('SpaceMix_(ME_WE_US_Support_Speciality)', ''),\n",
        "                'Assigned_Area_SQM': blk.get('Cumulative_Block_Circulation_Area', 0),\n",
        "                'Max_Occupancy': blk.get('Max_Occupancy_with_Capacity', 0),\n",
        "                'Priority': blk.get('Priority', 0),\n",
        "                'Adjacency_Priority': blk.get('Adjacency_Priority', 0)\n",
        "            })\n",
        "    detailed_df = pd.DataFrame(assignment_list)\n",
        "\n",
        "    # 3.2 Floor_Summary DataFrame\n",
        "    if not detailed_df.empty:\n",
        "        floor_summary_df = (\n",
        "            detailed_df\n",
        "            .groupby('Floor')\n",
        "            .agg(\n",
        "                Assgn_Blocks=('Block_Name', 'count'),\n",
        "                Assgn_Area_SQM=('Assigned_Area_SQM', 'sum'),\n",
        "                Total_Occupancy=('Max_Occupancy', 'sum')\n",
        "            )\n",
        "            .reset_index()\n",
        "        )\n",
        "    else:\n",
        "        floor_summary_df = pd.DataFrame(columns=['Floor', 'Assgn_Blocks', 'Assgn_Area_SQM', 'Total_Occupancy'])\n",
        "\n",
        "    # Merge with original floor input data to get base values\n",
        "    floor_input_subset = all_floor_data[[\n",
        "        'Name', 'Usable_Area', 'Max_Assignable_Floor_loading_Capacity'\n",
        "    ]].rename(columns={\n",
        "        'Name': 'Floor',\n",
        "        'Usable_Area': 'Input_Usable_Area',\n",
        "        'Max_Assignable_Floor_loading_Capacity': 'Input_Max_Capacity'\n",
        "    })\n",
        "\n",
        "    # Join input data with summary\n",
        "    floor_summary_df = pd.merge(\n",
        "        floor_input_subset,\n",
        "        floor_summary_df,\n",
        "        on='Floor',\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    # Fill NaNs (if any floor didn't get any assignments)\n",
        "    floor_summary_df[[\n",
        "        'Assgn_Blocks',\n",
        "        'Assgn_Area_SQM',\n",
        "        'Total_Occupancy'\n",
        "    ]] = floor_summary_df[[\n",
        "        'Assgn_Blocks',\n",
        "        'Assgn_Area_SQM',\n",
        "        'Total_Occupancy'\n",
        "    ]].fillna(0)\n",
        "\n",
        "    # 3.3 SpaceMix_By_Units DataFrame\n",
        "    all_categories = ['ME', 'WE', 'US', 'Support', 'Speciality']\n",
        "    category_totals = {\n",
        "        cat: len(typical_blocks[\n",
        "            typical_blocks['SpaceMix_(ME_WE_US_Support_Speciality)'].str.strip() == cat\n",
        "        ])\n",
        "        for cat in all_categories\n",
        "    }\n",
        "\n",
        "    rows = []\n",
        "    for fl, info in assignments.items():\n",
        "        counts = {cat: 0 for cat in all_categories}\n",
        "        for blk in info['assigned_blocks']:\n",
        "            cat = blk.get('SpaceMix_(ME_WE_US_Support_Speciality)', '').strip()\n",
        "            if cat in counts:\n",
        "                counts[cat] += 1\n",
        "        total_blocks_on_floor = sum(counts.values())\n",
        "\n",
        "        for cat in all_categories:\n",
        "            cnt = counts[cat]\n",
        "            pct_of_floor = (cnt / total_blocks_on_floor * 100) if total_blocks_on_floor else 0.0\n",
        "            total_cat = category_totals.get(cat, 0) # Use .get with default 0\n",
        "            pct_overall = (cnt / total_cat * 100) if total_cat else 0.0\n",
        "\n",
        "            rows.append({\n",
        "                'Floor': fl,\n",
        "                'SpaceMix': cat,\n",
        "                'Unit_Count_on_Floor': cnt,\n",
        "                'Pct_of_Floor_UC': round(pct_of_floor, 2),\n",
        "                'Pct_of_Overall_UC': round(pct_overall, 2)\n",
        "            })\n",
        "\n",
        "    space_mix_df = pd.DataFrame(rows)\n",
        "\n",
        "    # 3.4 Unassigned DataFrame\n",
        "    unassigned_list = []\n",
        "    for blk in unassigned_blocks:\n",
        "        unassigned_list.append({\n",
        "            'Department': blk.get('Department_Sub_Department', ''),\n",
        "            'Block_Name': blk.get('Block_Name', ''),\n",
        "            'Destination_Group': blk.get('Destination_Group', ''),\n",
        "            'SpaceMix': blk.get('SpaceMix_(ME_WE_US_Support_Speciality)', ''),\n",
        "            'Area_SQM': blk.get('Cumulative_Block_Circulation_Area', 0),\n",
        "            'Max_Occupancy': blk.get('Max_Occupancy_with_Capacity', 0),\n",
        "            'Priority': blk.get('Priority', 0),\n",
        "            'Adjacency_Priority': blk.get('Adjacency_Priority', 0)\n",
        "        })\n",
        "    unassigned_df = pd.DataFrame(unassigned_list)\n",
        "\n",
        "    return detailed_df, floor_summary_df, space_mix_df, unassigned_df\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 8: Generate & Export Files for All Modes and Categories\n",
        "# ----------------------------------------\n",
        "\n",
        "# Print adjacency-based destination groups summary\n",
        "print(\"📋 Adjacency-Based Destination Groups Summary:\")\n",
        "print(\"=\" * 60)\n",
        "for group_name, group_info in adjacency_destination_groups.items():\n",
        "    print(f\"\\n{group_name}:\")\n",
        "    print(f\"  • Department: {group_info.get('department', 'N/A')}\") # Use .get\n",
        "    print(f\"  • Priority: {group_info.get('priority', 'N/A')}\")     # Use .get\n",
        "    print(f\"  • Total Area: {group_info.get('total_area', 0):.2f} SQM\") # Use .get\n",
        "    print(f\"  • Total Capacity: {group_info.get('total_capacity', 0)}\") # Use .get\n",
        "    print(f\"  • Number of Blocks: {len(group_info.get('blocks', []))}\") # Use .get\n",
        "\n",
        "\n",
        "# Define categories for priority assignment\n",
        "priority_categories = ['ME', 'WE', 'US', 'Support']\n",
        "modes = ['centralized', 'semi', 'decentralized']\n",
        "\n",
        "# Generate plans for each mode and category combination\n",
        "all_plans = {}\n",
        "\n",
        "for mode in modes:\n",
        "    all_plans[mode] = {}\n",
        "    for category in priority_categories:\n",
        "        print(f\"\\nGenerating {mode} plan with {category} priority...\")\n",
        "        detailed, floor_sum, space_mix, unassigned = run_stack_plan(mode, category)\n",
        "        all_plans[mode][category] = {\n",
        "            'detailed': detailed,\n",
        "            'floor_summary': floor_sum,\n",
        "            'space_mix': space_mix,\n",
        "            'unassigned': unassigned\n",
        "        }\n",
        "\n",
        "# Build dynamic summary for each plan\n",
        "def make_typical_summary(detailed_df):\n",
        "    \"\"\"Create typical block summary\"\"\"\n",
        "    if detailed_df.empty:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Get all typical block types from the original data\n",
        "    types = typical_blocks['Block_Name'].dropna().str.strip().unique()\n",
        "\n",
        "    # Filter detailed_df for typical blocks only\n",
        "    typical_detailed = detailed_df[detailed_df['Block_Name'].isin(types)]\n",
        "\n",
        "    if typical_detailed.empty:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Group by Block_Name and Floor\n",
        "    df = (typical_detailed\n",
        "          .groupby(['Block_Name', 'Floor'])\n",
        "          .size()\n",
        "          .unstack(fill_value=0))\n",
        "\n",
        "    df['Total_Assigned'] = df.sum(axis=1)\n",
        "\n",
        "    # Calculate assignment ratio for each block type\n",
        "    for block_type in df.index:\n",
        "        total_blocks_of_type = len(typical_blocks[typical_blocks['Block_Name'].str.strip() == block_type])\n",
        "        df.loc[block_type, 'Assignment_Ratio'] = round(df.loc[block_type, 'Total_Assigned'] / total_blocks_of_type, 3) if total_blocks_of_type > 0 else 0\n",
        "\n",
        "    return df\n",
        "\n",
        "# Export to Excel files for each mode and category\n",
        "for mode in modes:\n",
        "    for category in priority_categories:\n",
        "        plan_data = all_plans[mode][category]\n",
        "\n",
        "        # Create summary\n",
        "        summary = make_typical_summary(plan_data['detailed'])\n",
        "\n",
        "        # Export to Excel\n",
        "        filename = f'stack_plan_{mode}_{category}_priority_adjacency_based.xlsx'\n",
        "        with pd.ExcelWriter(filename) as writer:\n",
        "            plan_data['detailed'].to_excel(writer, sheet_name='Detailed', index=False)\n",
        "            plan_data['floor_summary'].to_excel(writer, sheet_name='Floor_Summary', index=False)\n",
        "            plan_data['space_mix'].to_excel(writer, sheet_name='SpaceMix_By_Units', index=False)\n",
        "            plan_data['unassigned'].to_excel(writer, sheet_name='Unassigned', index=False)\n",
        "            if not summary.empty:\n",
        "                summary.to_excel(writer, sheet_name='Typical_Summary')\n",
        "\n",
        "print(\"\\n✅ Generated Excel outputs for all modes and priority categories.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1PoGnyhZnmB",
        "outputId": "1fc651a9-7936-484a-d157-3fe1346686bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading PDF Auto Stacking Input New Build - Case Study A- R1 (with block instances) - Split priority-destination grouping.pdf: [Errno 2] No such file or directory: 'Auto Stacking Input New Build - Case Study A- R1 (with block instances) - Split priority-destination grouping.pdf'\n",
            "Error reading PDF Auto Stacking Input New Build - Case Study A- R1 (with block instances) - Adjacency-destination grouping.pdf: [Errno 2] No such file or directory: 'Auto Stacking Input New Build - Case Study A- R1 (with block instances) - Adjacency-destination grouping.pdf'\n",
            "📋 Adjacency-Based Destination Groups Summary:\n",
            "============================================================\n",
            "\n",
            "Unmatched_Dest_Group_1:\n",
            "  • Department: Common_Common\n",
            "  • Priority: 0\n",
            "  • Total Area: 2562.87 SQM\n",
            "  • Total Capacity: 282.5\n",
            "  • Number of Blocks: 45\n",
            "\n",
            "Unmatched_Dest_Group_2:\n",
            "  • Department: External_External\n",
            "  • Priority: 0\n",
            "  • Total Area: 141.00 SQM\n",
            "  • Total Capacity: 2.5\n",
            "  • Number of Blocks: 5\n",
            "\n",
            "Generating centralized plan with ME priority...\n",
            "\n",
            "Generating centralized plan with WE priority...\n",
            "\n",
            "Generating centralized plan with US priority...\n",
            "\n",
            "Generating centralized plan with Support priority...\n",
            "\n",
            "Generating semi plan with ME priority...\n",
            "\n",
            "Generating semi plan with WE priority...\n",
            "\n",
            "Generating semi plan with US priority...\n",
            "\n",
            "Generating semi plan with Support priority...\n",
            "\n",
            "Generating decentralized plan with ME priority...\n",
            "\n",
            "Generating decentralized plan with WE priority...\n",
            "\n",
            "Generating decentralized plan with US priority...\n",
            "\n",
            "Generating decentralized plan with Support priority...\n",
            "\n",
            "✅ Generated Excel outputs for all modes and priority categories.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final-AR-1\n"
      ],
      "metadata": {
        "id": "RVLln72kuNJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install PyPDF2\n",
        "import pandas as pd\n",
        "import random\n",
        "import math\n",
        "import PyPDF2\n",
        "import re\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 1: Load Input Sheets\n",
        "# ----------------------------------------\n",
        "\n",
        "excel_path = '/content/A- R2.xlsx'  # adjust if needed\n",
        "\n",
        "# 1.1 Floors sheet\n",
        "all_floor_data = pd.read_excel(excel_path, sheet_name='Program Table Input 2 - Floor')\n",
        "all_floor_data.columns = all_floor_data.columns.str.strip()\n",
        "\n",
        "# 1.2 Blocks sheet\n",
        "all_block_data = pd.read_excel(excel_path, sheet_name='Program Table Input 1 - Block')\n",
        "all_block_data.columns = all_block_data.columns.str.strip()\n",
        "\n",
        "# 1.3 Department Split sheet\n",
        "department_split_data = pd.read_excel(excel_path, sheet_name='Department Split', skiprows=1)\n",
        "department_split_data.columns = department_split_data.columns.str.strip()\n",
        "department_split_data = department_split_data.rename(\n",
        "    columns={'BU_Department_Sub-Department': 'Department_Sub-Department'}\n",
        ")\n",
        "\n",
        "# 1.4 Adjacency sheet (original)\n",
        "xls = pd.ExcelFile(excel_path)\n",
        "adjacency_sheet_name = [name for name in xls.sheet_names if \"Adjacency\" in name][0]\n",
        "raw_data = xls.parse(adjacency_sheet_name, header=1, index_col=0)\n",
        "adjacency_data = raw_data.apply(pd.to_numeric, errors='coerce')\n",
        "adjacency_data.index = adjacency_data.index.str.strip()\n",
        "adjacency_data.columns = adjacency_data.columns.str.strip()\n",
        "\n",
        "# 1.5 De-Centralized Logic sheet\n",
        "df_logic = pd.read_excel(excel_path, sheet_name='De-Centralized Logic', header=None)\n",
        "De_Centralized_data = {}\n",
        "current_section = None\n",
        "for _, row in df_logic.iterrows():\n",
        "    first_cell = str(row[0]).strip() if pd.notna(row[0]) else \"\"\n",
        "    if first_cell in [\"Centralised\", \"Semi Centralized\", \"DeCentralised\"]:\n",
        "        current_section = first_cell\n",
        "        De_Centralized_data[current_section] = {\"Add\": 0}\n",
        "    elif current_section and first_cell == \"( Add into cetralised destination Block)\":\n",
        "        De_Centralized_data[current_section][\"Add\"] = int(row[1]) if pd.notna(row[1]) else 0\n",
        "\n",
        "# Ensure keys exist\n",
        "for key in [\"Centralised\", \"Semi Centralized\", \"DeCentralised\"]:\n",
        "    if key not in De_Centralized_data:\n",
        "        De_Centralized_data[key] = {\"Add\": 0}\n",
        "    elif \"Add\" not in De_Centralized_data[key]:\n",
        "        De_Centralized_data[key][\"Add\"] = 0\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 2: Physical Constraint Adjacency Logic\n",
        "# ----------------------------------------\n",
        "\n",
        "def define_physical_constraints():\n",
        "    \"\"\"\n",
        "    Define physical constraints based on the PDF document\n",
        "    Returns a dictionary mapping constraint types to their floor priorities\n",
        "    \"\"\"\n",
        "    physical_constraints = {\n",
        "        'Main Entry within Client Real estate Reception': {\n",
        "            'priority_1': 'lowest',  # Level 0 if available\n",
        "            'priority_2': 'mid',\n",
        "            'priority_3': 'top_most'\n",
        "        },\n",
        "        'Transfer floor': {\n",
        "            'blocks': []  # Nil - no specific blocks\n",
        "        },\n",
        "        'Floor with an Outdoor Terrace': {\n",
        "            'blocks': []  # Nil - no specific blocks\n",
        "        },\n",
        "        'Best View': {\n",
        "            'blocks': []  # Nil - no specific blocks\n",
        "        },\n",
        "        'Top most floor of Atrium Floor 2': {\n",
        "            'blocks': []  # Specific to Floor 2\n",
        "        },\n",
        "        'Top Most Level': {\n",
        "            'priority_1': 'highest'\n",
        "        },\n",
        "        'Refuge Floor': {\n",
        "            'blocks': []  # Nil - no specific blocks\n",
        "        },\n",
        "        'Additional Structural loading floor': {\n",
        "            'blocks': []  # Nil - no specific blocks\n",
        "        },\n",
        "        'Loading Dock': {\n",
        "            'blocks': []  # Nil - no specific blocks\n",
        "        },\n",
        "        'Service Floor': {\n",
        "            'blocks': []  # Nil - no specific blocks\n",
        "        }\n",
        "    }\n",
        "    return physical_constraints\n",
        "\n",
        "def get_floor_levels(floor_df):\n",
        "    \"\"\"\n",
        "    Determine floor levels based on floor names/numbers\n",
        "    Returns a dictionary mapping floor names to their level types\n",
        "    \"\"\"\n",
        "    floor_levels = {}\n",
        "    floors = floor_df['Name'].str.strip().tolist()\n",
        "\n",
        "    # Sort floors to identify lowest, highest, mid\n",
        "    # Assuming floors are named with numbers or can be sorted\n",
        "    sorted_floors = sorted(floors)\n",
        "\n",
        "    if len(sorted_floors) >= 1:\n",
        "        floor_levels[sorted_floors[0]] = 'lowest'\n",
        "        floor_levels[sorted_floors[-1]] = 'highest'\n",
        "\n",
        "        # Identify mid floors\n",
        "        if len(sorted_floors) > 2:\n",
        "            mid_floors = sorted_floors[1:-1]\n",
        "            for floor in mid_floors:\n",
        "                floor_levels[floor] = 'mid'\n",
        "        elif len(sorted_floors) == 2:\n",
        "            floor_levels[sorted_floors[1]] = 'mid'\n",
        "\n",
        "    # Special handling for specific floors mentioned in constraints\n",
        "    for floor in floors:\n",
        "        if 'atrium' in floor.lower() or '2' in floor:\n",
        "            floor_levels[floor] = 'atrium_top'\n",
        "\n",
        "    return floor_levels\n",
        "\n",
        "def assign_physical_constraint_blocks(block_data, floor_data, physical_constraints):\n",
        "    \"\"\"\n",
        "    Assign blocks based on physical constraints before other assignments\n",
        "    \"\"\"\n",
        "    blocks_df = block_data.copy()\n",
        "    floor_levels = get_floor_levels(floor_data)\n",
        "\n",
        "    # Add physical constraint assignment column\n",
        "    blocks_df['Physical_Constraint_Assignment'] = ''\n",
        "    blocks_df['Physical_Priority'] = 0\n",
        "\n",
        "    # Process blocks that have specific physical requirements\n",
        "    # For now, we'll identify blocks that should follow physical constraints\n",
        "    # This can be expanded based on specific block naming patterns or additional data\n",
        "\n",
        "    # Example: Reception blocks should go to lowest floor\n",
        "    reception_blocks = blocks_df[\n",
        "        blocks_df['Block_Name'].str.contains('Reception', case=False, na=False)\n",
        "    ]\n",
        "\n",
        "    for idx in reception_blocks.index:\n",
        "        blocks_df.loc[idx, 'Physical_Constraint_Assignment'] = 'Main Entry within Client Real estate Reception'\n",
        "        blocks_df.loc[idx, 'Physical_Priority'] = 1\n",
        "\n",
        "    # Example: Executive or VIP blocks should go to highest floors\n",
        "    executive_blocks = blocks_df[\n",
        "        blocks_df['Block_Name'].str.contains('Executive|VIP|CEO|Director', case=False, na=False)\n",
        "    ]\n",
        "\n",
        "    for idx in executive_blocks.index:\n",
        "        blocks_df.loc[idx, 'Physical_Constraint_Assignment'] = 'Top Most Level'\n",
        "        blocks_df.loc[idx, 'Physical_Priority'] = 1\n",
        "\n",
        "    # Example: Blocks with specific floor requirements\n",
        "    # You can add more specific logic based on your block naming conventions\n",
        "\n",
        "    return blocks_df, floor_levels\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 3: Read Adjacency Rules from PDF Files\n",
        "# ----------------------------------------\n",
        "\n",
        "def read_pdf_adjacency_rules(pdf_path):\n",
        "    \"\"\"Read adjacency rules from PDF file\"\"\"\n",
        "    adjacency_rules = {}\n",
        "\n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            pdf_reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page in pdf_reader.pages:\n",
        "                text += page.extract_text()\n",
        "\n",
        "        # Parse the text to extract adjacency rules\n",
        "        lines = text.split('\\n')\n",
        "        current_dept = None\n",
        "        current_block = None\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            # Look for department_subdepartment pattern\n",
        "            if '_' in line and any(keyword in line for keyword in ['Common', 'External']):\n",
        "                parts = line.split()\n",
        "                if len(parts) >= 2:\n",
        "                    dept_sub = parts[0]\n",
        "                    block_name = ' '.join(parts[1:])\n",
        "                    current_dept = dept_sub\n",
        "                    current_block = block_name\n",
        "\n",
        "                    if current_dept not in adjacency_rules:\n",
        "                        adjacency_rules[current_dept] = {}\n",
        "                    if current_block not in adjacency_rules[current_dept]:\n",
        "                        adjacency_rules[current_dept][current_block] = {}\n",
        "\n",
        "            # Look for priority values (1, 0.3, 0)\n",
        "            elif current_dept and current_block:\n",
        "                numbers = re.findall(r'\\b(?:1|0\\.3|0)\\b', line)\n",
        "                if numbers:\n",
        "                    # Store priority values\n",
        "                    adjacency_rules[current_dept][current_block]['priorities'] = [float(n) for n in numbers]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading PDF {pdf_path}: {e}\")\n",
        "\n",
        "    return adjacency_rules\n",
        "\n",
        "# Read adjacency rules from both PDF files\n",
        "adjacency_rules_1 = read_pdf_adjacency_rules('Auto Stacking Input New Build - Case Study A- R1 (with block instances) - Split priority-destination grouping.pdf')\n",
        "adjacency_rules_2 = read_pdf_adjacency_rules('Auto Stacking Input New Build - Case Study A- R1 (with block instances) - Adjacency-destination grouping.pdf')\n",
        "\n",
        "# Combine adjacency rules\n",
        "combined_adjacency_rules = {}\n",
        "for rules in [adjacency_rules_1, adjacency_rules_2]:\n",
        "    for dept, blocks in rules.items():\n",
        "        if dept not in combined_adjacency_rules:\n",
        "            combined_adjacency_rules[dept] = {}\n",
        "        combined_adjacency_rules[dept].update(blocks)\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 4: Create Destination Groups Based on Adjacency Rules\n",
        "# ----------------------------------------\n",
        "\n",
        "def create_adjacency_based_destination_groups(block_data, adjacency_rules):\n",
        "    \"\"\"\n",
        "    Create destination groups based on adjacency rules instead of block information\n",
        "    \"\"\"\n",
        "    # Create a copy of block data to work with\n",
        "    blocks_df = block_data.copy()\n",
        "\n",
        "    # Initialize Destination_Group and Adjacency_Priority columns for all blocks\n",
        "    blocks_df['Destination_Group'] = None\n",
        "    blocks_df['Adjacency_Priority'] = None\n",
        "\n",
        "    # Initialize destination group counter\n",
        "    group_counter = 1\n",
        "\n",
        "    # Dictionary to store formed groups\n",
        "    destination_groups = {}\n",
        "\n",
        "    # Process blocks marked as destination or both\n",
        "    destination_blocks = blocks_df[blocks_df['Typical_Destination'].isin(['Destination', 'both'])].copy()\n",
        "\n",
        "    # Create adjacency-based groups\n",
        "    for dept_sub, dept_rules in adjacency_rules.items():\n",
        "        # Find blocks belonging to this department\n",
        "        dept_blocks = destination_blocks[\n",
        "            destination_blocks['Department_Sub_Department'].str.strip() == dept_sub\n",
        "        ].copy()\n",
        "\n",
        "        if dept_blocks.empty:\n",
        "            continue\n",
        "\n",
        "        # Group blocks based on adjacency rules and priorities\n",
        "        for block_name, rule_info in dept_rules.items():\n",
        "            # Find blocks with this block name\n",
        "            matching_blocks = dept_blocks[\n",
        "                dept_blocks['Block_Name'].str.strip() == block_name\n",
        "            ].copy()\n",
        "\n",
        "            if matching_blocks.empty:\n",
        "                continue\n",
        "\n",
        "            # Get priority for this block type\n",
        "            priorities = rule_info.get('priorities', [0])\n",
        "            max_priority = max(priorities) if priorities else 0\n",
        "\n",
        "            # Create group name based on department and priority\n",
        "            if max_priority >= 1.0:\n",
        "                group_name = f\"High_Priority_Group_{group_counter}\"\n",
        "            elif max_priority >= 0.3:\n",
        "                group_name = f\"Medium_Priority_Group_{group_counter}\"\n",
        "            else:\n",
        "                group_name = f\"Low_Priority_Group_{group_counter}\"\n",
        "\n",
        "            # Assign all matching blocks to this group\n",
        "            for idx in matching_blocks.index:\n",
        "                blocks_df.loc[idx, 'Destination_Group'] = group_name\n",
        "                blocks_df.loc[idx, 'Adjacency_Priority'] = max_priority\n",
        "\n",
        "            # Store group information\n",
        "            if group_name not in destination_groups:\n",
        "                destination_groups[group_name] = {\n",
        "                    'blocks': [],\n",
        "                    'department': dept_sub,\n",
        "                    'priority': max_priority,\n",
        "                    'total_area': 0,\n",
        "                    'total_capacity': 0\n",
        "                }\n",
        "\n",
        "            for _, block in matching_blocks.iterrows():\n",
        "                destination_groups[group_name]['blocks'].append(block.to_dict())\n",
        "                destination_groups[group_name]['total_area'] += block['Cumulative_Block_Circulation_Area']\n",
        "                destination_groups[group_name]['total_capacity'] += block['Max_Occupancy_with_Capacity']\n",
        "\n",
        "            group_counter += 1\n",
        "\n",
        "    # Handle any remaining destination blocks that weren't matched\n",
        "    unmatched_dest_blocks = destination_blocks[\n",
        "        ~destination_blocks.index.isin(blocks_df[blocks_df['Destination_Group'].notna()].index)\n",
        "    ]\n",
        "\n",
        "    if not unmatched_dest_blocks.empty:\n",
        "        # Group unmatched blocks by department\n",
        "        for dept in unmatched_dest_blocks['Department_Sub_Department'].unique():\n",
        "            dept_unmatched = unmatched_dest_blocks[\n",
        "                unmatched_dest_blocks['Department_Sub_Department'] == dept\n",
        "            ]\n",
        "\n",
        "            group_name = f\"Unmatched_Dest_Group_{group_counter}\"\n",
        "\n",
        "            for idx in dept_unmatched.index:\n",
        "                blocks_df.loc[idx, 'Destination_Group'] = group_name\n",
        "                blocks_df.loc[idx, 'Adjacency_Priority'] = 0\n",
        "\n",
        "            destination_groups[group_name] = {\n",
        "                'blocks': dept_unmatched.to_dict('records'),\n",
        "                'department': dept,\n",
        "                'priority': 0,\n",
        "                'total_area': dept_unmatched['Cumulative_Block_Circulation_Area'].sum(),\n",
        "                'total_capacity': dept_unmatched['Max_Occupancy_with_Capacity'].sum()\n",
        "            }\n",
        "\n",
        "            group_counter += 1\n",
        "\n",
        "    return blocks_df, destination_groups\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 5: Apply Physical Constraints and Adjacency-Based Grouping\n",
        "# ----------------------------------------\n",
        "\n",
        "# Apply physical constraints first\n",
        "physical_constraints = define_physical_constraints()\n",
        "all_block_data, floor_levels = assign_physical_constraint_blocks(\n",
        "    all_block_data, all_floor_data, physical_constraints\n",
        ")\n",
        "\n",
        "# Apply adjacency-based grouping\n",
        "all_block_data, adjacency_destination_groups = create_adjacency_based_destination_groups(\n",
        "    all_block_data, combined_adjacency_rules\n",
        ")\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 6: Preprocess Blocks & Department Split\n",
        "# ----------------------------------------\n",
        "\n",
        "# 6.1 Separate Destination vs. Typical blocks (now with adjacency-based groups)\n",
        "destination_blocks = all_block_data[all_block_data['Typical_Destination'].isin(['Destination', 'both'])].copy()\n",
        "typical_blocks = all_block_data[all_block_data['Typical_Destination'] == 'Typical'].copy()\n",
        "\n",
        "# 6.2 Add priority information to destination blocks\n",
        "destination_blocks['Priority'] = destination_blocks.get('Adjacency_Priority', 0)\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 7: Initialize Floor Assignments\n",
        "# ----------------------------------------\n",
        "\n",
        "def initialize_floor_assignments(floor_df):\n",
        "    \"\"\"\n",
        "    Returns a dict keyed by floor name. Each entry tracks:\n",
        "      - remaining_area\n",
        "      - remaining_capacity\n",
        "      - assigned_blocks      (list of block‐row dicts)\n",
        "      - assigned_departments (set of sub‐departments)\n",
        "      - ME_area, WE_area, US_area, Support_area, Speciality_area (floats)\n",
        "    \"\"\"\n",
        "    assignments = {}\n",
        "    for _, row in floor_df.iterrows():\n",
        "        floor = row['Name'].strip()\n",
        "        assignments[floor] = {\n",
        "            'remaining_area': row['Usable_Area'],\n",
        "            'remaining_capacity': row['Max_Assignable_Floor_loading_Capacity'],\n",
        "            'assigned_blocks': [],\n",
        "            'assigned_departments': set(),\n",
        "            'ME_area': 0.0,\n",
        "            'WE_area': 0.0,\n",
        "            'US_area': 0.0,\n",
        "            'Support_area': 0.0,\n",
        "            'Speciality_area': 0.0\n",
        "        }\n",
        "    return assignments\n",
        "\n",
        "floors = list(all_floor_data['Name'].str.strip())\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 8: Enhanced Assignment Functions\n",
        "# ----------------------------------------\n",
        "\n",
        "def assign_physical_constraint_blocks_to_floors(assignments, block_data, floor_levels):\n",
        "    \"\"\"\n",
        "    Assign blocks with physical constraints to appropriate floors first\n",
        "    \"\"\"\n",
        "    # Get blocks with physical constraints\n",
        "    constraint_blocks = block_data[\n",
        "        block_data['Physical_Constraint_Assignment'] != ''\n",
        "    ].copy()\n",
        "\n",
        "    assigned_blocks = []\n",
        "\n",
        "    for _, block in constraint_blocks.iterrows():\n",
        "        constraint_type = block['Physical_Constraint_Assignment']\n",
        "        area = block['Cumulative_Block_Circulation_Area']\n",
        "        capacity = block['Max_Occupancy_with_Capacity']\n",
        "\n",
        "        # Determine target floor based on constraint\n",
        "        target_floors = []\n",
        "\n",
        "        if constraint_type == 'Main Entry within Client Real estate Reception':\n",
        "            # Priority 1: lowest, Priority 2: mid, Priority 3: top_most\n",
        "            target_floors = [\n",
        "                floor for floor, level in floor_levels.items()\n",
        "                if level == 'lowest'\n",
        "            ]\n",
        "            if not target_floors:\n",
        "                target_floors = [\n",
        "                    floor for floor, level in floor_levels.items()\n",
        "                    if level == 'mid'\n",
        "                ]\n",
        "            if not target_floors:\n",
        "                target_floors = [\n",
        "                    floor for floor, level in floor_levels.items()\n",
        "                    if level == 'highest'\n",
        "                ]\n",
        "\n",
        "        elif constraint_type == 'Top Most Level':\n",
        "            target_floors = [\n",
        "                floor for floor, level in floor_levels.items()\n",
        "                if level == 'highest'\n",
        "            ]\n",
        "\n",
        "        # Try to assign to target floors\n",
        "        assigned = False\n",
        "        for floor in target_floors:\n",
        "            if floor in assignments:\n",
        "                if (assignments[floor]['remaining_area'] >= area and\n",
        "                    assignments[floor]['remaining_capacity'] >= capacity):\n",
        "\n",
        "                    assignments[floor]['assigned_blocks'].append(block.to_dict())\n",
        "                    assignments[floor]['assigned_departments'].add(\n",
        "                        block['Department_Sub_Department'].strip()\n",
        "                    )\n",
        "                    assignments[floor]['remaining_area'] -= area\n",
        "                    assignments[floor]['remaining_capacity'] -= capacity\n",
        "                    assigned_blocks.append(block.name)  # Track assigned block index\n",
        "                    assigned = True\n",
        "                    break\n",
        "\n",
        "        if not assigned:\n",
        "            print(f\"Warning: Could not assign block {block['Block_Name']} with constraint {constraint_type}\")\n",
        "\n",
        "    return assignments, assigned_blocks\n",
        "\n",
        "def can_groups_be_adjacent(group1_info, group2_info):\n",
        "    \"\"\"Check if two groups can be adjacent based on adjacency rules and priorities\"\"\"\n",
        "    # High priority groups (1.0) can be adjacent to any group\n",
        "    if group1_info['priority'] >= 1.0 or group2_info['priority'] >= 1.0:\n",
        "        return True\n",
        "\n",
        "    # Medium priority groups (0.3) can be adjacent to medium and high priority groups\n",
        "    if (group1_info['priority'] >= 0.3 and group2_info['priority'] >= 0.3):\n",
        "        return True\n",
        "\n",
        "    # Same department groups can be adjacent\n",
        "    if group1_info['department'] == group2_info['department']:\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "def split_destination_groups_by_adjacency(destination_groups):\n",
        "    \"\"\"Split destination groups based on adjacency rules and priorities\"\"\"\n",
        "    # Sort groups by priority (highest first)\n",
        "    sorted_groups = sorted(\n",
        "        destination_groups.items(),\n",
        "        key=lambda x: x[1]['priority'],\n",
        "        reverse=True\n",
        "    )\n",
        "\n",
        "    subgroups = []\n",
        "    current_subgroup = []\n",
        "\n",
        "    for group_name, group_info in sorted_groups:\n",
        "        if not current_subgroup:\n",
        "            current_subgroup.append((group_name, group_info))\n",
        "        else:\n",
        "            # Check if this group can be adjacent to any group in current subgroup\n",
        "            can_group = False\n",
        "            for existing_group_name, existing_group_info in current_subgroup:\n",
        "                if can_groups_be_adjacent(group_info, existing_group_info):\n",
        "                    can_group = True\n",
        "                    break\n",
        "\n",
        "            if can_group:\n",
        "                current_subgroup.append((group_name, group_info))\n",
        "            else:\n",
        "                # Start new subgroup\n",
        "                if current_subgroup:\n",
        "                    subgroups.append(current_subgroup)\n",
        "                current_subgroup = [(group_name, group_info)]\n",
        "\n",
        "    # Add the last subgroup\n",
        "    if current_subgroup:\n",
        "        subgroups.append(current_subgroup)\n",
        "\n",
        "    return subgroups\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 9: Core Stacking Function with Physical Constraints\n",
        "# ----------------------------------------\n",
        "\n",
        "def run_stack_plan(mode, priority_category='ME'):\n",
        "    \"\"\"\n",
        "    mode: 'centralized', 'semi', or 'decentralized'\n",
        "    priority_category: 'ME', 'WE', 'US', or 'Support' - which category to prioritize in typical block assignment\n",
        "    Returns four DataFrames:\n",
        "      1) detailed_df      – each block's assigned floor, department, block name, destination group, space mix, area, occupancy\n",
        "      2) floor_summary_df – floor‐wise totals (block count, total area, total occupancy)\n",
        "      3) space_mix_df     – for each floor and each category {ME, WE, US, Support, Speciality}\n",
        "      4) unassigned_df    – blocks that couldn't be placed\n",
        "    \"\"\"\n",
        "    assignments = initialize_floor_assignments(all_floor_data)\n",
        "    unassigned_blocks = []\n",
        "\n",
        "    # Phase 0: Assign Physical Constraint Blocks First\n",
        "    print(f\"Phase 0: Assigning physical constraint blocks...\")\n",
        "    assignments, assigned_constraint_blocks = assign_physical_constraint_blocks_to_floors(\n",
        "        assignments, all_block_data, floor_levels\n",
        "    )\n",
        "\n",
        "    # Determine how many floors to use for destination blocks\n",
        "    def destination_floor_count():\n",
        "        if mode == 'centralized':\n",
        "            return 2\n",
        "        elif mode == 'semi':\n",
        "            return 2 + De_Centralized_data[\"Semi Centralized\"][\"Add\"]\n",
        "        elif mode == 'decentralized':\n",
        "            return 2 + De_Centralized_data[\"DeCentralised\"][\"Add\"]\n",
        "        else:\n",
        "            return 2\n",
        "\n",
        "    max_dest_floors = destination_floor_count()\n",
        "    # Cap at total number of floors\n",
        "    max_dest_floors = min(max_dest_floors, len(floors))\n",
        "\n",
        "    # Phase 1: Adjacency-Based Destination Group Assignment\n",
        "    print(f\"Phase 1: Assigning destination groups...\")\n",
        "\n",
        "    # Filter out already assigned blocks from destination groups\n",
        "    filtered_destination_groups = {}\n",
        "    for group_name, group_info in adjacency_destination_groups.items():\n",
        "        filtered_blocks = []\n",
        "        for block in group_info['blocks']:\n",
        "            # Check if block was already assigned in Phase 0\n",
        "            if block.get('Block_ID') not in assigned_constraint_blocks:\n",
        "                filtered_blocks.append(block)\n",
        "\n",
        "        if filtered_blocks:\n",
        "            filtered_destination_groups[group_name] = {\n",
        "                'blocks': filtered_blocks,\n",
        "                'department': group_info['department'],\n",
        "                'priority': group_info['priority'],\n",
        "                'total_area': sum(b['Cumulative_Block_Circulation_Area'] for b in filtered_blocks),\n",
        "                'total_capacity': sum(b['Max_Occupancy_with_Capacity'] for b in filtered_blocks)\n",
        "            }\n",
        "\n",
        "    group_names = list(filtered_destination_groups.keys())\n",
        "    random.shuffle(group_names)\n",
        "\n",
        "    for grp_name in group_names:\n",
        "        grp_info = filtered_destination_groups[grp_name]\n",
        "        grp_area = grp_info['total_area']\n",
        "        grp_cap = grp_info['total_capacity']\n",
        "        placed_whole = False\n",
        "\n",
        "        # Try to place entire group first on designated destination floors\n",
        "        candidate_floors = floors[:max_dest_floors].copy()\n",
        "\n",
        "        for fl in candidate_floors:\n",
        "            if (assignments[fl]['remaining_area'] >= grp_area and\n",
        "                assignments[fl]['remaining_capacity'] >= grp_cap):\n",
        "                # Entire group fits here—place all blocks\n",
        "                for blk in grp_info['blocks']:\n",
        "                    assignments[fl]['assigned_blocks'].append(blk)\n",
        "                    assignments[fl]['assigned_departments'].add(\n",
        "                        blk['Department_Sub_Department']\n",
        "                    )\n",
        "                assignments[fl]['remaining_area'] -= grp_area\n",
        "                assignments[fl]['remaining_capacity'] -= grp_cap\n",
        "                placed_whole = True\n",
        "                break\n",
        "\n",
        "        # If not placed as whole, try remaining floors\n",
        "        if not placed_whole:\n",
        "            for fl in floors[max_dest_floors:]:\n",
        "                if (assignments[fl]['remaining_area'] >= grp_area and\n",
        "                    assignments[fl]['remaining_capacity'] >= grp_cap):\n",
        "                    for blk in grp_info['blocks']:\n",
        "                        assignments[fl]['assigned_blocks'].append(blk)\n",
        "                        assignments[fl]['assigned_departments'].add(\n",
        "                            blk['Department_Sub_Department'].strip()\n",
        "                        )\n",
        "                    assignments[fl]['remaining_area'] -= grp_area\n",
        "                    assignments[fl]['remaining_capacity'] -= grp_cap\n",
        "                    placed_whole = True\n",
        "                    break\n",
        "\n",
        "        # If still not placed, try splitting based on adjacency\n",
        "        if not placed_whole:\n",
        "            # Split this group's blocks if possible\n",
        "            subgroups = split_destination_groups_by_adjacency({grp_name: grp_info})\n",
        "\n",
        "            for subgroup in subgroups:\n",
        "                subgroup_area = sum(group_info['total_area'] for _, group_info in subgroup)\n",
        "                subgroup_cap = sum(group_info['total_capacity'] for _, group_info in subgroup)\n",
        "                subgroup_blocks = []\n",
        "                for _, group_info in subgroup:\n",
        "                    subgroup_blocks.extend(group_info['blocks'])\n",
        "\n",
        "                subgroup_placed = False\n",
        "\n",
        "                # Try to place subgroup on available floors\n",
        "                for fl in floors:\n",
        "                    if (assignments[fl]['remaining_area'] >= subgroup_area and\n",
        "                        assignments[fl]['remaining_capacity'] >= subgroup_cap):\n",
        "                        for blk in subgroup_blocks:\n",
        "                            assignments[fl]['assigned_blocks'].append(blk)\n",
        "                            assignments[fl]['assigned_departments'].add(\n",
        "                                blk['Department_Sub_Department'].strip()\n",
        "                            )\n",
        "                        assignments[fl]['remaining_area'] -= subgroup_area\n",
        "                        assignments[fl]['remaining_capacity'] -= subgroup_cap\n",
        "                        subgroup_placed = True\n",
        "                        break\n",
        "\n",
        "                # If subgroup still can't be placed, add to unassigned\n",
        "                if not subgroup_placed:\n",
        "                    for blk in subgroup_blocks:\n",
        "                        unassigned_blocks.append(blk)\n",
        "\n",
        "\n",
        "    # Phase 2: Category-prioritized distribution of typical blocks across floors\n",
        "    print(f\"Phase 2: Assigning typical blocks with {priority_category} priority...\")\n",
        "\n",
        "    # Filter out already assigned typical blocks\n",
        "    remaining_typical_blocks = typical_blocks[\n",
        "        ~typical_blocks.index.isin(assigned_constraint_blocks)\n",
        "    ].copy()\n",
        "\n",
        "    # 2.1 Group typical blocks by SpaceMix category and Block_Name\n",
        "    typical_recs = remaining_typical_blocks.to_dict('records')\n",
        "\n",
        "    # Define category order based on priority_category\n",
        "    all_categories = ['ME', 'WE', 'US', 'Support', 'Speciality']\n",
        "    if priority_category in all_categories:\n",
        "        category_order = [priority_category] + [cat for cat in all_categories if cat != priority_category]\n",
        "    else:\n",
        "        category_order = all_categories\n",
        "\n",
        "    # Group blocks by category and then by block name\n",
        "    category_blocks = {}\n",
        "    for cat in category_order:\n",
        "        category_blocks[cat] = {}\n",
        "        cat_blocks = remaining_typical_blocks[\n",
        "            remaining_typical_blocks['SpaceMix_(ME_WE_US_Support_Speciality)'].str.strip() == cat\n",
        "        ]\n",
        "        for _, blk in cat_blocks.iterrows():\n",
        "            name = blk['Block_Name']\n",
        "            if name not in category_blocks[cat]:\n",
        "                category_blocks[cat][name] = []\n",
        "            category_blocks[cat][name].append(blk.to_dict())\n",
        "\n",
        "    # 2.2 Process categories in priority order\n",
        "    for cat in category_order:\n",
        "        if cat not in category_blocks:\n",
        "            continue\n",
        "\n",
        "        # Compute each floor's available area for this category\n",
        "        avail = {fl: assignments[fl]['remaining_area'] for fl in floors}\n",
        "        total_avail = sum(avail.values())\n",
        "\n",
        "        if total_avail <= 0:\n",
        "            # No more space available, add remaining blocks to unassigned\n",
        "            for btype, blks in category_blocks[cat].items():\n",
        "                for blk in blks:\n",
        "                    unassigned_blocks.append(blk)\n",
        "            continue\n",
        "\n",
        "        # 2.3 For each block type in this category, compute target counts per floor\n",
        "        for btype, blks in category_blocks[cat].items():\n",
        "            count = len(blks)\n",
        "            ratios = {fl: (avail[fl] / total_avail if total_avail > 0 else 1/len(floors))\n",
        "                      for fl in floors}\n",
        "            raw = {fl: ratios[fl] * count for fl in floors}\n",
        "            targ = {fl: int(round(raw[fl])) for fl in floors}\n",
        "\n",
        "            diff = count - sum(targ.values())\n",
        "            if diff:\n",
        "                frac = {fl: raw[fl] - math.floor(raw[fl]) for fl in floors}\n",
        "                if diff > 0:\n",
        "                    for fl in sorted(floors, key=lambda x: frac[x], reverse=True)[:diff]:\n",
        "                        targ[fl] += 1\n",
        "                else:\n",
        "                    for fl in sorted(floors, key=lambda x: frac[x])[: -diff]:\n",
        "                        targ[fl] -= 1\n",
        "\n",
        "            random.shuffle(blks)\n",
        "            idx = 0\n",
        "            for fl in floors:\n",
        "                for _ in range(targ[fl]):\n",
        "                    if idx >= count:\n",
        "                        break\n",
        "                    blk = blks[idx]\n",
        "                    idx += 1\n",
        "                    area = blk['Cumulative_Block_Circulation_Area']\n",
        "                    cap = blk['Max_Occupancy_with_Capacity']\n",
        "                    if (assignments[fl]['remaining_area'] >= area\n",
        "                        and assignments[fl]['remaining_capacity'] >= cap):\n",
        "                        assignments[fl]['assigned_blocks'].append(blk)\n",
        "                        assignments[fl]['assigned_departments'].add(\n",
        "                            blk['Department_Sub_Department']\n",
        "                        )\n",
        "                        assignments[fl]['remaining_area'] -= area\n",
        "                        assignments[fl]['remaining_capacity'] -= cap\n",
        "                    else:\n",
        "                        unassigned_blocks.append(blk)\n",
        "\n",
        "            # any leftovers\n",
        "            while idx < count:\n",
        "                unassigned_blocks.append(blks[idx])\n",
        "                idx += 1\n",
        "    # Phase 3: Build Detailed & Summary DataFrames\n",
        "    # 3.1 Detailed DataFrame\n",
        "    assignment_list = []\n",
        "    for fl, info in assignments.items():\n",
        "        for blk in info['assigned_blocks']:\n",
        "            assignment_list.append({\n",
        "                'Block_id': blk.get('Block_ID', ''),\n",
        "                'Floor': fl,\n",
        "                'Department': blk.get('Department_Sub_Department', ''),\n",
        "                'Block_Name': blk.get('Block_Name', ''),\n",
        "                'Destination_Group': blk.get('Destination_Group', ''),\n",
        "                'SpaceMix': blk.get('SpaceMix_(ME_WE_US_Support_Speciality)', ''),\n",
        "                'Assigned_Area_SQM': blk.get('Cumulative_Block_Circulation_Area', 0),\n",
        "                'Max_Occupancy': blk.get('Max_Occupancy_with_Capacity', 0),\n",
        "                'Priority': blk.get('Priority', 0),\n",
        "                'Adjacency_Priority': blk.get('Adjacency_Priority', 0)\n",
        "            })\n",
        "    detailed_df = pd.DataFrame(assignment_list)\n",
        "\n",
        "    # 3.2 Floor_Summary DataFrame\n",
        "    if not detailed_df.empty:\n",
        "        floor_summary_df = (\n",
        "            detailed_df\n",
        "            .groupby('Floor')\n",
        "            .agg(\n",
        "                Assgn_Blocks=('Block_Name', 'count'),\n",
        "                Assgn_Area_SQM=('Assigned_Area_SQM', 'sum'),\n",
        "                Total_Occupancy=('Max_Occupancy', 'sum')\n",
        "            )\n",
        "            .reset_index()\n",
        "        )\n",
        "    else:\n",
        "        floor_summary_df = pd.DataFrame(columns=['Floor', 'Assgn_Blocks', 'Assgn_Area_SQM', 'Total_Occupancy'])\n",
        "\n",
        "    # Merge with original floor input data to get base values\n",
        "    floor_input_subset = all_floor_data[[\n",
        "        'Name', 'Usable_Area', 'Max_Assignable_Floor_loading_Capacity'\n",
        "    ]].rename(columns={\n",
        "        'Name': 'Floor',\n",
        "        'Usable_Area': 'Input_Usable_Area',\n",
        "        'Max_Assignable_Floor_loading_Capacity': 'Input_Max_Capacity'\n",
        "    })\n",
        "\n",
        "    # Join input data with summary\n",
        "    floor_summary_df = pd.merge(\n",
        "        floor_input_subset,\n",
        "        floor_summary_df,\n",
        "        on='Floor',\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    # Fill NaNs (if any floor didn't get any assignments)\n",
        "    floor_summary_df[[\n",
        "        'Assgn_Blocks',\n",
        "        'Assgn_Area_SQM',\n",
        "        'Total_Occupancy'\n",
        "    ]] = floor_summary_df[[\n",
        "        'Assgn_Blocks',\n",
        "        'Assgn_Area_SQM',\n",
        "        'Total_Occupancy'\n",
        "    ]].fillna(0)\n",
        "\n",
        "    # 3.3 SpaceMix_By_Units DataFrame\n",
        "    all_categories = ['ME', 'WE', 'US', 'Support', 'Speciality']\n",
        "    category_totals = {\n",
        "        cat: len(typical_blocks[\n",
        "            typical_blocks['SpaceMix_(ME_WE_US_Support_Speciality)'].str.strip() == cat\n",
        "        ])\n",
        "        for cat in all_categories\n",
        "    }\n",
        "\n",
        "    rows = []\n",
        "    for fl, info in assignments.items():\n",
        "        counts = {cat: 0 for cat in all_categories}\n",
        "        for blk in info['assigned_blocks']:\n",
        "            cat = blk.get('SpaceMix_(ME_WE_US_Support_Speciality)', '').strip()\n",
        "            if cat in counts:\n",
        "                counts[cat] += 1\n",
        "        total_blocks_on_floor = sum(counts.values())\n",
        "\n",
        "        for cat in all_categories:\n",
        "            cnt = counts[cat]\n",
        "            pct_of_floor = (cnt / total_blocks_on_floor * 100) if total_blocks_on_floor else 0.0\n",
        "            total_cat = category_totals.get(cat, 0) # Use .get with default 0\n",
        "            pct_overall = (cnt / total_cat * 100) if total_cat else 0.0\n",
        "\n",
        "            rows.append({\n",
        "                'Floor': fl,\n",
        "                'SpaceMix': cat,\n",
        "                'Unit_Count_on_Floor': cnt,\n",
        "                'Pct_of_Floor_UC': round(pct_of_floor, 2),\n",
        "                'Pct_of_Overall_UC': round(pct_overall, 2)\n",
        "            })\n",
        "\n",
        "    space_mix_df = pd.DataFrame(rows)\n",
        "\n",
        "    # 3.4 Unassigned DataFrame\n",
        "    unassigned_list = []\n",
        "    for blk in unassigned_blocks:\n",
        "        unassigned_list.append({\n",
        "            'Department': blk.get('Department_Sub_Department', ''),\n",
        "            'Block_Name': blk.get('Block_Name', ''),\n",
        "            'Destination_Group': blk.get('Destination_Group', ''),\n",
        "            'SpaceMix': blk.get('SpaceMix_(ME_WE_US_Support_Speciality)', ''),\n",
        "            'Area_SQM': blk.get('Cumulative_Block_Circulation_Area', 0),\n",
        "            'Max_Occupancy': blk.get('Max_Occupancy_with_Capacity', 0),\n",
        "            'Priority': blk.get('Priority', 0),\n",
        "            'Adjacency_Priority': blk.get('Adjacency_Priority', 0)\n",
        "        })\n",
        "    unassigned_df = pd.DataFrame(unassigned_list)\n",
        "\n",
        "    return detailed_df, floor_summary_df, space_mix_df, unassigned_df\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 8: Generate & Export Files for All Modes and Categories\n",
        "# ----------------------------------------\n",
        "\n",
        "# Print adjacency-based destination groups summary\n",
        "print(\"📋 Adjacency-Based Destination Groups Summary:\")\n",
        "print(\"=\" * 60)\n",
        "for group_name, group_info in adjacency_destination_groups.items():\n",
        "    print(f\"\\n{group_name}:\")\n",
        "    print(f\"  • Department: {group_info.get('department', 'N/A')}\") # Use .get\n",
        "    print(f\"  • Priority: {group_info.get('priority', 'N/A')}\")     # Use .get\n",
        "    print(f\"  • Total Area: {group_info.get('total_area', 0):.2f} SQM\") # Use .get\n",
        "    print(f\"  • Total Capacity: {group_info.get('total_capacity', 0)}\") # Use .get\n",
        "    print(f\"  • Number of Blocks: {len(group_info.get('blocks', []))}\") # Use .get\n",
        "\n",
        "\n",
        "# Define categories for priority assignment\n",
        "priority_categories = ['ME', 'WE', 'US', 'Support']\n",
        "modes = ['centralized', 'semi', 'decentralized']\n",
        "\n",
        "# Generate plans for each mode and category combination\n",
        "all_plans = {}\n",
        "\n",
        "for mode in modes:\n",
        "    all_plans[mode] = {}\n",
        "    for category in priority_categories:\n",
        "        print(f\"\\nGenerating {mode} plan with {category} priority...\")\n",
        "        detailed, floor_sum, space_mix, unassigned = run_stack_plan(mode, category)\n",
        "        all_plans[mode][category] = {\n",
        "            'detailed': detailed,\n",
        "            'floor_summary': floor_sum,\n",
        "            'space_mix': space_mix,\n",
        "            'unassigned': unassigned\n",
        "        }\n",
        "\n",
        "# Build dynamic summary for each plan\n",
        "def make_typical_summary(detailed_df):\n",
        "    \"\"\"Create typical block summary\"\"\"\n",
        "    if detailed_df.empty:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Get all typical block types from the original data\n",
        "    types = typical_blocks['Block_Name'].dropna().str.strip().unique()\n",
        "\n",
        "    # Filter detailed_df for typical blocks only\n",
        "    typical_detailed = detailed_df[detailed_df['Block_Name'].isin(types)]\n",
        "\n",
        "    if typical_detailed.empty:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Group by Block_Name and Floor\n",
        "    df = (typical_detailed\n",
        "          .groupby(['Block_Name', 'Floor'])\n",
        "          .size()\n",
        "          .unstack(fill_value=0))\n",
        "\n",
        "    df['Total_Assigned'] = df.sum(axis=1)\n",
        "\n",
        "    # Calculate assignment ratio for each block type\n",
        "    for block_type in df.index:\n",
        "        total_blocks_of_type = len(typical_blocks[typical_blocks['Block_Name'].str.strip() == block_type])\n",
        "        df.loc[block_type, 'Assignment_Ratio'] = round(df.loc[block_type, 'Total_Assigned'] / total_blocks_of_type, 3) if total_blocks_of_type > 0 else 0\n",
        "\n",
        "    return df\n",
        "\n",
        "# Export to Excel files for each mode and category\n",
        "for mode in modes:\n",
        "    for category in priority_categories:\n",
        "        plan_data = all_plans[mode][category]\n",
        "\n",
        "        # Create summary\n",
        "        summary = make_typical_summary(plan_data['detailed'])\n",
        "\n",
        "        # Export to Excel\n",
        "        filename = f'stack_plan_{mode}_{category}_priority_adjacency_based.xlsx'\n",
        "        with pd.ExcelWriter(filename) as writer:\n",
        "            plan_data['detailed'].to_excel(writer, sheet_name='Detailed', index=False)\n",
        "            plan_data['floor_summary'].to_excel(writer, sheet_name='Floor_Summary', index=False)\n",
        "            plan_data['space_mix'].to_excel(writer, sheet_name='SpaceMix_By_Units', index=False)\n",
        "            plan_data['unassigned'].to_excel(writer, sheet_name='Unassigned', index=False)\n",
        "            if not summary.empty:\n",
        "                summary.to_excel(writer, sheet_name='Typical_Summary')\n",
        "\n",
        "print(\"\\n✅ Generated Excel outputs for all modes and priority categories.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Vsw-clZnn3K",
        "outputId": "5b47217e-1b42-4413-d268-b8bf843aabed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Error reading PDF Auto Stacking Input New Build - Case Study A- R1 (with block instances) - Split priority-destination grouping.pdf: [Errno 2] No such file or directory: 'Auto Stacking Input New Build - Case Study A- R1 (with block instances) - Split priority-destination grouping.pdf'\n",
            "Error reading PDF Auto Stacking Input New Build - Case Study A- R1 (with block instances) - Adjacency-destination grouping.pdf: [Errno 2] No such file or directory: 'Auto Stacking Input New Build - Case Study A- R1 (with block instances) - Adjacency-destination grouping.pdf'\n",
            "📋 Adjacency-Based Destination Groups Summary:\n",
            "============================================================\n",
            "\n",
            "Unmatched_Dest_Group_1:\n",
            "  • Department: Common_Common\n",
            "  • Priority: 0\n",
            "  • Total Area: 4396.26 SQM\n",
            "  • Total Capacity: 239.25\n",
            "  • Number of Blocks: 41\n",
            "\n",
            "Unmatched_Dest_Group_2:\n",
            "  • Department: External_External\n",
            "  • Priority: 0\n",
            "  • Total Area: 132.97 SQM\n",
            "  • Total Capacity: 2.5\n",
            "  • Number of Blocks: 5\n",
            "\n",
            "Generating centralized plan with ME priority...\n",
            "Phase 0: Assigning physical constraint blocks...\n",
            "Phase 1: Assigning destination groups...\n",
            "Phase 2: Assigning typical blocks with ME priority...\n",
            "\n",
            "Generating centralized plan with WE priority...\n",
            "Phase 0: Assigning physical constraint blocks...\n",
            "Phase 1: Assigning destination groups...\n",
            "Phase 2: Assigning typical blocks with WE priority...\n",
            "\n",
            "Generating centralized plan with US priority...\n",
            "Phase 0: Assigning physical constraint blocks...\n",
            "Phase 1: Assigning destination groups...\n",
            "Phase 2: Assigning typical blocks with US priority...\n",
            "\n",
            "Generating centralized plan with Support priority...\n",
            "Phase 0: Assigning physical constraint blocks...\n",
            "Phase 1: Assigning destination groups...\n",
            "Phase 2: Assigning typical blocks with Support priority...\n",
            "\n",
            "Generating semi plan with ME priority...\n",
            "Phase 0: Assigning physical constraint blocks...\n",
            "Phase 1: Assigning destination groups...\n",
            "Phase 2: Assigning typical blocks with ME priority...\n",
            "\n",
            "Generating semi plan with WE priority...\n",
            "Phase 0: Assigning physical constraint blocks...\n",
            "Phase 1: Assigning destination groups...\n",
            "Phase 2: Assigning typical blocks with WE priority...\n",
            "\n",
            "Generating semi plan with US priority...\n",
            "Phase 0: Assigning physical constraint blocks...\n",
            "Phase 1: Assigning destination groups...\n",
            "Phase 2: Assigning typical blocks with US priority...\n",
            "\n",
            "Generating semi plan with Support priority...\n",
            "Phase 0: Assigning physical constraint blocks...\n",
            "Phase 1: Assigning destination groups...\n",
            "Phase 2: Assigning typical blocks with Support priority...\n",
            "\n",
            "Generating decentralized plan with ME priority...\n",
            "Phase 0: Assigning physical constraint blocks...\n",
            "Phase 1: Assigning destination groups...\n",
            "Phase 2: Assigning typical blocks with ME priority...\n",
            "\n",
            "Generating decentralized plan with WE priority...\n",
            "Phase 0: Assigning physical constraint blocks...\n",
            "Phase 1: Assigning destination groups...\n",
            "Phase 2: Assigning typical blocks with WE priority...\n",
            "\n",
            "Generating decentralized plan with US priority...\n",
            "Phase 0: Assigning physical constraint blocks...\n",
            "Phase 1: Assigning destination groups...\n",
            "Phase 2: Assigning typical blocks with US priority...\n",
            "\n",
            "Generating decentralized plan with Support priority...\n",
            "Phase 0: Assigning physical constraint blocks...\n",
            "Phase 1: Assigning destination groups...\n",
            "Phase 2: Assigning typical blocks with Support priority...\n",
            "\n",
            "✅ Generated Excel outputs for all modes and priority categories.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final-BR-1"
      ],
      "metadata": {
        "id": "BxIXkX62uUc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import math\n",
        "import PyPDF2\n",
        "import re\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 1: Load Input Sheets\n",
        "# ----------------------------------------\n",
        "\n",
        "excel_path = '/content/B- R2.xlsx'  # adjust if needed\n",
        "\n",
        "# 1.1 Floors sheet\n",
        "all_floor_data = pd.read_excel(excel_path, sheet_name='Program Table Input 2 - Floor')\n",
        "all_floor_data.columns = all_floor_data.columns.str.strip()\n",
        "\n",
        "# 1.2 Blocks sheet\n",
        "all_block_data = pd.read_excel(excel_path, sheet_name='Program Table Input 1 - Block')\n",
        "all_block_data.columns = all_block_data.columns.str.strip()\n",
        "\n",
        "# 1.3 Department Split sheet\n",
        "department_split_data = pd.read_excel(excel_path, sheet_name='Department Split', skiprows=1)\n",
        "department_split_data.columns = department_split_data.columns.str.strip()\n",
        "department_split_data = department_split_data.rename(\n",
        "    columns={'BU_Department_Sub-Department': 'Department_Sub-Department'}\n",
        ")\n",
        "\n",
        "# 1.4 Adjacency sheet (original)\n",
        "xls = pd.ExcelFile(excel_path)\n",
        "adjacency_sheet_name = [name for name in xls.sheet_names if \"Adjacency\" in name][0]\n",
        "raw_data = xls.parse(adjacency_sheet_name, header=1, index_col=0)\n",
        "adjacency_data = raw_data.apply(pd.to_numeric, errors='coerce')\n",
        "adjacency_data.index = adjacency_data.index.str.strip()\n",
        "adjacency_data.columns = adjacency_data.columns.str.strip()\n",
        "\n",
        "# 1.5 De-Centralized Logic sheet\n",
        "df_logic = pd.read_excel(excel_path, sheet_name='De-Centralized Logic', header=None)\n",
        "De_Centralized_data = {}\n",
        "current_section = None\n",
        "for _, row in df_logic.iterrows():\n",
        "    first_cell = str(row[0]).strip() if pd.notna(row[0]) else \"\"\n",
        "    if first_cell in [\"Centralised\", \"Semi Centralized\", \"DeCentralised\"]:\n",
        "        current_section = first_cell\n",
        "        De_Centralized_data[current_section] = {\"Add\": 0}\n",
        "    elif current_section and first_cell == \"( Add into cetralised destination Block)\":\n",
        "        De_Centralized_data[current_section][\"Add\"] = int(row[1]) if pd.notna(row[1]) else 0\n",
        "\n",
        "# Ensure keys exist\n",
        "for key in [\"Centralised\", \"Semi Centralized\", \"DeCentralised\"]:\n",
        "    if key not in De_Centralized_data:\n",
        "        De_Centralized_data[key] = {\"Add\": 0}\n",
        "    elif \"Add\" not in De_Centralized_data[key]:\n",
        "        De_Centralized_data[key][\"Add\"] = 0\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 2: Physical Constraint Adjacency Logic\n",
        "# ----------------------------------------\n",
        "\n",
        "def define_physical_constraints():\n",
        "    \"\"\"\n",
        "    Define physical constraints based on the PDF document\n",
        "    Returns a dictionary mapping constraint types to their floor priorities\n",
        "    \"\"\"\n",
        "    physical_constraints = {\n",
        "        'Main Entry within Client Real estate Reception': {\n",
        "            'priority_1': 'lowest',  # Level 0 if available\n",
        "            'priority_2': 'mid',\n",
        "            'priority_3': 'top_most'\n",
        "        },\n",
        "        'Transfer floor': {\n",
        "            'blocks': []  # Nil - no specific blocks\n",
        "        },\n",
        "        'Floor with an Outdoor Terrace': {\n",
        "            'blocks': []  # Nil - no specific blocks\n",
        "        },\n",
        "        'Best View': {\n",
        "            'blocks': []  # Nil - no specific blocks\n",
        "        },\n",
        "        'Top most floor of Atrium Floor 2': {\n",
        "            'blocks': []  # Specific to Floor 2\n",
        "        },\n",
        "        'Top Most Level': {\n",
        "            'priority_1': 'highest'\n",
        "        },\n",
        "        'Refuge Floor': {\n",
        "            'blocks': []  # Nil - no specific blocks\n",
        "        },\n",
        "        'Additional Structural loading floor': {\n",
        "            'blocks': []  # Nil - no specific blocks\n",
        "        },\n",
        "        'Loading Dock': {\n",
        "            'blocks': []  # Nil - no specific blocks\n",
        "        },\n",
        "        'Service Floor': {\n",
        "            'blocks': []  # Nil - no specific blocks\n",
        "        }\n",
        "    }\n",
        "    return physical_constraints\n",
        "\n",
        "def get_floor_levels(floor_df):\n",
        "    \"\"\"\n",
        "    Determine floor levels based on floor names/numbers\n",
        "    Returns a dictionary mapping floor names to their level types\n",
        "    \"\"\"\n",
        "    floor_levels = {}\n",
        "    floors = floor_df['Name'].str.strip().tolist()\n",
        "\n",
        "    # Sort floors to identify lowest, highest, mid\n",
        "    # Assuming floors are named with numbers or can be sorted\n",
        "    sorted_floors = sorted(floors)\n",
        "\n",
        "    if len(sorted_floors) >= 1:\n",
        "        floor_levels[sorted_floors[0]] = 'lowest'\n",
        "        floor_levels[sorted_floors[-1]] = 'highest'\n",
        "\n",
        "        # Identify mid floors\n",
        "        if len(sorted_floors) > 2:\n",
        "            mid_floors = sorted_floors[1:-1]\n",
        "            for floor in mid_floors:\n",
        "                floor_levels[floor] = 'mid'\n",
        "        elif len(sorted_floors) == 2:\n",
        "            floor_levels[sorted_floors[1]] = 'mid'\n",
        "\n",
        "    # Special handling for specific floors mentioned in constraints\n",
        "    for floor in floors:\n",
        "        if 'atrium' in floor.lower() or '2' in floor:\n",
        "            floor_levels[floor] = 'atrium_top'\n",
        "\n",
        "    return floor_levels\n",
        "\n",
        "def assign_physical_constraint_blocks(block_data, floor_data, physical_constraints):\n",
        "    \"\"\"\n",
        "    Assign blocks based on physical constraints before other assignments\n",
        "    \"\"\"\n",
        "    blocks_df = block_data.copy()\n",
        "    floor_levels = get_floor_levels(floor_data)\n",
        "\n",
        "    # Add physical constraint assignment column\n",
        "    blocks_df['Physical_Constraint_Assignment'] = ''\n",
        "    blocks_df['Physical_Priority'] = 0\n",
        "\n",
        "    # Process blocks that have specific physical requirements\n",
        "    # For now, we'll identify blocks that should follow physical constraints\n",
        "    # This can be expanded based on specific block naming patterns or additional data\n",
        "\n",
        "    # Example: Reception blocks should go to lowest floor\n",
        "    reception_blocks = blocks_df[\n",
        "        blocks_df['Block_Name'].str.contains('Reception', case=False, na=False)\n",
        "    ]\n",
        "\n",
        "    for idx in reception_blocks.index:\n",
        "        blocks_df.loc[idx, 'Physical_Constraint_Assignment'] = 'Main Entry within Client Real estate Reception'\n",
        "        blocks_df.loc[idx, 'Physical_Priority'] = 1\n",
        "\n",
        "    # Example: Executive or VIP blocks should go to highest floors\n",
        "    executive_blocks = blocks_df[\n",
        "        blocks_df['Block_Name'].str.contains('Executive|VIP|CEO|Director', case=False, na=False)\n",
        "    ]\n",
        "\n",
        "    for idx in executive_blocks.index:\n",
        "        blocks_df.loc[idx, 'Physical_Constraint_Assignment'] = 'Top Most Level'\n",
        "        blocks_df.loc[idx, 'Physical_Priority'] = 1\n",
        "\n",
        "    # Example: Blocks with specific floor requirements\n",
        "    # You can add more specific logic based on your block naming conventions\n",
        "\n",
        "    return blocks_df, floor_levels\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 3: Read Adjacency Rules from PDF Files\n",
        "# ----------------------------------------\n",
        "\n",
        "def read_pdf_adjacency_rules(pdf_path):\n",
        "    \"\"\"Read adjacency rules from PDF file\"\"\"\n",
        "    adjacency_rules = {}\n",
        "\n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            pdf_reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page in pdf_reader.pages:\n",
        "                text += page.extract_text()\n",
        "\n",
        "        # Parse the text to extract adjacency rules\n",
        "        lines = text.split('\\n')\n",
        "        current_dept = None\n",
        "        current_block = None\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            # Look for department_subdepartment pattern\n",
        "            if '_' in line and any(keyword in line for keyword in ['Common', 'External']):\n",
        "                parts = line.split()\n",
        "                if len(parts) >= 2:\n",
        "                    dept_sub = parts[0]\n",
        "                    block_name = ' '.join(parts[1:])\n",
        "                    current_dept = dept_sub\n",
        "                    current_block = block_name\n",
        "\n",
        "                    if current_dept not in adjacency_rules:\n",
        "                        adjacency_rules[current_dept] = {}\n",
        "                    if current_block not in adjacency_rules[current_dept]:\n",
        "                        adjacency_rules[current_dept][current_block] = {}\n",
        "\n",
        "            # Look for priority values (1, 0.3, 0)\n",
        "            elif current_dept and current_block:\n",
        "                numbers = re.findall(r'\\b(?:1|0\\.3|0)\\b', line)\n",
        "                if numbers:\n",
        "                    # Store priority values\n",
        "                    adjacency_rules[current_dept][current_block]['priorities'] = [float(n) for n in numbers]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading PDF {pdf_path}: {e}\")\n",
        "\n",
        "    return adjacency_rules\n",
        "\n",
        "# Read adjacency rules from both PDF files\n",
        "adjacency_rules_1 = read_pdf_adjacency_rules('Auto Stacking Input New Build - Case Study A- R1 (with block instances) - Split priority-destination grouping.pdf')\n",
        "adjacency_rules_2 = read_pdf_adjacency_rules('Auto Stacking Input New Build - Case Study A- R1 (with block instances) - Adjacency-destination grouping.pdf')\n",
        "\n",
        "# Combine adjacency rules\n",
        "combined_adjacency_rules = {}\n",
        "for rules in [adjacency_rules_1, adjacency_rules_2]:\n",
        "    for dept, blocks in rules.items():\n",
        "        if dept not in combined_adjacency_rules:\n",
        "            combined_adjacency_rules[dept] = {}\n",
        "        combined_adjacency_rules[dept].update(blocks)\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 4: Create Destination Groups Based on Adjacency Rules\n",
        "# ----------------------------------------\n",
        "\n",
        "def create_adjacency_based_destination_groups(block_data, adjacency_rules):\n",
        "    \"\"\"\n",
        "    Create destination groups based on adjacency rules instead of block information\n",
        "    \"\"\"\n",
        "    # Create a copy of block data to work with\n",
        "    blocks_df = block_data.copy()\n",
        "\n",
        "    # Initialize Destination_Group and Adjacency_Priority columns for all blocks\n",
        "    blocks_df['Destination_Group'] = None\n",
        "    blocks_df['Adjacency_Priority'] = None\n",
        "\n",
        "    # Initialize destination group counter\n",
        "    group_counter = 1\n",
        "\n",
        "    # Dictionary to store formed groups\n",
        "    destination_groups = {}\n",
        "\n",
        "    # Process blocks marked as destination or both\n",
        "    destination_blocks = blocks_df[blocks_df['Typical_Destination'].isin(['Destination', 'both'])].copy()\n",
        "\n",
        "    # Create adjacency-based groups\n",
        "    for dept_sub, dept_rules in adjacency_rules.items():\n",
        "        # Find blocks belonging to this department\n",
        "        dept_blocks = destination_blocks[\n",
        "            destination_blocks['Department_Sub_Department'].str.strip() == dept_sub\n",
        "        ].copy()\n",
        "\n",
        "        if dept_blocks.empty:\n",
        "            continue\n",
        "\n",
        "        # Group blocks based on adjacency rules and priorities\n",
        "        for block_name, rule_info in dept_rules.items():\n",
        "            # Find blocks with this block name\n",
        "            matching_blocks = dept_blocks[\n",
        "                dept_blocks['Block_Name'].str.strip() == block_name\n",
        "            ].copy()\n",
        "\n",
        "            if matching_blocks.empty:\n",
        "                continue\n",
        "\n",
        "            # Get priority for this block type\n",
        "            priorities = rule_info.get('priorities', [0])\n",
        "            max_priority = max(priorities) if priorities else 0\n",
        "\n",
        "            # Create group name based on department and priority\n",
        "            if max_priority >= 1.0:\n",
        "                group_name = f\"High_Priority_Group_{group_counter}\"\n",
        "            elif max_priority >= 0.3:\n",
        "                group_name = f\"Medium_Priority_Group_{group_counter}\"\n",
        "            else:\n",
        "                group_name = f\"Low_Priority_Group_{group_counter}\"\n",
        "\n",
        "            # Assign all matching blocks to this group\n",
        "            for idx in matching_blocks.index:\n",
        "                blocks_df.loc[idx, 'Destination_Group'] = group_name\n",
        "                blocks_df.loc[idx, 'Adjacency_Priority'] = max_priority\n",
        "\n",
        "            # Store group information\n",
        "            if group_name not in destination_groups:\n",
        "                destination_groups[group_name] = {\n",
        "                    'blocks': [],\n",
        "                    'department': dept_sub,\n",
        "                    'priority': max_priority,\n",
        "                    'total_area': 0,\n",
        "                    'total_capacity': 0\n",
        "                }\n",
        "\n",
        "            for _, block in matching_blocks.iterrows():\n",
        "                destination_groups[group_name]['blocks'].append(block.to_dict())\n",
        "                destination_groups[group_name]['total_area'] += block['Cumulative_Block_Circulation_Area']\n",
        "                destination_groups[group_name]['total_capacity'] += block['Max_Occupancy_with_Capacity']\n",
        "\n",
        "            group_counter += 1\n",
        "\n",
        "    # Handle any remaining destination blocks that weren't matched\n",
        "    unmatched_dest_blocks = destination_blocks[\n",
        "        ~destination_blocks.index.isin(blocks_df[blocks_df['Destination_Group'].notna()].index)\n",
        "    ]\n",
        "\n",
        "    if not unmatched_dest_blocks.empty:\n",
        "        # Group unmatched blocks by department\n",
        "        for dept in unmatched_dest_blocks['Department_Sub_Department'].unique():\n",
        "            dept_unmatched = unmatched_dest_blocks[\n",
        "                unmatched_dest_blocks['Department_Sub_Department'] == dept\n",
        "            ]\n",
        "\n",
        "            group_name = f\"Unmatched_Dest_Group_{group_counter}\"\n",
        "\n",
        "            for idx in dept_unmatched.index:\n",
        "                blocks_df.loc[idx, 'Destination_Group'] = group_name\n",
        "                blocks_df.loc[idx, 'Adjacency_Priority'] = 0\n",
        "\n",
        "            destination_groups[group_name] = {\n",
        "                'blocks': dept_unmatched.to_dict('records'),\n",
        "                'department': dept,\n",
        "                'priority': 0,\n",
        "                'total_area': dept_unmatched['Cumulative_Block_Circulation_Area'].sum(),\n",
        "                'total_capacity': dept_unmatched['Max_Occupancy_with_Capacity'].sum()\n",
        "            }\n",
        "\n",
        "            group_counter += 1\n",
        "\n",
        "    return blocks_df, destination_groups\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 5: Apply Physical Constraints and Adjacency-Based Grouping\n",
        "# ----------------------------------------\n",
        "\n",
        "# Apply physical constraints first\n",
        "physical_constraints = define_physical_constraints()\n",
        "all_block_data, floor_levels = assign_physical_constraint_blocks(\n",
        "    all_block_data, all_floor_data, physical_constraints\n",
        ")\n",
        "\n",
        "# Apply adjacency-based grouping\n",
        "all_block_data, adjacency_destination_groups = create_adjacency_based_destination_groups(\n",
        "    all_block_data, combined_adjacency_rules\n",
        ")\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 6: Preprocess Blocks & Department Split\n",
        "# ----------------------------------------\n",
        "\n",
        "# 6.1 Separate Destination vs. Typical blocks (now with adjacency-based groups)\n",
        "destination_blocks = all_block_data[all_block_data['Typical_Destination'].isin(['Destination', 'both'])].copy()\n",
        "typical_blocks = all_block_data[all_block_data['Typical_Destination'] == 'Typical'].copy()\n",
        "\n",
        "# 6.2 Add priority information to destination blocks\n",
        "destination_blocks['Priority'] = destination_blocks.get('Adjacency_Priority', 0)\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 7: Initialize Floor Assignments\n",
        "# ----------------------------------------\n",
        "\n",
        "def initialize_floor_assignments(floor_df):\n",
        "    \"\"\"\n",
        "    Returns a dict keyed by floor name. Each entry tracks:\n",
        "      - remaining_area\n",
        "      - remaining_capacity\n",
        "      - assigned_blocks      (list of block‐row dicts)\n",
        "      - assigned_departments (set of sub‐departments)\n",
        "      - ME_area, WE_area, US_area, Support_area, Speciality_area (floats)\n",
        "    \"\"\"\n",
        "    assignments = {}\n",
        "    for _, row in floor_df.iterrows():\n",
        "        floor = row['Name'].strip()\n",
        "        assignments[floor] = {\n",
        "            'remaining_area': row['Usable Area'], # Corrected column name\n",
        "            'remaining_capacity': row['Max Assignable Floor loading Capacity'], # Corrected column name\n",
        "            'assigned_blocks': [],\n",
        "            'assigned_departments': set(),\n",
        "            'ME_area': 0.0,\n",
        "            'WE_area': 0.0,\n",
        "            'US_area': 0.0,\n",
        "            'Support_area': 0.0,\n",
        "            'Speciality_area': 0.0\n",
        "        }\n",
        "    return assignments\n",
        "\n",
        "floors = list(all_floor_data['Name'].str.strip())\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 8: Enhanced Assignment Functions\n",
        "# ----------------------------------------\n",
        "\n",
        "def assign_physical_constraint_blocks_to_floors(assignments, block_data, floor_levels):\n",
        "    \"\"\"\n",
        "    Assign blocks with physical constraints to appropriate floors first\n",
        "    \"\"\"\n",
        "    # Get blocks with physical constraints\n",
        "    constraint_blocks = block_data[\n",
        "        block_data['Physical_Constraint_Assignment'] != ''\n",
        "    ].copy()\n",
        "\n",
        "    assigned_blocks = []\n",
        "\n",
        "    for _, block in constraint_blocks.iterrows():\n",
        "        constraint_type = block['Physical_Constraint_Assignment']\n",
        "        area = block['Cumulative_Block_Circulation_Area']\n",
        "        capacity = block['Max_Occupancy_with_Capacity']\n",
        "\n",
        "        # Determine target floor based on constraint\n",
        "        target_floors = []\n",
        "\n",
        "        if constraint_type == 'Main Entry within Client Real estate Reception':\n",
        "            # Priority 1: lowest, Priority 2: mid, Priority 3: top_most\n",
        "            target_floors = [\n",
        "                floor for floor, level in floor_levels.items()\n",
        "                if level == 'lowest'\n",
        "            ]\n",
        "            if not target_floors:\n",
        "                target_floors = [\n",
        "                    floor for floor, level in floor_levels.items()\n",
        "                    if level == 'mid'\n",
        "                ]\n",
        "            if not target_floors:\n",
        "                target_floors = [\n",
        "                    floor for floor, level in floor_levels.items()\n",
        "                    if level == 'highest'\n",
        "                ]\n",
        "\n",
        "        elif constraint_type == 'Top Most Level':\n",
        "            target_floors = [\n",
        "                floor for floor, level in floor_levels.items()\n",
        "                if level == 'highest'\n",
        "            ]\n",
        "\n",
        "        # Try to assign to target floors\n",
        "        assigned = False\n",
        "        for floor in target_floors:\n",
        "            if floor in assignments:\n",
        "                if (assignments[floor]['remaining_area'] >= area and\n",
        "                    assignments[floor]['remaining_capacity'] >= capacity):\n",
        "\n",
        "                    assignments[floor]['assigned_blocks'].append(block.to_dict())\n",
        "                    assignments[floor]['assigned_departments'].add(\n",
        "                        block['Department_Sub_Department'].strip()\n",
        "                    )\n",
        "                    assignments[floor]['remaining_area'] -= area\n",
        "                    assignments[floor]['remaining_capacity'] -= capacity\n",
        "                    assigned_blocks.append(block.name)  # Track assigned block index\n",
        "                    assigned = True\n",
        "                    break\n",
        "\n",
        "        if not assigned:\n",
        "            print(f\"Warning: Could not assign block {block['Block_Name']} with constraint {constraint_type}\")\n",
        "\n",
        "    return assignments, assigned_blocks\n",
        "\n",
        "def can_groups_be_adjacent(group1_info, group2_info):\n",
        "    \"\"\"Check if two groups can be adjacent based on adjacency rules and priorities\"\"\"\n",
        "    # High priority groups (1.0) can be adjacent to any group\n",
        "    if group1_info['priority'] >= 1.0 or group2_info['priority'] >= 1.0:\n",
        "        return True\n",
        "\n",
        "    # Medium priority groups (0.3) can be adjacent to medium and high priority groups\n",
        "    if (group1_info['priority'] >= 0.3 and group2_info['priority'] >= 0.3):\n",
        "        return True\n",
        "\n",
        "    # Same department groups can be adjacent\n",
        "    if group1_info['department'] == group2_info['department']:\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "def split_destination_groups_by_adjacency(destination_groups):\n",
        "    \"\"\"Split destination groups based on adjacency rules and priorities\"\"\"\n",
        "    # Sort groups by priority (highest first)\n",
        "    sorted_groups = sorted(\n",
        "        destination_groups.items(),\n",
        "        key=lambda x: x[1]['priority'],\n",
        "        reverse=True\n",
        "    )\n",
        "\n",
        "    subgroups = []\n",
        "    current_subgroup = []\n",
        "\n",
        "    for group_name, group_info in sorted_groups:\n",
        "        if not current_subgroup:\n",
        "            current_subgroup.append((group_name, group_info))\n",
        "        else:\n",
        "            # Check if this group can be adjacent to any group in current subgroup\n",
        "            can_group = False\n",
        "            for existing_group_name, existing_group_info in current_subgroup:\n",
        "                if can_groups_be_adjacent(group_info, existing_group_info):\n",
        "                    can_group = True\n",
        "                    break\n",
        "\n",
        "            if can_group:\n",
        "                current_subgroup.append((group_name, group_info))\n",
        "            else:\n",
        "                # Start new subgroup\n",
        "                if current_subgroup:\n",
        "                    subgroups.append(current_subgroup)\n",
        "                current_subgroup = [(group_name, group_info)]\n",
        "\n",
        "    # Add the last subgroup\n",
        "    if current_subgroup:\n",
        "        subgroups.append(current_subgroup)\n",
        "\n",
        "    return subgroups\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 9: Core Stacking Function with Physical Constraints\n",
        "# ----------------------------------------\n",
        "\n",
        "def run_stack_plan(mode, priority_category='ME'):\n",
        "    \"\"\"\n",
        "    mode: 'centralized', 'semi', or 'decentralized'\n",
        "    priority_category: 'ME', 'WE', 'US', or 'Support' - which category to prioritize in typical block assignment\n",
        "    Returns four DataFrames:\n",
        "      1) detailed_df      – each block's assigned floor, department, block name, destination group, space mix, area, occupancy\n",
        "      2) floor_summary_df – floor‐wise totals (block count, total area, total occupancy)\n",
        "      3) space_mix_df     – for each floor and each category {ME, WE, US, Support, Speciality}\n",
        "      4) unassigned_df    – blocks that couldn't be placed\n",
        "    \"\"\"\n",
        "    assignments = initialize_floor_assignments(all_floor_data)\n",
        "    unassigned_blocks = []\n",
        "\n",
        "    # Phase 0: Assign Physical Constraint Blocks First\n",
        "    print(f\"Phase 0: Assigning physical constraint blocks...\")\n",
        "    assignments, assigned_constraint_blocks = assign_physical_constraint_blocks_to_floors(\n",
        "        assignments, all_block_data, floor_levels\n",
        "    )\n",
        "\n",
        "    # Determine how many floors to use for destination blocks\n",
        "    def destination_floor_count():\n",
        "        if mode == 'centralized':\n",
        "            return 2\n",
        "        elif mode == 'semi':\n",
        "            return 2 + De_Centralized_data[\"Semi Centralized\"][\"Add\"]\n",
        "        elif mode == 'decentralized':\n",
        "            return 2 + De_Centralized_data[\"DeCentralised\"][\"Add\"]\n",
        "        else:\n",
        "            return 2\n",
        "\n",
        "    max_dest_floors = destination_floor_count()\n",
        "    # Cap at total number of floors\n",
        "    max_dest_floors = min(max_dest_floors, len(floors))\n",
        "\n",
        "    # Phase 1: Adjacency-Based Destination Group Assignment\n",
        "    print(f\"Phase 1: Assigning destination groups...\")\n",
        "\n",
        "    # Filter out already assigned blocks from destination groups\n",
        "    filtered_destination_groups = {}\n",
        "    for group_name, group_info in adjacency_destination_groups.items():\n",
        "        filtered_blocks = []\n",
        "        for block in group_info['blocks']:\n",
        "            # Check if block was already assigned in Phase 0\n",
        "            if block.get('Block_ID') not in assigned_constraint_blocks:\n",
        "                filtered_blocks.append(block)\n",
        "\n",
        "        if filtered_blocks:\n",
        "            filtered_destination_groups[group_name] = {\n",
        "                'blocks': filtered_blocks,\n",
        "                'department': group_info['department'],\n",
        "                'priority': group_info['priority'],\n",
        "                'total_area': sum(b['Cumulative_Block_Circulation_Area'] for b in filtered_blocks),\n",
        "                'total_capacity': sum(b['Max_Occupancy_with_Capacity'] for b in filtered_blocks)\n",
        "            }\n",
        "\n",
        "    group_names = list(filtered_destination_groups.keys())\n",
        "    random.shuffle(group_names)\n",
        "\n",
        "    for grp_name in group_names:\n",
        "        grp_info = filtered_destination_groups[grp_name]\n",
        "        grp_area = grp_info['total_area']\n",
        "        grp_cap = grp_info['total_capacity']\n",
        "        placed_whole = False\n",
        "\n",
        "        # Try to place entire group first on designated destination floors\n",
        "        candidate_floors = floors[:max_dest_floors].copy()\n",
        "\n",
        "        for fl in candidate_floors:\n",
        "            if (assignments[fl]['remaining_area'] >= grp_area and\n",
        "                assignments[fl]['remaining_capacity'] >= grp_cap):\n",
        "                # Entire group fits here—place all blocks\n",
        "                for blk in grp_info['blocks']:\n",
        "                    assignments[fl]['assigned_blocks'].append(blk)\n",
        "                    assignments[fl]['assigned_departments'].add(\n",
        "                        blk['Department_Sub_Department']\n",
        "                    )\n",
        "                assignments[fl]['remaining_area'] -= grp_area\n",
        "                assignments[fl]['remaining_capacity'] -= grp_cap\n",
        "                placed_whole = True\n",
        "                break\n",
        "\n",
        "        # If not placed as whole, try remaining floors\n",
        "        if not placed_whole:\n",
        "            for fl in floors[max_dest_floors:]:\n",
        "                if (assignments[fl]['remaining_area'] >= grp_area and\n",
        "                    assignments[fl]['remaining_capacity'] >= grp_cap):\n",
        "                    for blk in grp_info['blocks']:\n",
        "                        assignments[fl]['assigned_blocks'].append(blk)\n",
        "                        assignments[fl]['assigned_departments'].add(\n",
        "                            blk['Department_Sub_Department'].strip()\n",
        "                        )\n",
        "                    assignments[fl]['remaining_area'] -= grp_area\n",
        "                    assignments[fl]['remaining_capacity'] -= grp_cap\n",
        "                    placed_whole = True\n",
        "                    break\n",
        "\n",
        "        # If still not placed, try splitting based on adjacency\n",
        "        if not placed_whole:\n",
        "            # Split this group's blocks if possible\n",
        "            subgroups = split_destination_groups_by_adjacency({grp_name: grp_info})\n",
        "\n",
        "            for subgroup in subgroups:\n",
        "                subgroup_area = sum(group_info['total_area'] for _, group_info in subgroup)\n",
        "                subgroup_cap = sum(group_info['total_capacity'] for _, group_info in subgroup)\n",
        "                subgroup_blocks = []\n",
        "                for _, group_info in subgroup:\n",
        "                    subgroup_blocks.extend(group_info['blocks'])\n",
        "\n",
        "                subgroup_placed = False\n",
        "\n",
        "                # Try to place subgroup on available floors\n",
        "                for fl in floors:\n",
        "                    if (assignments[fl]['remaining_area'] >= subgroup_area and\n",
        "                        assignments[fl]['remaining_capacity'] >= subgroup_cap):\n",
        "                        for blk in subgroup_blocks:\n",
        "                            assignments[fl]['assigned_blocks'].append(blk)\n",
        "                            assignments[fl]['assigned_departments'].add(\n",
        "                                blk['Department_Sub_Department'].strip()\n",
        "                            )\n",
        "                        assignments[fl]['remaining_area'] -= subgroup_area\n",
        "                        assignments[fl]['remaining_capacity'] -= subgroup_cap\n",
        "                        subgroup_placed = True\n",
        "                        break\n",
        "\n",
        "                # If subgroup still can't be placed, add to unassigned\n",
        "                if not subgroup_placed:\n",
        "                    for blk in subgroup_blocks:\n",
        "                        unassigned_blocks.append(blk)\n",
        "\n",
        "\n",
        "    # Phase 2: Category-prioritized distribution of typical blocks across floors\n",
        "    print(f\"Phase 2: Assigning typical blocks with {priority_category} priority...\")\n",
        "\n",
        "    # Filter out already assigned typical blocks\n",
        "    remaining_typical_blocks = typical_blocks[\n",
        "        ~typical_blocks.index.isin(assigned_constraint_blocks)\n",
        "    ].copy()\n",
        "\n",
        "    # 2.1 Group typical blocks by SpaceMix category and Block_Name\n",
        "    typical_recs = remaining_typical_blocks.to_dict('records')\n",
        "\n",
        "    # Define category order based on priority_category\n",
        "    all_categories = ['ME', 'WE', 'US', 'Support', 'Speciality']\n",
        "    if priority_category in all_categories:\n",
        "        category_order = [priority_category] + [cat for cat in all_categories if cat != priority_category]\n",
        "    else:\n",
        "        category_order = all_categories\n",
        "\n",
        "    # Group blocks by category and then by block name\n",
        "    category_blocks = {}\n",
        "    for cat in category_order:\n",
        "        category_blocks[cat] = {}\n",
        "        cat_blocks = remaining_typical_blocks[\n",
        "            remaining_typical_blocks['SpaceMix_(ME_WE_US_Support_Speciality)'].str.strip() == cat\n",
        "        ]\n",
        "        for _, blk in cat_blocks.iterrows():\n",
        "            name = blk['Block_Name']\n",
        "            if name not in category_blocks[cat]:\n",
        "                category_blocks[cat][name] = []\n",
        "            category_blocks[cat][name].append(blk.to_dict())\n",
        "\n",
        "    # 2.2 Process categories in priority order\n",
        "    for cat in category_order:\n",
        "        if cat not in category_blocks:\n",
        "            continue\n",
        "\n",
        "        # Compute each floor's available area for this category\n",
        "        avail = {fl: assignments[fl]['remaining_area'] for fl in floors}\n",
        "        total_avail = sum(avail.values())\n",
        "\n",
        "        if total_avail <= 0:\n",
        "            # No more space available, add remaining blocks to unassigned\n",
        "            for btype, blks in category_blocks[cat].items():\n",
        "                for blk in blks:\n",
        "                    unassigned_blocks.append(blk)\n",
        "            continue\n",
        "\n",
        "        # 2.3 For each block type in this category, compute target counts per floor\n",
        "        for btype, blks in category_blocks[cat].items():\n",
        "            count = len(blks)\n",
        "            ratios = {fl: (avail[fl] / total_avail if total_avail > 0 else 1/len(floors))\n",
        "                      for fl in floors}\n",
        "            raw = {fl: ratios[fl] * count for fl in floors}\n",
        "            targ = {fl: int(round(raw[fl])) for fl in floors}\n",
        "\n",
        "            diff = count - sum(targ.values())\n",
        "            if diff:\n",
        "                frac = {fl: raw[fl] - math.floor(raw[fl]) for fl in floors}\n",
        "                if diff > 0:\n",
        "                    for fl in sorted(floors, key=lambda x: frac[x], reverse=True)[:diff]:\n",
        "                        targ[fl] += 1\n",
        "                else:\n",
        "                    for fl in sorted(floors, key=lambda x: frac[x])[: -diff]:\n",
        "                        targ[fl] -= 1\n",
        "\n",
        "            random.shuffle(blks)\n",
        "            idx = 0\n",
        "            for fl in floors:\n",
        "                for _ in range(targ[fl]):\n",
        "                    if idx >= count:\n",
        "                        break\n",
        "                    blk = blks[idx]\n",
        "                    idx += 1\n",
        "                    area = blk['Cumulative_Block_Circulation_Area']\n",
        "                    cap = blk['Max_Occupancy_with_Capacity']\n",
        "                    if (assignments[fl]['remaining_area'] >= area\n",
        "                        and assignments[fl]['remaining_capacity'] >= cap):\n",
        "                        assignments[fl]['assigned_blocks'].append(blk)\n",
        "                        assignments[fl]['assigned_departments'].add(\n",
        "                            blk['Department_Sub_Department']\n",
        "                        )\n",
        "                        assignments[fl]['remaining_area'] -= area\n",
        "                        assignments[fl]['remaining_capacity'] -= cap\n",
        "                    else:\n",
        "                        unassigned_blocks.append(blk)\n",
        "\n",
        "            # any leftovers\n",
        "            while idx < count:\n",
        "                unassigned_blocks.append(blks[idx])\n",
        "                idx += 1\n",
        "    # Phase 3: Build Detailed & Summary DataFrames\n",
        "    # 3.1 Detailed DataFrame\n",
        "    assignment_list = []\n",
        "    for fl, info in assignments.items():\n",
        "        for blk in info['assigned_blocks']:\n",
        "            assignment_list.append({\n",
        "                'Block_id': blk.get('Block_ID', ''),\n",
        "                'Floor': fl,\n",
        "                'Department': blk.get('Department_Sub_Department', ''),\n",
        "                'Block_Name': blk.get('Block_Name', ''),\n",
        "                'Destination_Group': blk.get('Destination_Group', ''),\n",
        "                'SpaceMix': blk.get('SpaceMix_(ME_WE_US_Support_Speciality)', ''),\n",
        "                'Assigned_Area_SQM': blk.get('Cumulative_Block_Circulation_Area', 0),\n",
        "                'Max_Occupancy': blk.get('Max_Occupancy_with_Capacity', 0),\n",
        "                'Priority': blk.get('Priority', 0),\n",
        "                'Adjacency_Priority': blk.get('Adjacency_Priority', 0)\n",
        "            })\n",
        "    detailed_df = pd.DataFrame(assignment_list)\n",
        "\n",
        "    # 3.2 Floor_Summary DataFrame\n",
        "    if not detailed_df.empty:\n",
        "        floor_summary_df = (\n",
        "            detailed_df\n",
        "            .groupby('Floor')\n",
        "            .agg(\n",
        "                Assgn_Blocks=('Block_Name', 'count'),\n",
        "                Assgn_Area_SQM=('Assigned_Area_SQM', 'sum'),\n",
        "                Total_Occupancy=('Max_Occupancy', 'sum')\n",
        "            )\n",
        "            .reset_index()\n",
        "        )\n",
        "    else:\n",
        "        floor_summary_df = pd.DataFrame(columns=['Floor', 'Assgn_Blocks', 'Assgn_Area_SQM', 'Total_Occupancy'])\n",
        "\n",
        "    # Merge with original floor input data to get base values\n",
        "    floor_input_subset = all_floor_data[[\n",
        "        'Name', 'Usable Area', 'Max Assignable Floor loading Capacity' # Corrected column name\n",
        "    ]].rename(columns={\n",
        "        'Name': 'Floor',\n",
        "        'Usable Area': 'Input_Usable_Area', # Corrected column name\n",
        "        'Max Assignable Floor loading Capacity': 'Input_Max_Capacity' # Corrected column name\n",
        "    })\n",
        "\n",
        "    # Join input data with summary\n",
        "    floor_summary_df = pd.merge(\n",
        "        floor_input_subset,\n",
        "        floor_summary_df,\n",
        "        on='Floor',\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    # Fill NaNs (if any floor didn't get any assignments)\n",
        "    floor_summary_df[[\n",
        "        'Assgn_Blocks',\n",
        "        'Assgn_Area_SQM',\n",
        "        'Total_Occupancy'\n",
        "    ]] = floor_summary_df[[\n",
        "        'Assgn_Blocks',\n",
        "        'Assgn_Area_SQM',\n",
        "        'Total_Occupancy'\n",
        "    ]].fillna(0)\n",
        "\n",
        "    # 3.3 SpaceMix_By_Units DataFrame\n",
        "    all_categories = ['ME', 'WE', 'US', 'Support', 'Speciality']\n",
        "    category_totals = {\n",
        "        cat: len(typical_blocks[\n",
        "            typical_blocks['SpaceMix_(ME_WE_US_Support_Speciality)'].str.strip() == cat\n",
        "        ])\n",
        "        for cat in all_categories\n",
        "    }\n",
        "\n",
        "    rows = []\n",
        "    for fl, info in assignments.items():\n",
        "        counts = {cat: 0 for cat in all_categories}\n",
        "        for blk in info['assigned_blocks']:\n",
        "            cat = blk.get('SpaceMix_(ME_WE_US_Support_Speciality)', '').strip()\n",
        "            if cat in counts:\n",
        "                counts[cat] += 1\n",
        "        total_blocks_on_floor = sum(counts.values())\n",
        "\n",
        "        for cat in all_categories:\n",
        "            cnt = counts[cat]\n",
        "            pct_of_floor = (cnt / total_blocks_on_floor * 100) if total_blocks_on_floor else 0.0\n",
        "            total_cat = category_totals.get(cat, 0) # Use .get with default 0\n",
        "            pct_overall = (cnt / total_cat * 100) if total_cat else 0.0\n",
        "\n",
        "            rows.append({\n",
        "                'Floor': fl,\n",
        "                'SpaceMix': cat,\n",
        "                'Unit_Count_on_Floor': cnt,\n",
        "                'Pct_of_Floor_UC': round(pct_of_floor, 2),\n",
        "                'Pct_of_Overall_UC': round(pct_overall, 2)\n",
        "            })\n",
        "\n",
        "    space_mix_df = pd.DataFrame(rows)\n",
        "\n",
        "    # 3.4 Unassigned DataFrame\n",
        "    unassigned_list = []\n",
        "    for blk in unassigned_blocks:\n",
        "        unassigned_list.append({\n",
        "            'Department': blk.get('Department_Sub_Department', ''),\n",
        "            'Block_Name': blk.get('Block_Name', ''),\n",
        "            'Destination_Group': blk.get('Destination_Group', ''),\n",
        "            'SpaceMix': blk.get('SpaceMix_(ME_WE_US_Support_Speciality)', ''),\n",
        "            'Area_SQM': blk.get('Cumulative_Block_Circulation_Area', 0),\n",
        "            'Max_Occupancy': blk.get('Max_Occupancy_with_Capacity', 0),\n",
        "            'Priority': blk.get('Priority', 0),\n",
        "            'Adjacency_Priority': blk.get('Adjacency_Priority', 0)\n",
        "        })\n",
        "    unassigned_df = pd.DataFrame(unassigned_list)\n",
        "\n",
        "    return detailed_df, floor_summary_df, space_mix_df, unassigned_df\n",
        "\n",
        "# ----------------------------------------\n",
        "# Step 8: Generate & Export Files for All Modes and Categories\n",
        "# ----------------------------------------\n",
        "\n",
        "# Print adjacency-based destination groups summary\n",
        "print(\"📋 Adjacency-Based Destination Groups Summary:\")\n",
        "print(\"=\" * 60)\n",
        "for group_name, group_info in adjacency_destination_groups.items():\n",
        "    print(f\"\\n{group_name}:\")\n",
        "    print(f\"  • Department: {group_info.get('department', 'N/A')}\") # Use .get\n",
        "    print(f\"  • Priority: {group_info.get('priority', 'N/A')}\")     # Use .get\n",
        "    print(f\"  • Total Area: {group_info.get('total_area', 0):.2f} SQM\") # Use .get\n",
        "    print(f\"  • Total Capacity: {group_info.get('total_capacity', 0)}\") # Use .get\n",
        "    print(f\"  • Number of Blocks: {len(group_info.get('blocks', []))}\") # Use .get\n",
        "\n",
        "\n",
        "# Define categories for priority assignment\n",
        "priority_categories = ['ME', 'WE', 'US', 'Support']\n",
        "modes = ['centralized', 'semi', 'decentralized']\n",
        "\n",
        "# Generate plans for each mode and category combination\n",
        "all_plans = {}\n",
        "\n",
        "for mode in modes:\n",
        "    all_plans[mode] = {}\n",
        "    for category in priority_categories:\n",
        "        print(f\"\\nGenerating {mode} plan with {category} priority...\")\n",
        "        detailed, floor_sum, space_mix, unassigned = run_stack_plan(mode, category)\n",
        "        all_plans[mode][category] = {\n",
        "            'detailed': detailed,\n",
        "            'floor_summary': floor_sum,\n",
        "            'space_mix': space_mix,\n",
        "            'unassigned': unassigned\n",
        "        }\n",
        "\n",
        "# Build dynamic summary for each plan\n",
        "def make_typical_summary(detailed_df):\n",
        "    \"\"\"Create typical block summary\"\"\"\n",
        "    if detailed_df.empty:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Get all typical block types from the original data\n",
        "    types = typical_blocks['Block_Name'].dropna().str.strip().unique()\n",
        "\n",
        "    # Filter detailed_df for typical blocks only\n",
        "    typical_detailed = detailed_df[detailed_df['Block_Name'].isin(types)]\n",
        "\n",
        "    if typical_detailed.empty:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Group by Block_Name and Floor\n",
        "    df = (typical_detailed\n",
        "          .groupby(['Block_Name', 'Floor'])\n",
        "          .size()\n",
        "          .unstack(fill_value=0))\n",
        "\n",
        "    df['Total_Assigned'] = df.sum(axis=1)\n",
        "\n",
        "    # Calculate assignment ratio for each block type\n",
        "    for block_type in df.index:\n",
        "        total_blocks_of_type = len(typical_blocks[typical_blocks['Block_Name'].str.strip() == block_type])\n",
        "        df.loc[block_type, 'Assignment_Ratio'] = round(df.loc[block_type, 'Total_Assigned'] / total_blocks_of_type, 3) if total_blocks_of_type > 0 else 0\n",
        "\n",
        "    return df\n",
        "\n",
        "# Export to Excel files for each mode and category\n",
        "for mode in modes:\n",
        "    for category in priority_categories:\n",
        "        plan_data = all_plans[mode][category]\n",
        "\n",
        "        # Create summary\n",
        "        summary = make_typical_summary(plan_data['detailed'])\n",
        "\n",
        "        # Export to Excel\n",
        "        filename = f'stack_plan_{mode}_{category}_priority_adjacency_based.xlsx'\n",
        "        with pd.ExcelWriter(filename) as writer:\n",
        "            plan_data['detailed'].to_excel(writer, sheet_name='Detailed', index=False)\n",
        "            plan_data['floor_summary'].to_excel(writer, sheet_name='Floor_Summary', index=False)\n",
        "            plan_data['space_mix'].to_excel(writer, sheet_name='SpaceMix_By_Units', index=False)\n",
        "            plan_data['unassigned'].to_excel(writer, sheet_name='Unassigned', index=False)\n",
        "            if not summary.empty:\n",
        "                summary.to_excel(writer, sheet_name='Typical_Summary')\n",
        "\n",
        "print(\"\\n✅ Generated Excel outputs for all modes and priority categories.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCPjvWbFrOLU",
        "outputId": "e3f6001b-4354-4f71-c7c9-bc1c4d50aae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading PDF Auto Stacking Input New Build - Case Study A- R1 (with block instances) - Split priority-destination grouping.pdf: [Errno 2] No such file or directory: 'Auto Stacking Input New Build - Case Study A- R1 (with block instances) - Split priority-destination grouping.pdf'\n",
            "Error reading PDF Auto Stacking Input New Build - Case Study A- R1 (with block instances) - Adjacency-destination grouping.pdf: [Errno 2] No such file or directory: 'Auto Stacking Input New Build - Case Study A- R1 (with block instances) - Adjacency-destination grouping.pdf'\n",
            "📋 Adjacency-Based Destination Groups Summary:\n",
            "============================================================\n",
            "\n",
            "Unmatched_Dest_Group_1:\n",
            "  • Department: External_External_External\n",
            "  • Priority: 0\n",
            "  • Total Area: 4022.52 SQM\n",
            "  • Total Capacity: 349.0\n",
            "  • Number of Blocks: 5\n",
            "\n",
            "Unmatched_Dest_Group_2:\n",
            "  • Department: Common_Common_Common\n",
            "  • Priority: 0\n",
            "  • Total Area: 17962.05 SQM\n",
            "  • Total Capacity: 194.0\n",
            "  • Number of Blocks: 224\n",
            "\n",
            "Generating centralized plan with ME priority...\n",
            "Phase 0: Assigning physical constraint blocks...\n",
            "Phase 1: Assigning destination groups...\n",
            "Phase 2: Assigning typical blocks with ME priority...\n",
            "\n",
            "Generating centralized plan with WE priority...\n",
            "Phase 0: Assigning physical constraint blocks...\n",
            "Phase 1: Assigning destination groups...\n",
            "Phase 2: Assigning typical blocks with WE priority...\n",
            "\n",
            "Generating centralized plan with US priority...\n",
            "Phase 0: Assigning physical constraint blocks...\n",
            "Phase 1: Assigning destination groups...\n",
            "Phase 2: Assigning typical blocks with US priority...\n",
            "\n",
            "Generating centralized plan with Support priority...\n",
            "Phase 0: Assigning physical constraint blocks...\n",
            "Phase 1: Assigning destination groups...\n",
            "Phase 2: Assigning typical blocks with Support priority...\n",
            "\n",
            "Generating semi plan with ME priority...\n",
            "Phase 0: Assigning physical constraint blocks...\n",
            "Phase 1: Assigning destination groups...\n",
            "Phase 2: Assigning typical blocks with ME priority...\n",
            "\n",
            "Generating semi plan with WE priority...\n",
            "Phase 0: Assigning physical constraint blocks...\n",
            "Phase 1: Assigning destination groups...\n",
            "Phase 2: Assigning typical blocks with WE priority...\n",
            "\n",
            "Generating semi plan with US priority...\n",
            "Phase 0: Assigning physical constraint blocks...\n",
            "Phase 1: Assigning destination groups...\n",
            "Phase 2: Assigning typical blocks with US priority...\n",
            "\n",
            "Generating semi plan with Support priority...\n",
            "Phase 0: Assigning physical constraint blocks...\n",
            "Phase 1: Assigning destination groups...\n",
            "Phase 2: Assigning typical blocks with Support priority...\n",
            "\n",
            "Generating decentralized plan with ME priority...\n",
            "Phase 0: Assigning physical constraint blocks...\n",
            "Phase 1: Assigning destination groups...\n",
            "Phase 2: Assigning typical blocks with ME priority...\n",
            "\n",
            "Generating decentralized plan with WE priority...\n",
            "Phase 0: Assigning physical constraint blocks...\n",
            "Phase 1: Assigning destination groups...\n",
            "Phase 2: Assigning typical blocks with WE priority...\n",
            "\n",
            "Generating decentralized plan with US priority...\n",
            "Phase 0: Assigning physical constraint blocks...\n",
            "Phase 1: Assigning destination groups...\n",
            "Phase 2: Assigning typical blocks with US priority...\n",
            "\n",
            "Generating decentralized plan with Support priority...\n",
            "Phase 0: Assigning physical constraint blocks...\n",
            "Phase 1: Assigning destination groups...\n",
            "Phase 2: Assigning typical blocks with Support priority...\n",
            "\n",
            "✅ Generated Excel outputs for all modes and priority categories.\n"
          ]
        }
      ]
    }
  ]
}